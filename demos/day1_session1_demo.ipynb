{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Day 1, Session 1: Introduction to HuggingFace Pipelines\n## üöÄ Building Foundations for Multimodal Invoice Processing\n\n---\n\n### üìö **What You'll Learn in This Session**\n\nBy the end of this demonstration, you will understand:\n\n1. **üèóÔ∏è HuggingFace Pipeline Architecture**\n   - How pipelines abstract complex AI models into simple APIs\n   - The three-layer architecture: Pipeline ‚Üí Model ‚Üí Tokenizer/Feature Extractor\n   - Why this matters for production AI systems\n\n2. **üß† AI Task Categories for Invoice Processing**\n   - **Text Understanding**: Sentiment analysis, question answering, named entity recognition\n   - **Computer Vision**: Image classification, object detection, OCR\n   - **Multimodal Processing**: Document understanding that combines text + vision\n\n3. **‚ö° Performance & Production Considerations**\n   - GPU acceleration benefits (10-100x speedup)\n   - Memory management strategies for limited resources\n   - Model selection trade-offs (accuracy vs speed vs memory)\n\n4. **üéØ Real-World Applications**\n   - Processing actual invoice and receipt images\n   - Extracting structured data from unstructured documents\n   - Building the foundation for automated accounts payable\n\n---\n\n### üåç **Why This Matters: The Invoice Processing Challenge**\n\n**The Problem:**\n- Companies process millions of invoices annually\n- Manual data entry costs $15-40 per invoice\n- Human error rates: 1-3% \n- Processing delays impact cash flow\n\n**The AI Solution:**\n- Automated extraction reduces costs to $1-5 per invoice\n- Error rates drop to <0.1% with proper validation\n- Processing time: minutes instead of hours\n- 24/7 processing capability\n\n**Technical Foundation:**\n- HuggingFace provides 500,000+ pre-trained models\n- Models handle 100+ languages and document types\n- GPU acceleration enables real-time processing\n- This session shows you HOW to build these systems\n\n---\n\n### üéØ **Session Objectives**\n\n**Technical Goals:**\n- ‚úÖ Understand HuggingFace pipeline architecture\n- ‚úÖ Demonstrate text and vision processing capabilities  \n- ‚úÖ Preview document understanding for invoice analysis\n- ‚úÖ Measure GPU acceleration benefits\n- ‚úÖ Learn memory management strategies\n\n**Business Impact:**\n- ‚úÖ Process real invoice and receipt images\n- ‚úÖ Extract structured data automatically\n- ‚úÖ Understand production deployment requirements\n- ‚úÖ Calculate ROI potential for automation\n\n**Hands-On Experience:**\n- ‚úÖ Run state-of-the-art AI models with 3 lines of code\n- ‚úÖ Compare different approaches to document processing\n- ‚úÖ Measure performance across CPU vs GPU\n- ‚úÖ Handle real business documents\n\n---\n\n### üèóÔ∏è **HuggingFace Pipeline Architecture Explained**\n\n```\nüìÑ Input Document\n       ‚Üì\nüîÑ Feature Extraction (Image ‚Üí Tensors, Text ‚Üí Tokens)\n       ‚Üì  \nüß† Transformer Model (BERT, LayoutLM, Vision Transformer)\n       ‚Üì\nüìä Post-Processing (Logits ‚Üí Human-Readable Results)\n       ‚Üì\n‚úÖ Structured Output (JSON, Classes, Bounding Boxes)\n```\n\n**Why Pipelines Matter:**\n- **Abstraction**: Hide complex tokenization, model inference, post-processing\n- **Standardization**: Same API for 500,000+ models\n- **Performance**: Optimized for GPU acceleration and batching\n- **Production-Ready**: Built-in error handling and resource management\n\n**Three Types We'll Use:**\n1. **Text Pipelines**: Process invoice text content\n2. **Vision Pipelines**: Analyze document images\n3. **Multimodal Pipelines**: Combine text + vision for document understanding\n\n---\n\n### üìã **Prerequisites Check**\n- ‚úÖ Google Colab with GPU enabled (T4 recommended)\n- ‚úÖ Basic Python knowledge\n- ‚úÖ Understanding of JSON data structures\n- ‚úÖ Familiarity with business invoice concepts\n\n**üí° Pro Tip:** Enable GPU in Runtime ‚Üí Change Runtime Type ‚Üí GPU for 10-100x performance boost!\n\n---\n\nLet's begin building the future of automated document processing! üöÄ"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and GPU Check\n",
    "\n",
    "First, let's verify GPU availability and install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're on Google Colab and have GPU access\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check GPU availability\n",
    "try:\n",
    "    gpu_info = subprocess.check_output('nvidia-smi', shell=True).decode()\n",
    "    print(\"GPU is available\")\n",
    "    print(\"\\nGPU Information:\")\n",
    "    print(\"=\" * 50)\n",
    "    !nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
    "except:\n",
    "    print(\"No GPU detected. Please enable GPU in Runtime > Change runtime type\")\n",
    "    print(\"This notebook will still work but will be much slower on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download real invoice and receipt images\nimport requests\nimport zipfile\nimport io\nimport os\n\n# Dropbox shared link for the folder\ndropbox_url = \"https://www.dropbox.com/scl/fo/m9hyfmvi78snwv0nh34mo/AMEXxwXMLAOeve-_yj12ck8?rlkey=urinkikgiuven0fro7r4x5rcu&st=hv3of7g7&dl=1\"\n\nprint(f\"Downloading real invoice data from: {dropbox_url}\")\n\ntry:\n    response = requests.get(dropbox_url)\n    response.raise_for_status()\n\n    # Read the content as a zip file\n    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n        # Extract all contents to a directory named 'downloaded_images'\n        z.extractall(\"downloaded_images\")\n\n    print(\"‚úÖ Downloaded and extracted images to 'downloaded_images' folder.\")\n    \n    # List downloaded files\n    downloaded_files = []\n    for root, dirs, files in os.walk(\"downloaded_images\"):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                downloaded_files.append(os.path.join(root, file))\n                print(f\"  üìÑ {os.path.join(root, file)}\")\n    \n    # Store file paths for later use\n    INVOICE_IMAGES = [f for f in downloaded_files if 'invoice' in f.lower()]\n    RECEIPT_IMAGES = [f for f in downloaded_files if 'receipt' in f.lower()]\n    \n    print(f\"\\nFound {len(INVOICE_IMAGES)} invoice images and {len(RECEIPT_IMAGES)} receipt images\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"‚ùå Error downloading the file: {e}\")\n    INVOICE_IMAGES = []\n    RECEIPT_IMAGES = []\nexcept zipfile.BadZipFile:\n    print(\"‚ùå Error: The downloaded file is not a valid zip file.\")\n    INVOICE_IMAGES = []\n    RECEIPT_IMAGES = []\nexcept Exception as e:\n    print(f\"‚ùå An unexpected error occurred: {e}\")\n    INVOICE_IMAGES = []\n    RECEIPT_IMAGES = []\n\n# Install required packages\nprint(\"\\nInstalling required packages...\")\n!pip install -q transformers torch torchvision pillow accelerate\n!pip install -q timm sentencepiece\n\nprint(\"Packages installed successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and check versions\n",
    "import torch\n",
    "import transformers\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Text Pipeline Demo - Sentiment Analysis\n",
    "\n",
    "We'll start with sentiment analysis on invoice-related text to understand pipeline basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a sentiment analysis pipeline\n",
    "print(\"Loading sentiment analysis model...\")\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    ")\n",
    "\n",
    "# Test with invoice-related scenarios\n",
    "invoice_texts = [\n",
    "    \"Payment received on time. Thank you for your business.\",\n",
    "    \"Invoice is 90 days overdue. Please pay immediately.\",\n",
    "    \"We're pleased to offer you a 15% discount on this invoice.\",\n",
    "    \"Additional late fees have been applied to your account.\",\n",
    "    \"Your invoice has been processed successfully.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENTIMENT ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in invoice_texts:\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Sentiment: {result['label']} (confidence: {result['score']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Question Answering Pipeline - Extracting Information\n",
    "\n",
    "Question answering models can extract specific information from text - a key capability for invoice processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a question-answering pipeline\n",
    "print(\"Loading question-answering model...\")\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"distilbert-base-cased-distilled-squad\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Sample invoice context\n",
    "invoice_context = \"\"\"\n",
    "INVOICE #2024-1234\n",
    "Date: January 15, 2024\n",
    "Due Date: February 15, 2024\n",
    "\n",
    "Bill To:\n",
    "Acme Corporation\n",
    "123 Business Street\n",
    "New York, NY 10001\n",
    "\n",
    "Description: Professional consulting services\n",
    "Hours: 40\n",
    "Rate: $150/hour\n",
    "Subtotal: $6,000\n",
    "Tax (8%): $480\n",
    "Total Amount Due: $6,480\n",
    "\n",
    "Payment Terms: Net 30 days\n",
    "Late Fee: 1.5% per month\n",
    "\"\"\"\n",
    "\n",
    "# Questions to ask about the invoice\n",
    "questions = [\n",
    "    \"What is the invoice number?\",\n",
    "    \"What is the total amount due?\",\n",
    "    \"When is the payment due?\",\n",
    "    \"What is the hourly rate?\",\n",
    "    \"What are the payment terms?\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING INVOICE INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for question in questions:\n",
    "    answer = qa_pipeline(question=question, context=invoice_context)\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Answer: {answer['answer']}\")\n",
    "    print(f\"Confidence: {answer['score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Vision Pipeline - Image Classification\n",
    "\n",
    "Computer vision capabilities are essential for document analysis. Let's explore image classification on document samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test image classification on real downloaded documents\nprint(\"Loading image classification model...\")\nimage_classifier = pipeline(\n    \"image-classification\",\n    model=\"google/vit-base-patch16-224\",\n    device=0 if torch.cuda.is_available() else -1\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"IMAGE CLASSIFICATION RESULTS\")\nprint(\"=\"*60)\n\n# Use downloaded images if available, otherwise fallback to URLs\ntest_images = []\n\nif INVOICE_IMAGES:\n    test_images.append((\"Downloaded Invoice\", INVOICE_IMAGES[0]))\nif RECEIPT_IMAGES:\n    test_images.append((\"Downloaded Receipt\", RECEIPT_IMAGES[0]))\n\n# Fallback to online samples if no downloaded images\nif not test_images:\n    sample_images = {\n        \"Sample Invoice\": \"https://raw.githubusercontent.com/naiveHobo/InvoiceNet/master/invoices/1.png\",\n        \"Sample Receipt\": \"https://raw.githubusercontent.com/Asprise/receipt-ocr/main/receipt-java/sub-receipt.jpg\",\n    }\n    \n    for name, url in sample_images.items():\n        test_images.append((name, url))\n\nfor name, path_or_url in test_images:\n    try:\n        print(f\"\\nProcessing: {name}\")\n        \n        if path_or_url.startswith('http'):\n            # Download from URL\n            response = requests.get(path_or_url)\n            image = Image.open(BytesIO(response.content))\n        else:\n            # Load from local file\n            image = Image.open(path_or_url)\n        \n        # Resize image if too large\n        if image.size[0] > 500 or image.size[1] > 500:\n            image.thumbnail((500, 500), Image.Resampling.LANCZOS)\n        \n        # Measure inference time\n        start_time = time.time()\n        results = image_classifier(image, top_k=3)\n        inference_time = time.time() - start_time\n        \n        print(f\"Image size: {image.size}\")\n        print(f\"Inference time: {inference_time:.3f} seconds\")\n        print(\"\\nTop predictions:\")\n        for i, result in enumerate(results, 1):\n            print(f\"  {i}. {result['label']}: {result['score']:.2%}\")\n            \n        # Display the image\n        from IPython.display import display\n        display(image)\n        \n    except Exception as e:\n        print(f\"Error processing {name}: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Document Understanding Preview\n",
    "\n",
    "Document question-answering combines vision and language understanding - the core of modern invoice processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load document question-answering pipeline\nprint(\"Loading document question-answering model...\")\nprint(\"This model can read and understand documents.\")\nprint(\"Note: This is a larger model and may take a moment to download...\\n\")\n\ndoc_qa = pipeline(\n    \"document-question-answering\",\n    model=\"impira/layoutlm-document-qa\",\n    device=0 if torch.cuda.is_available() else -1\n)\n\n# Use downloaded invoice image if available, otherwise fallback\nif INVOICE_IMAGES:\n    invoice_path = INVOICE_IMAGES[0]\n    print(f\"Using downloaded invoice: {invoice_path}\")\n    invoice_image = Image.open(invoice_path)\nelse:\n    # Fallback to sample image\n    invoice_url = \"https://raw.githubusercontent.com/naiveHobo/InvoiceNet/master/invoices/1.png\"\n    print(f\"Using sample invoice from: {invoice_url}\")\n    response = requests.get(invoice_url)\n    invoice_image = Image.open(BytesIO(response.content))\n\ntry:\n    # Questions to ask about the invoice\n    questions = [\n        \"What is the invoice number?\",\n        \"What is the total amount?\",\n        \"What is the date?\",\n        \"Who is the vendor?\",\n        \"What is the due date?\"\n    ]\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"DOCUMENT UNDERSTANDING - INVOICE ANALYSIS\")\n    print(\"=\"*60)\n    print(\"\\nDemonstrating multimodal document understanding.\")\n    print(\"The model reads and interprets invoice images directly.\\n\")\n    \n    for question in questions:\n        print(f\"\\nQuestion: {question}\")\n        \n        start_time = time.time()\n        result = doc_qa(image=invoice_image, question=question)\n        inference_time = time.time() - start_time\n        \n        if result:\n            answer = result[0] if isinstance(result, list) else result\n            print(f\"Answer: {answer.get('answer', 'Not found')}\")\n            if 'score' in answer:\n                print(f\"Confidence: {answer['score']:.2%}\")\n            print(f\"Time: {inference_time:.2f} seconds\")\n    \n    # Display the invoice\n    print(\"\\nInvoice being analyzed:\")\n    invoice_image.thumbnail((600, 800), Image.Resampling.LANCZOS)\n    from IPython.display import display\n    display(invoice_image)\n    \nexcept Exception as e:\n    print(f\"Document QA error: {e}\")\n    print(\"This is expected with some invoice formats.\")\n    print(\"We'll explore more robust solutions in upcoming sessions.\")\n    \n    # Still display the image for reference\n    print(\"\\nInvoice image for reference:\")\n    invoice_image.thumbnail((600, 800), Image.Resampling.LANCZOS)\n    from IPython.display import display\n    display(invoice_image)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performance Comparison - CPU vs GPU\n",
    "\n",
    "Understanding the performance benefits of GPU acceleration is critical for production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CPU vs GPU performance\n",
    "test_text = \"This invoice requires immediate payment to avoid late fees.\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERFORMANCE COMPARISON: CPU vs GPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Test on GPU\n",
    "    gpu_pipeline = pipeline(\"sentiment-analysis\", device=0)\n",
    "    \n",
    "    # Warm up\n",
    "    _ = gpu_pipeline(test_text)\n",
    "    \n",
    "    # Measure GPU time\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = gpu_pipeline(test_text)\n",
    "    gpu_time = time.time() - start\n",
    "    \n",
    "    # Test on CPU\n",
    "    cpu_pipeline = pipeline(\"sentiment-analysis\", device=-1)\n",
    "    \n",
    "    # Warm up\n",
    "    _ = cpu_pipeline(test_text)\n",
    "    \n",
    "    # Measure CPU time\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = cpu_pipeline(test_text)\n",
    "    cpu_time = time.time() - start\n",
    "    \n",
    "    print(f\"\\nCPU Time (100 iterations): {cpu_time:.2f} seconds\")\n",
    "    print(f\"GPU Time (100 iterations): {gpu_time:.2f} seconds\")\n",
    "    print(f\"\\nGPU Speedup: {cpu_time/gpu_time:.1f}x faster\")\n",
    "    \n",
    "    # Clean up\n",
    "    del gpu_pipeline\n",
    "    del cpu_pipeline\n",
    "else:\n",
    "    print(\"GPU not available for comparison.\")\n",
    "    print(\"Enable GPU in Runtime > Change runtime type for better performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Memory Management\n",
    "\n",
    "Effective memory management is essential when working with large models on limited GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"Get current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / 1e9, torch.cuda.memory_reserved() / 1e9\n",
    "    return 0, 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPU MEMORY MANAGEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Check initial memory\n",
    "    allocated, reserved = get_gpu_memory()\n",
    "    print(f\"\\nInitial GPU Memory:\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "    \n",
    "    # Load a model\n",
    "    print(\"\\nLoading a model...\")\n",
    "    test_pipeline = pipeline(\"text-generation\", model=\"gpt2\", device=0)\n",
    "    \n",
    "    allocated, reserved = get_gpu_memory()\n",
    "    print(f\"\\nAfter loading GPT-2:\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "    \n",
    "    # Clear memory\n",
    "    print(\"\\nClearing GPU memory...\")\n",
    "    del test_pipeline\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    allocated, reserved = get_gpu_memory()\n",
    "    print(f\"\\nAfter cleanup:\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "    \n",
    "    print(\"\\nMemory Management Best Practices:\")\n",
    "    print(\"  1. Delete pipelines when done: del pipeline_name\")\n",
    "    print(\"  2. Clear cache: torch.cuda.empty_cache()\")\n",
    "    print(\"  3. Use smaller models when possible\")\n",
    "    print(\"  4. T4 GPU has 16GB - plan model selection accordingly\")\n",
    "else:\n",
    "    print(\"GPU not available. Memory management is less critical on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Learnings\n",
    "\n",
    "### Technical Insights:\n",
    "1. **Pipeline Architecture**: HuggingFace pipelines abstract complex model operations into simple function calls\n",
    "2. **Automatic Model Management**: Models are downloaded and cached on first use\n",
    "3. **GPU Acceleration**: Provides 10-100x speedup for inference operations\n",
    "4. **Memory Constraints**: T4 GPU's 16GB requires careful model selection and memory management\n",
    "5. **Multimodal Capabilities**: Document understanding models combine vision and language processing\n",
    "\n",
    "### Practical Applications:\n",
    "1. **Text Analysis**: Sentiment analysis and question answering for invoice text processing\n",
    "2. **Vision Processing**: Image classification for document type detection\n",
    "3. **Document Understanding**: Direct extraction of information from invoice images\n",
    "4. **Performance Optimization**: GPU usage is critical for production throughput\n",
    "5. **Resource Management**: Proper cleanup prevents out-of-memory errors\n",
    "\n",
    "### Next Steps:\n",
    "1. Session 2: Building a complete invoice extraction agent\n",
    "2. Session 3: Advanced computer vision for layout understanding\n",
    "3. Session 4: Deploying with Ollama for production use\n",
    "4. Session 5: Optimization and scaling strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available tasks and model recommendations\n",
    "from transformers import pipelines\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVAILABLE PIPELINE TASKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Common tasks for document processing\n",
    "relevant_tasks = [\n",
    "    \"text-classification\",\n",
    "    \"token-classification\", \n",
    "    \"question-answering\",\n",
    "    \"document-question-answering\",\n",
    "    \"image-classification\",\n",
    "    \"object-detection\",\n",
    "    \"image-to-text\",\n",
    "    \"zero-shot-classification\"\n",
    "]\n",
    "\n",
    "print(\"\\nTasks relevant for invoice processing:\")\n",
    "for task in relevant_tasks:\n",
    "    print(f\"  - {task}\")\n",
    "\n",
    "print(\"\\nModel Resources:\")\n",
    "print(\"  HuggingFace Model Hub: https://huggingface.co/models\")\n",
    "print(\"  - 500,000+ available models\")\n",
    "print(\"  - Filter by task, language, and license\")\n",
    "print(\"  - Community ratings and usage statistics\")\n",
    "print(\"  - Detailed model documentation\")\n",
    "\n",
    "print(\"\\nRecommended Models for Invoice Processing:\")\n",
    "print(\"  - LayoutLM: Document understanding with layout awareness\")\n",
    "print(\"  - Donut: End-to-end document AI without OCR\")\n",
    "print(\"  - TrOCR: Transformer-based optical character recognition\")\n",
    "print(\"  - Table Transformer: Table detection and structure recognition\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}