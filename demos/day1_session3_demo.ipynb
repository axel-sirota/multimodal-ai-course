{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, Session 3: Building Agent Workflows with LangGraph\n",
    "\n",
    "## From Simple Chains to Complex Workflows\n",
    "\n",
    "### The Evolution of Agent Architecture\n",
    "\n",
    "We've seen how ReAct agents work - they reason and act in a loop. But production systems need more:\n",
    "\n",
    "**Simple ReAct (Session 2):**\n",
    "```python\n",
    "while not done:\n",
    "    thought = llm.think(\"What next?\")\n",
    "    action = execute_tool(thought.action)\n",
    "    observation = observe(action)\n",
    "```\n",
    "\n",
    "**Production Workflows (This Session):**\n",
    "```python\n",
    "# Complex state management\n",
    "state = WorkflowState(\n",
    "    invoice_data={...},\n",
    "    validation_results={...},\n",
    "    business_context={...}\n",
    ")\n",
    "\n",
    "# Parallel execution\n",
    "async def validate_invoice(state):\n",
    "    vat_check, risk_check, terms_check = await asyncio.gather(\n",
    "        validate_vat(state),\n",
    "        check_vendor_risk(state), \n",
    "        verify_payment_terms(state)\n",
    "    )\n",
    "    return combine_results(vat_check, risk_check, terms_check)\n",
    "```\n",
    "\n",
    "### What LangGraph Brings to the Table\n",
    "\n",
    "**State Management:**\n",
    "- Type-safe state that flows through all nodes\n",
    "- Automatic state updates and merging\n",
    "- Built-in error and metadata tracking\n",
    "\n",
    "**Graph Architecture:**\n",
    "- Visual workflow definition\n",
    "- Conditional routing based on state\n",
    "- Parallel execution of independent steps\n",
    "\n",
    "**Production Features:**\n",
    "- Checkpointing for long-running workflows  \n",
    "- State history for auditing\n",
    "- Resumable workflows after interruption\n",
    "\n",
    "### The Business Case\n",
    "\n",
    "**Traditional Document Processing:**\n",
    "```\n",
    "Sequential: Extract → Validate → Check → Approve\n",
    "Time: 15 seconds per invoice\n",
    "Throughput: 4 invoices/minute\n",
    "```\n",
    "\n",
    "**LangGraph Workflow:**\n",
    "```\n",
    "Parallel: Extract → [Validate ∥ Check ∥ Verify] → Approve  \n",
    "Time: 6 seconds per invoice\n",
    "Throughput: 10 invoices/minute\n",
    "```\n",
    "\n",
    "Let's build this system step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download real invoice and receipt images first\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Dropbox shared link for the folder\n",
    "dropbox_url = \"https://www.dropbox.com/scl/fo/m9hyfmvi78snwv0nh34mo/AMEXxwXMLAOeve-_yj12ck8?rlkey=urinkikgiuven0fro7r4x5rcu&st=hv3of7g7&dl=1\"\n",
    "\n",
    "print(f\"Downloading real invoice data from: {dropbox_url}\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(dropbox_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Read the content as a zip file\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        # Extract all contents to a directory named 'downloaded_images'\n",
    "        z.extractall(\"downloaded_images\")\n",
    "\n",
    "    print(\"✅ Downloaded and extracted images to 'downloaded_images' folder.\")\n",
    "    \n",
    "    # List downloaded files\n",
    "    for root, dirs, files in os.walk(\"downloaded_images\"):\n",
    "        for file in files:\n",
    "            print(f\"  📄 {os.path.join(root, file)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error downloading images: {e}\")\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q langgraph langchain langchain-community\n",
    "\n",
    "# Configuration for course LLM server\n",
    "OLLAMA_URL = \"http://XX.XX.XX.XX\"  # Instructor provides\n",
    "API_TOKEN = \"YOUR_TOKEN_HERE\"\n",
    "MODEL = \"qwen3:8b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: State Design - The Foundation of Workflows\n",
    "\n",
    "### Understanding State in Agent Systems\n",
    "\n",
    "State is the data that flows through your workflow. Good state design is crucial:\n",
    "\n",
    "**Anti-Pattern - Global Variables:**\n",
    "```python\n",
    "# Bad: Global state is fragile\n",
    "vendor_name = None\n",
    "amount = None\n",
    "approval_status = None\n",
    "\n",
    "def process_invoice():\n",
    "    global vendor_name, amount, approval_status\n",
    "    # Dangerous: race conditions, hard to debug\n",
    "```\n",
    "\n",
    "**Pattern - Typed State Objects:**\n",
    "```python\n",
    "# Good: Typed, immutable, traceable\n",
    "@dataclass\n",
    "class InvoiceState:\n",
    "    invoice_id: str\n",
    "    vendor_name: Optional[str] = None\n",
    "    amount: Optional[float] = None\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "```\n",
    "\n",
    "### LangGraph State Architecture\n",
    "\n",
    "LangGraph uses TypedDict for state definition with automatic merging:\n",
    "\n",
    "```python\n",
    "class MyState(TypedDict):\n",
    "    # Required fields\n",
    "    invoice_id: str\n",
    "    \n",
    "    # Optional fields with defaults\n",
    "    amount: Optional[float]\n",
    "    errors: List[str]  # LangGraph handles list merging\n",
    "    \n",
    "    # Nested structures\n",
    "    validation_results: Dict[str, bool]\n",
    "```\n",
    "\n",
    "**How State Flows:**\n",
    "```\n",
    "Node A (input_state) → output_state_A\n",
    "                    ↓\n",
    "Node B (input_state + output_state_A) → output_state_B\n",
    "                                      ↓\n",
    "Node C (combined_state) → final_state\n",
    "```\n",
    "\n",
    "### Designing for Invoice Processing\n",
    "\n",
    "Our state needs to handle:\n",
    "- **Input data**: What we start with\n",
    "- **Extracted data**: What we discover\n",
    "- **Validation results**: What we verify\n",
    "- **Metadata**: How we got there\n",
    "\n",
    "Let's design state that supports complex workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Define our workflow state\n",
    "class InvoiceState(TypedDict):\n",
    "    # Input\n",
    "    invoice_id: str\n",
    "    raw_text: Optional[str]\n",
    "    \n",
    "    # Extracted data\n",
    "    vendor_name: Optional[str]\n",
    "    amount: Optional[float]\n",
    "    currency: Optional[str]\n",
    "    invoice_date: Optional[str]\n",
    "    due_date: Optional[str]\n",
    "    payment_terms: Optional[str]\n",
    "    vat_number: Optional[str]\n",
    "    line_items: Optional[List[Dict]]\n",
    "    \n",
    "    # Validation results\n",
    "    vat_valid: Optional[bool]\n",
    "    vendor_risk_score: Optional[float]\n",
    "    payment_terms_approved: Optional[bool]\n",
    "    \n",
    "    # Workflow metadata\n",
    "    errors: List[str]\n",
    "    warnings: List[str]\n",
    "    approval_status: Optional[str]  # 'approved', 'rejected', 'manual_review'\n",
    "    processing_time: Optional[float]\n",
    "    steps_executed: List[str]\n",
    "\n",
    "print(\"✅ State structure defined\")\n",
    "print(\"State tracks:\")\n",
    "print(\"- Invoice data (vendor, amount, dates)\")\n",
    "print(\"- Validation results (VAT, risk, terms)\")\n",
    "print(\"- Workflow metadata (errors, approval status)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Node Functions - Building Workflow Components\n",
    "\n",
    "### The Node Pattern in LangGraph\n",
    "\n",
    "Nodes are pure functions that transform state. They follow a consistent pattern:\n",
    "\n",
    "```python\n",
    "def my_node(state: MyState) -> MyState:\n",
    "    \"\"\"\n",
    "    Clear description of what this node does\n",
    "    \n",
    "    Args:\n",
    "        state: Current workflow state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with new information\n",
    "    \"\"\"\n",
    "    # 1. Extract needed data from state\n",
    "    invoice_id = state[\"invoice_id\"]\n",
    "    \n",
    "    # 2. Perform the work\n",
    "    result = do_processing(invoice_id)\n",
    "    \n",
    "    # 3. Update state (don't mutate, return new values)\n",
    "    state[\"new_field\"] = result\n",
    "    state[\"metadata\"][\"node_executed\"] = \"my_node\"\n",
    "    \n",
    "    # 4. Return the updated state\n",
    "    return state\n",
    "```\n",
    "\n",
    "### Node Design Principles\n",
    "\n",
    "**Single Responsibility:**\n",
    "```python\n",
    "# Good: Each node has one clear purpose\n",
    "def extract_vendor_info(state): ...\n",
    "def validate_vat_number(state): ...\n",
    "def check_payment_terms(state): ...\n",
    "\n",
    "# Bad: Node doing too much\n",
    "def process_everything(state): ...\n",
    "```\n",
    "\n",
    "**Error Handling:**\n",
    "```python\n",
    "def robust_node(state: MyState) -> MyState:\n",
    "    try:\n",
    "        # Core processing\n",
    "        result = risky_operation(state[\"data\"])\n",
    "        state[\"result\"] = result\n",
    "    except ValidationError as e:\n",
    "        state[\"errors\"].append(f\"Validation failed: {str(e)}\")\n",
    "    except TimeoutError:\n",
    "        state[\"warnings\"].append(\"Service timeout, using cached data\")\n",
    "        state[\"result\"] = get_cached_data(state[\"data\"])\n",
    "    except Exception as e:\n",
    "        state[\"errors\"].append(f\"Unexpected error: {str(e)}\")\n",
    "        \n",
    "    return state\n",
    "```\n",
    "\n",
    "### Parallel-Safe Nodes\n",
    "\n",
    "When nodes run in parallel, they must be independent:\n",
    "\n",
    "```python\n",
    "# ✅ Good: Independent operations\n",
    "def validate_vat(state):\n",
    "    # Only reads: vat_number\n",
    "    # Only writes: vat_valid, vat_errors\n",
    "    pass\n",
    "\n",
    "def check_vendor_risk(state):\n",
    "    # Only reads: vendor_name  \n",
    "    # Only writes: risk_score, risk_factors\n",
    "    pass\n",
    "\n",
    "# ❌ Bad: Conflicting writes\n",
    "def bad_node_a(state):\n",
    "    state[\"status\"] = \"processing_a\"  # Conflict!\n",
    "    \n",
    "def bad_node_b(state):\n",
    "    state[\"status\"] = \"processing_b\"  # Conflict!\n",
    "```\n",
    "\n",
    "Let's build our invoice processing nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Node 1: Extract invoice data\n",
    "def extract_invoice_data(state: InvoiceState) -> InvoiceState:\n",
    "    \"\"\"Extract structured data from invoice\"\"\"\n",
    "    print(\"📄 Extracting invoice data...\")\n",
    "    \n",
    "    # Simulate extraction (in production, would use OCR/NLP)\n",
    "    if state[\"invoice_id\"] == \"INV-2024-001\":\n",
    "        state[\"vendor_name\"] = \"TechSupplies Co.\"\n",
    "        state[\"amount\"] = 15000.00\n",
    "        state[\"currency\"] = \"USD\"\n",
    "        state[\"invoice_date\"] = \"2024-01-15\"\n",
    "        state[\"payment_terms\"] = \"Net 30\"\n",
    "        state[\"vat_number\"] = \"GB123456789\"\n",
    "        state[\"line_items\"] = [\n",
    "            {\"description\": \"Laptops\", \"quantity\": 5, \"unit_price\": 2000},\n",
    "            {\"description\": \"Software Licenses\", \"quantity\": 10, \"unit_price\": 500}\n",
    "        ]\n",
    "    else:\n",
    "        state[\"errors\"].append(f\"Invoice {state['invoice_id']} not found\")\n",
    "    \n",
    "    state[\"steps_executed\"].append(\"extract_data\")\n",
    "    return state\n",
    "\n",
    "# Node 2: Validate VAT\n",
    "def validate_vat(state: InvoiceState) -> InvoiceState:\n",
    "    \"\"\"Validate VAT number\"\"\"\n",
    "    print(\"🔍 Validating VAT number...\")\n",
    "    \n",
    "    if state[\"vat_number\"]:\n",
    "        # Simple validation (in production, use VIES API)\n",
    "        if state[\"vat_number\"].startswith(\"GB\") and len(state[\"vat_number\"]) == 11:\n",
    "            state[\"vat_valid\"] = True\n",
    "        else:\n",
    "            state[\"vat_valid\"] = False\n",
    "            state[\"warnings\"].append(\"VAT number format appears invalid\")\n",
    "    \n",
    "    state[\"steps_executed\"].append(\"validate_vat\")\n",
    "    return state\n",
    "\n",
    "# Node 3: Check vendor risk\n",
    "def check_vendor_risk(state: InvoiceState) -> InvoiceState:\n",
    "    \"\"\"Assess vendor risk score\"\"\"\n",
    "    print(\"📊 Checking vendor risk...\")\n",
    "    \n",
    "    # Simulate risk scoring\n",
    "    vendor_scores = {\n",
    "        \"TechSupplies Co.\": 0.2,  # Low risk\n",
    "        \"NewVendor Inc.\": 0.7,    # High risk\n",
    "        \"Unknown\": 0.9            # Very high risk\n",
    "    }\n",
    "    \n",
    "    state[\"vendor_risk_score\"] = vendor_scores.get(\n",
    "        state[\"vendor_name\"], \n",
    "        0.5  # Default medium risk\n",
    "    )\n",
    "    \n",
    "    if state[\"vendor_risk_score\"] > 0.6:\n",
    "        state[\"warnings\"].append(f\"High risk vendor (score: {state['vendor_risk_score']})\")\n",
    "    \n",
    "    state[\"steps_executed\"].append(\"check_vendor_risk\")\n",
    "    return state\n",
    "\n",
    "# Node 4: Verify payment terms\n",
    "def verify_payment_terms(state: InvoiceState) -> InvoiceState:\n",
    "    \"\"\"Check if payment terms align with policy\"\"\"\n",
    "    print(\"💰 Verifying payment terms...\")\n",
    "    \n",
    "    # Business rules\n",
    "    if state[\"payment_terms\"] == \"Net 30\":\n",
    "        state[\"payment_terms_approved\"] = True\n",
    "    elif state[\"payment_terms\"] == \"Net 60\" and state[\"amount\"] > 10000:\n",
    "        state[\"payment_terms_approved\"] = True\n",
    "    elif state[\"payment_terms\"] == \"Net 90\":\n",
    "        state[\"payment_terms_approved\"] = False\n",
    "        state[\"warnings\"].append(\"Net 90 requires CFO approval\")\n",
    "    else:\n",
    "        state[\"payment_terms_approved\"] = False\n",
    "    \n",
    "    # Calculate due date\n",
    "    if state[\"invoice_date\"] and state[\"payment_terms\"]:\n",
    "        days = int(state[\"payment_terms\"].split()[1])\n",
    "        invoice_date = datetime.strptime(state[\"invoice_date\"], \"%Y-%m-%d\")\n",
    "        due_date = invoice_date + timedelta(days=days)\n",
    "        state[\"due_date\"] = due_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    state[\"steps_executed\"].append(\"verify_payment_terms\")\n",
    "    return state\n",
    "\n",
    "# Node 5: Make approval decision\n",
    "def make_approval_decision(state: InvoiceState) -> InvoiceState:\n",
    "    \"\"\"Decide whether to approve, reject, or flag for review\"\"\"\n",
    "    print(\"✅ Making approval decision...\")\n",
    "    \n",
    "    # Decision logic\n",
    "    if state[\"errors\"]:\n",
    "        state[\"approval_status\"] = \"rejected\"\n",
    "    elif state[\"vendor_risk_score\"] and state[\"vendor_risk_score\"] > 0.8:\n",
    "        state[\"approval_status\"] = \"manual_review\"\n",
    "    elif not state[\"vat_valid\"]:\n",
    "        state[\"approval_status\"] = \"manual_review\"\n",
    "    elif not state[\"payment_terms_approved\"]:\n",
    "        state[\"approval_status\"] = \"manual_review\"\n",
    "    else:\n",
    "        state[\"approval_status\"] = \"approved\"\n",
    "    \n",
    "    state[\"steps_executed\"].append(\"make_decision\")\n",
    "    return state\n",
    "\n",
    "print(\"✅ All node functions created\")\n",
    "print(\"Nodes: extract → validate (parallel) → decision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Graph Construction - Connecting the Workflow\n",
    "\n",
    "### Graph Theory for Workflows\n",
    "\n",
    "LangGraph is based on directed graphs where:\n",
    "- **Nodes** = Processing steps\n",
    "- **Edges** = Data flow between steps\n",
    "- **Conditional Edges** = Dynamic routing based on state\n",
    "\n",
    "```python\n",
    "# Simple linear flow\n",
    "A → B → C → END\n",
    "\n",
    "# Parallel processing\n",
    "     B\n",
    "   ↗   ↘\n",
    "A       D → END\n",
    "   ↘   ↗\n",
    "     C\n",
    "\n",
    "# Conditional routing\n",
    "A → condition → {success: B, error: C} → END\n",
    "```\n",
    "\n",
    "### Edge Types in LangGraph\n",
    "\n",
    "**Regular Edges:**\n",
    "```python\n",
    "# Always go from node A to node B\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "```\n",
    "\n",
    "**Conditional Edges:**\n",
    "```python\n",
    "# Route based on state\n",
    "def router(state):\n",
    "    if state[\"errors\"]:\n",
    "        return \"error_handler\"\n",
    "    elif state[\"amount\"] > 10000:\n",
    "        return \"high_value_processor\" \n",
    "    else:\n",
    "        return \"standard_processor\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"decision_point\",\n",
    "    router,\n",
    "    {\n",
    "        \"error_handler\": \"handle_errors\",\n",
    "        \"high_value_processor\": \"process_high_value\",\n",
    "        \"standard_processor\": \"process_standard\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### Advanced Routing Patterns\n",
    "\n",
    "**Multi-condition Routing:**\n",
    "```python\n",
    "def complex_router(state):\n",
    "    # Multiple conditions\n",
    "    if state[\"errors\"]:\n",
    "        return \"error\"\n",
    "    elif state[\"manual_review_required\"]:\n",
    "        return \"human_review\" \n",
    "    elif state[\"risk_score\"] > 0.8:\n",
    "        return \"risk_assessment\"\n",
    "    else:\n",
    "        return \"auto_approve\"\n",
    "```\n",
    "\n",
    "**Fan-out/Fan-in:**\n",
    "```python\n",
    "# Fan-out: One node triggers multiple parallel nodes\n",
    "workflow.add_edge(\"extract\", \"validate_vat\")\n",
    "workflow.add_edge(\"extract\", \"check_vendor\")\n",
    "workflow.add_edge(\"extract\", \"verify_terms\")\n",
    "\n",
    "# Fan-in: Multiple nodes converge to one\n",
    "workflow.add_edge(\"validate_vat\", \"make_decision\")\n",
    "workflow.add_edge(\"check_vendor\", \"make_decision\")\n",
    "workflow.add_edge(\"verify_terms\", \"make_decision\")\n",
    "```\n",
    "\n",
    "### Graph Compilation and Optimization\n",
    "\n",
    "```python\n",
    "# Compile with optimizations\n",
    "app = workflow.compile()\n",
    "\n",
    "# Advanced compilation options\n",
    "app = workflow.compile(\n",
    "    checkpointer=memory_saver,      # State persistence\n",
    "    interrupt_before=[\"human_step\"], # Pause for human input\n",
    "    interrupt_after=[\"extract\"]     # Checkpoint after extraction\n",
    ")\n",
    "```\n",
    "\n",
    "Let's build our invoice processing graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(InvoiceState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"extract\", extract_invoice_data)\n",
    "workflow.add_node(\"validate_vat\", validate_vat)\n",
    "workflow.add_node(\"check_risk\", check_vendor_risk)\n",
    "workflow.add_node(\"verify_terms\", verify_payment_terms)\n",
    "workflow.add_node(\"decide\", make_approval_decision)\n",
    "\n",
    "# Define conditional routing\n",
    "def route_after_extraction(state: InvoiceState) -> str:\n",
    "    \"\"\"Route based on extraction results\"\"\"\n",
    "    if state[\"errors\"]:\n",
    "        return \"decide\"  # Skip validation if extraction failed\n",
    "    return \"continue\"\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"extract\")\n",
    "\n",
    "# Add edges (connections between nodes)\n",
    "workflow.add_conditional_edges(\n",
    "    \"extract\",\n",
    "    route_after_extraction,\n",
    "    {\n",
    "        \"continue\": \"validate_vat\",\n",
    "        \"decide\": \"decide\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parallel validation steps\n",
    "workflow.add_edge(\"validate_vat\", \"check_risk\")\n",
    "workflow.add_edge(\"check_risk\", \"verify_terms\")\n",
    "workflow.add_edge(\"verify_terms\", \"decide\")\n",
    "\n",
    "# End after decision\n",
    "workflow.add_edge(\"decide\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"✅ Workflow graph compiled\")\n",
    "print(\"Flow: Extract → Validate (3 checks) → Decision → End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Workflow Visualization - Understanding Your Graph\n",
    "\n",
    "### The Power of Visual Workflows\n",
    "\n",
    "Unlike traditional code, LangGraph workflows are visual. This helps with:\n",
    "\n",
    "**Development:**\n",
    "```python\n",
    "# Code is hard to understand\n",
    "if extraction_successful:\n",
    "    if parallel_validation_mode:\n",
    "        run_vat_validation()\n",
    "        run_risk_check()\n",
    "        run_terms_verification()\n",
    "    else:\n",
    "        run_sequential_validation()\n",
    "    \n",
    "    if all_validations_passed():\n",
    "        approve()\n",
    "    else:\n",
    "        manual_review()\n",
    "```\n",
    "\n",
    "**Visual Graph:**\n",
    "```\n",
    "┌─────────┐    ┌─────────┐\n",
    "│ Extract │────│Condition│\n",
    "└─────────┘    └────┬────┘\n",
    "                    │\n",
    "              ┌─────▼─────┐\n",
    "              │  Parallel │\n",
    "              │Validation │\n",
    "              └─────┬─────┘\n",
    "                    │\n",
    "              ┌─────▼─────┐\n",
    "              │  Decision │\n",
    "              └───────────┘\n",
    "```\n",
    "\n",
    "### Graph Analysis Benefits\n",
    "\n",
    "**Performance Optimization:**\n",
    "- Identify bottlenecks visually\n",
    "- See parallel execution opportunities\n",
    "- Understand data dependencies\n",
    "\n",
    "**Debugging:**\n",
    "- Trace execution paths\n",
    "- Identify where workflows fail\n",
    "- Understand state flow\n",
    "\n",
    "**Documentation:**\n",
    "- Workflows become self-documenting\n",
    "- Business stakeholders can understand flow\n",
    "- Compliance audits are easier\n",
    "\n",
    "### Graph Metrics\n",
    "\n",
    "LangGraph provides insights into your workflow:\n",
    "\n",
    "```python\n",
    "# Get graph statistics\n",
    "graph_info = app.get_graph()\n",
    "print(f\"Nodes: {len(graph_info.nodes)}\")\n",
    "print(f\"Edges: {len(graph_info.edges)}\")\n",
    "print(f\"Parallel paths: {count_parallel_paths(graph_info)}\")\n",
    "\n",
    "# Execution statistics  \n",
    "execution_stats = {\n",
    "    \"total_steps\": len(result[\"steps_executed\"]),\n",
    "    \"parallel_efficiency\": calculate_parallel_speedup(result),\n",
    "    \"bottleneck_node\": find_slowest_node(result)\n",
    "}\n",
    "```\n",
    "\n",
    "Let's visualize our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph (requires graphviz)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_png()))\n",
    "except:\n",
    "    print(\"Graphviz not available. Here's the text representation:\")\n",
    "    print(\"\\n📊 Workflow Structure:\")\n",
    "    print(\"┌─────────┐\")\n",
    "    print(\"│ Extract │\")\n",
    "    print(\"└────┬────┘\")\n",
    "    print(\"     │ (if success)\")\n",
    "    print(\"┌────▼────┐\")\n",
    "    print(\"│Validate │\")\n",
    "    print(\"│  VAT    │\")\n",
    "    print(\"└────┬────┘\")\n",
    "    print(\"┌────▼────┐\")\n",
    "    print(\"│ Check   │\")\n",
    "    print(\"│  Risk   │\")\n",
    "    print(\"└────┬────┘\")\n",
    "    print(\"┌────▼────┐\")\n",
    "    print(\"│ Verify  │\")\n",
    "    print(\"│ Terms   │\")\n",
    "    print(\"└────┬────┘\")\n",
    "    print(\"┌────▼────┐\")\n",
    "    print(\"│ Decide  │\")\n",
    "    print(\"└────┬────┘\")\n",
    "    print(\"     │\")\n",
    "    print(\"    END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Execution and State Flow\n",
    "\n",
    "### Understanding Workflow Execution\n",
    "\n",
    "When you run a LangGraph workflow, here's what happens:\n",
    "\n",
    "**Execution Model:**\n",
    "```python\n",
    "# 1. Initialize state\n",
    "initial_state = {\"invoice_id\": \"INV-001\", \"errors\": []}\n",
    "\n",
    "# 2. Execute graph\n",
    "for node in execution_order:\n",
    "    state = node(state)  # State accumulates data\n",
    "    \n",
    "# 3. State evolution\n",
    "# Step 1: {\"invoice_id\": \"INV-001\", \"errors\": []}\n",
    "# Step 2: {\"invoice_id\": \"INV-001\", \"errors\": [], \"vendor\": \"TechCorp\"}  \n",
    "# Step 3: {\"invoice_id\": \"INV-001\", \"errors\": [], \"vendor\": \"TechCorp\", \"amount\": 15000}\n",
    "```\n",
    "\n",
    "**State Merging:**\n",
    "```python\n",
    "# LangGraph automatically merges state updates\n",
    "def node_a(state):\n",
    "    return {\"field_a\": \"value_a\"}  # Only returns what changed\n",
    "\n",
    "def node_b(state):  \n",
    "    return {\"field_b\": \"value_b\"}  # Adds to existing state\n",
    "\n",
    "# Final state: {\"field_a\": \"value_a\", \"field_b\": \"value_b\", ...}\n",
    "```\n",
    "\n",
    "### Execution Patterns\n",
    "\n",
    "**Sequential Execution:**\n",
    "```python\n",
    "# Traditional: One after another\n",
    "result_1 = step_1(input)\n",
    "result_2 = step_2(result_1)  \n",
    "result_3 = step_3(result_2)\n",
    "# Total time: T1 + T2 + T3\n",
    "```\n",
    "\n",
    "**Parallel Execution:**\n",
    "```python\n",
    "# LangGraph: Independent steps run together\n",
    "result_1, result_2, result_3 = await asyncio.gather(\n",
    "    step_1(input),\n",
    "    step_2(input),\n",
    "    step_3(input)\n",
    ")\n",
    "# Total time: max(T1, T2, T3)\n",
    "```\n",
    "\n",
    "### Error Propagation\n",
    "\n",
    "**Error Handling Strategy:**\n",
    "```python\n",
    "def error_aware_node(state):\n",
    "    if state[\"errors\"]:\n",
    "        # Skip processing if previous errors\n",
    "        return state\n",
    "    \n",
    "    try:\n",
    "        # Normal processing\n",
    "        result = process_data(state[\"data\"])\n",
    "        state[\"result\"] = result\n",
    "    except Exception as e:\n",
    "        # Add error but continue workflow\n",
    "        state[\"errors\"].append(str(e))\n",
    "        state[\"result\"] = None\n",
    "    \n",
    "    return state\n",
    "```\n",
    "\n",
    "**Error Recovery Patterns:**\n",
    "```python\n",
    "def resilient_workflow(state):\n",
    "    # Attempt primary processing\n",
    "    if not state[\"errors\"]:\n",
    "        try:\n",
    "            return primary_processor(state)\n",
    "        except ServiceUnavailable:\n",
    "            state[\"warnings\"].append(\"Primary service down, using fallback\")\n",
    "            return fallback_processor(state)\n",
    "    \n",
    "    # Error path\n",
    "    return error_handler(state)\n",
    "```\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a valid invoice\n",
    "print(\"=\" * 60)\n",
    "print(\"PROCESSING INVOICE: INV-2024-001\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"invoice_id\": \"INV-2024-001\",\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "    \"steps_executed\": []\n",
    "}\n",
    "\n",
    "# Track execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the workflow\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "# Calculate processing time\n",
    "result[\"processing_time\"] = time.time() - start_time\n",
    "\n",
    "# Display results\n",
    "print(\"\\n📋 WORKFLOW RESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Invoice ID: {result['invoice_id']}\")\n",
    "print(f\"Vendor: {result.get('vendor_name', 'N/A')}\")\n",
    "print(f\"Amount: ${result.get('amount', 0):,.2f} {result.get('currency', '')}\")\n",
    "print(f\"Payment Terms: {result.get('payment_terms', 'N/A')}\")\n",
    "print(f\"Due Date: {result.get('due_date', 'N/A')}\")\n",
    "\n",
    "print(\"\\n✅ VALIDATION RESULTS:\")\n",
    "print(f\"VAT Valid: {result.get('vat_valid', False)}\")\n",
    "print(f\"Vendor Risk Score: {result.get('vendor_risk_score', 'N/A')}\")\n",
    "print(f\"Payment Terms Approved: {result.get('payment_terms_approved', False)}\")\n",
    "\n",
    "print(\"\\n🎯 FINAL DECISION:\")\n",
    "print(f\"Status: {result.get('approval_status', 'Unknown').upper()}\")\n",
    "\n",
    "if result[\"warnings\"]:\n",
    "    print(\"\\n⚠️ WARNINGS:\")\n",
    "    for warning in result[\"warnings\"]:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "print(\"\\n⏱️ PERFORMANCE:\")\n",
    "print(f\"Processing Time: {result['processing_time']:.2f} seconds\")\n",
    "print(f\"Steps Executed: {', '.join(result['steps_executed'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Error Handling and Edge Cases\n",
    "\n",
    "### Production-Grade Error Handling\n",
    "\n",
    "Real workflows need to handle failures gracefully. Here's how:\n",
    "\n",
    "**Graceful Degradation:**\n",
    "```python\n",
    "def robust_validation_node(state):\n",
    "    # Try primary validation\n",
    "    try:\n",
    "        primary_result = validate_with_external_api(state[\"data\"])\n",
    "        state[\"validation_result\"] = primary_result\n",
    "        state[\"validation_confidence\"] = \"high\"\n",
    "    except APITimeoutError:\n",
    "        # Fallback to local validation\n",
    "        fallback_result = validate_locally(state[\"data\"])\n",
    "        state[\"validation_result\"] = fallback_result\n",
    "        state[\"validation_confidence\"] = \"medium\"\n",
    "        state[\"warnings\"].append(\"External API timeout, used local validation\")\n",
    "    except APIRateLimitError:\n",
    "        # Queue for later processing\n",
    "        state[\"validation_result\"] = None\n",
    "        state[\"manual_review_required\"] = True\n",
    "        state[\"warnings\"].append(\"API rate limit, flagged for manual review\")\n",
    "    \n",
    "    return state\n",
    "```\n",
    "\n",
    "**Circuit Breaker Pattern:**\n",
    "```python\n",
    "class ServiceCircuitBreaker:\n",
    "    def __init__(self, failure_threshold=5, timeout=300):\n",
    "        self.failure_count = 0\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.last_failure_time = None\n",
    "        self.timeout = timeout\n",
    "    \n",
    "    def call_service(self, func, *args, **kwargs):\n",
    "        if self.is_circuit_open():\n",
    "            raise ServiceUnavailableError(\"Circuit breaker open\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self.on_success()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.on_failure()\n",
    "            raise\n",
    "```\n",
    "\n",
    "### Error Classification\n",
    "\n",
    "**Error Severity Levels:**\n",
    "```python\n",
    "def classify_error(error, state):\n",
    "    if isinstance(error, CriticalDataError):\n",
    "        # Stop processing immediately\n",
    "        state[\"approval_status\"] = \"rejected\"\n",
    "        state[\"errors\"].append(f\"Critical: {str(error)}\")\n",
    "        return \"stop_processing\"\n",
    "    \n",
    "    elif isinstance(error, ValidationWarning):\n",
    "        # Continue but flag for review\n",
    "        state[\"warnings\"].append(f\"Warning: {str(error)}\")\n",
    "        state[\"manual_review_required\"] = True\n",
    "        return \"continue_with_flag\"\n",
    "    \n",
    "    elif isinstance(error, ServiceTemporarilyUnavailable):\n",
    "        # Retry or use fallback\n",
    "        state[\"warnings\"].append(f\"Service issue: {str(error)}\")\n",
    "        return \"use_fallback\"\n",
    "    \n",
    "    else:\n",
    "        # Unknown error - be conservative\n",
    "        state[\"errors\"].append(f\"Unknown error: {str(error)}\")\n",
    "        return \"manual_review\"\n",
    "```\n",
    "\n",
    "### Retry and Backoff Strategies\n",
    "\n",
    "**Exponential Backoff:**\n",
    "```python\n",
    "import asyncio\n",
    "from functools import wraps\n",
    "\n",
    "def retry_with_backoff(max_retries=3, base_delay=1, backoff_factor=2):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    return await func(*args, **kwargs)\n",
    "                except RetryableError as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise\n",
    "                    \n",
    "                    delay = base_delay * (backoff_factor ** attempt)\n",
    "                    await asyncio.sleep(delay)\n",
    "            \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_with_backoff(max_retries=3)\n",
    "async def call_external_service(data):\n",
    "    # Service call that might fail\n",
    "    pass\n",
    "```\n",
    "\n",
    "Let's test our error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with non-existent invoice\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTING ERROR HANDLING: Non-existent Invoice\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "error_state = {\n",
    "    \"invoice_id\": \"INV-INVALID-999\",\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "    \"steps_executed\": []\n",
    "}\n",
    "\n",
    "error_result = app.invoke(error_state)\n",
    "\n",
    "print(\"\\n🔍 ERROR HANDLING RESULTS:\")\n",
    "print(f\"Approval Status: {error_result.get('approval_status', 'Unknown')}\")\n",
    "print(f\"Errors: {error_result['errors']}\")\n",
    "print(f\"Steps Executed: {error_result['steps_executed']}\")\n",
    "print(\"\\nNote: Workflow correctly skipped validation when extraction failed!\")\n",
    "\n",
    "# Test with high-risk vendor\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING EDGE CASE: High-Risk Vendor\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modify node to simulate high-risk vendor\n",
    "def high_risk_extract(state):\n",
    "    state[\"vendor_name\"] = \"Unknown Vendor\"\n",
    "    state[\"amount\"] = 50000\n",
    "    state[\"payment_terms\"] = \"Net 90\"\n",
    "    state[\"vat_number\"] = \"INVALID123\"\n",
    "    state[\"steps_executed\"].append(\"extract_data\")\n",
    "    return state\n",
    "\n",
    "# Create modified workflow for testing\n",
    "test_workflow = StateGraph(InvoiceState)\n",
    "test_workflow.add_node(\"extract\", high_risk_extract)\n",
    "test_workflow.add_node(\"validate_vat\", validate_vat)\n",
    "test_workflow.add_node(\"check_risk\", check_vendor_risk)\n",
    "test_workflow.add_node(\"verify_terms\", verify_payment_terms)\n",
    "test_workflow.add_node(\"decide\", make_approval_decision)\n",
    "\n",
    "test_workflow.set_entry_point(\"extract\")\n",
    "test_workflow.add_edge(\"extract\", \"validate_vat\")\n",
    "test_workflow.add_edge(\"validate_vat\", \"check_risk\")\n",
    "test_workflow.add_edge(\"check_risk\", \"verify_terms\")\n",
    "test_workflow.add_edge(\"verify_terms\", \"decide\")\n",
    "test_workflow.add_edge(\"decide\", END)\n",
    "\n",
    "test_app = test_workflow.compile()\n",
    "\n",
    "risk_state = {\n",
    "    \"invoice_id\": \"INV-RISKY-001\",\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "    \"steps_executed\": []\n",
    "}\n",
    "\n",
    "risk_result = test_app.invoke(risk_state)\n",
    "\n",
    "print(\"\\n🚨 HIGH-RISK RESULTS:\")\n",
    "print(f\"Vendor: {risk_result.get('vendor_name')}\")\n",
    "print(f\"Amount: ${risk_result.get('amount', 0):,.2f}\")\n",
    "print(f\"Risk Score: {risk_result.get('vendor_risk_score')}\")\n",
    "print(f\"Approval Status: {risk_result.get('approval_status').upper()}\")\n",
    "print(f\"Warnings: {risk_result['warnings']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Parallel Execution - Performance Optimization\n",
    "\n",
    "### Understanding Parallel Processing\n",
    "\n",
    "Traditional sequential processing is a bottleneck:\n",
    "\n",
    "**Sequential Bottleneck:**\n",
    "```python\n",
    "# Each step waits for the previous one\n",
    "def sequential_validation(invoice_data):\n",
    "    vat_result = validate_vat(invoice_data)      # 2 seconds\n",
    "    risk_result = check_vendor_risk(invoice_data) # 3 seconds  \n",
    "    terms_result = verify_terms(invoice_data)     # 1 second\n",
    "    return combine_results(vat_result, risk_result, terms_result)\n",
    "    # Total time: 6 seconds\n",
    "```\n",
    "\n",
    "**Parallel Optimization:**\n",
    "```python\n",
    "# Independent validations run simultaneously\n",
    "async def parallel_validation(invoice_data):\n",
    "    vat_task = asyncio.create_task(validate_vat(invoice_data))\n",
    "    risk_task = asyncio.create_task(check_vendor_risk(invoice_data))\n",
    "    terms_task = asyncio.create_task(verify_terms(invoice_data))\n",
    "    \n",
    "    vat_result, risk_result, terms_result = await asyncio.gather(\n",
    "        vat_task, risk_task, terms_task\n",
    "    )\n",
    "    return combine_results(vat_result, risk_result, terms_result)\n",
    "    # Total time: 3 seconds (limited by slowest task)\n",
    "```\n",
    "\n",
    "### LangGraph Parallel Patterns\n",
    "\n",
    "**Fan-out/Fan-in Architecture:**\n",
    "```python\n",
    "# One node triggers multiple parallel paths\n",
    "workflow.add_edge(\"extract_data\", \"validate_vat\")\n",
    "workflow.add_edge(\"extract_data\", \"check_risk\")  \n",
    "workflow.add_edge(\"extract_data\", \"verify_terms\")\n",
    "\n",
    "# All paths converge to decision node\n",
    "workflow.add_edge(\"validate_vat\", \"make_decision\")\n",
    "workflow.add_edge(\"check_risk\", \"make_decision\")\n",
    "workflow.add_edge(\"verify_terms\", \"make_decision\")\n",
    "\n",
    "# LangGraph automatically handles parallel execution\n",
    "```\n",
    "\n",
    "### Performance Considerations\n",
    "\n",
    "**When Parallel Processing Helps:**\n",
    "```python\n",
    "# ✅ Good: Independent operations\n",
    "def validate_vat(state):\n",
    "    # Only needs: vat_number\n",
    "    # External API call: 2 seconds\n",
    "    pass\n",
    "\n",
    "def check_vendor_risk(state):  \n",
    "    # Only needs: vendor_name\n",
    "    # Database lookup: 1 second\n",
    "    pass\n",
    "\n",
    "# ❌ Bad: Dependent operations  \n",
    "def step_a(state):\n",
    "    state[\"intermediate_result\"] = process_data()\n",
    "    \n",
    "def step_b(state):\n",
    "    # Needs intermediate_result from step_a\n",
    "    return analyze(state[\"intermediate_result\"])\n",
    "```\n",
    "\n",
    "**Resource Management:**\n",
    "```python\n",
    "# Monitor resource usage in parallel execution\n",
    "import concurrent.futures\n",
    "import psutil\n",
    "\n",
    "def monitor_parallel_execution():\n",
    "    cpu_before = psutil.cpu_percent()\n",
    "    memory_before = psutil.virtual_memory().percent\n",
    "    \n",
    "    # Run parallel tasks\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = [\n",
    "            executor.submit(validate_vat, state),\n",
    "            executor.submit(check_risk, state),\n",
    "            executor.submit(verify_terms, state)\n",
    "        ]\n",
    "        results = [future.result() for future in futures]\n",
    "    \n",
    "    cpu_after = psutil.cpu_percent()\n",
    "    memory_after = psutil.virtual_memory().percent\n",
    "    \n",
    "    print(f\"CPU increase: {cpu_after - cpu_before}%\")\n",
    "    print(f\"Memory increase: {memory_after - memory_before}%\")\n",
    "```\n",
    "\n",
    "### Parallel Execution Best Practices\n",
    "\n",
    "**State Isolation:**\n",
    "```python\n",
    "# Each parallel node should work on different parts of state\n",
    "def parallel_safe_node(state):\n",
    "    # ✅ Good: Read shared data, write to own namespace\n",
    "    shared_data = state[\"invoice_data\"]\n",
    "    my_result = process(shared_data)\n",
    "    \n",
    "    # Write to isolated key\n",
    "    state[\"my_node_result\"] = my_result\n",
    "    return state\n",
    "```\n",
    "\n",
    "Let's implement high-performance parallel processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "import asyncio\n",
    "\n",
    "# Create parallel validation workflow\n",
    "parallel_workflow = StateGraph(InvoiceState)\n",
    "\n",
    "# Add nodes\n",
    "parallel_workflow.add_node(\"extract\", extract_invoice_data)\n",
    "parallel_workflow.add_node(\"validate_vat\", validate_vat)\n",
    "parallel_workflow.add_node(\"check_risk\", check_vendor_risk)\n",
    "parallel_workflow.add_node(\"verify_terms\", verify_payment_terms)\n",
    "parallel_workflow.add_node(\"decide\", make_approval_decision)\n",
    "\n",
    "# Set entry point\n",
    "parallel_workflow.set_entry_point(\"extract\")\n",
    "\n",
    "# Create parallel validation after extraction\n",
    "# All three validation nodes run simultaneously\n",
    "parallel_workflow.add_edge(\"extract\", \"validate_vat\")\n",
    "parallel_workflow.add_edge(\"extract\", \"check_risk\")\n",
    "parallel_workflow.add_edge(\"extract\", \"verify_terms\")\n",
    "\n",
    "# All validation nodes lead to decision\n",
    "parallel_workflow.add_edge(\"validate_vat\", \"decide\")\n",
    "parallel_workflow.add_edge(\"check_risk\", \"decide\")\n",
    "parallel_workflow.add_edge(\"verify_terms\", \"decide\")\n",
    "\n",
    "parallel_workflow.add_edge(\"decide\", END)\n",
    "\n",
    "# Compile parallel workflow\n",
    "parallel_app = parallel_workflow.compile()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARALLEL EXECUTION DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run parallel workflow\n",
    "parallel_state = {\n",
    "    \"invoice_id\": \"INV-2024-001\",\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "    \"steps_executed\": []\n",
    "}\n",
    "\n",
    "print(\"\\n🚀 Running validations in PARALLEL...\")\n",
    "start = time.time()\n",
    "parallel_result = parallel_app.invoke(parallel_state)\n",
    "parallel_time = time.time() - start\n",
    "\n",
    "print(\"\\n⚡ PARALLEL EXECUTION COMPLETE!\")\n",
    "print(f\"Time: {parallel_time:.2f} seconds\")\n",
    "print(f\"Steps executed: {parallel_result['steps_executed']}\")\n",
    "print(\"\\nNote: All three validations ran simultaneously!\")\n",
    "print(\"This is much faster than sequential execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: State Persistence and Checkpointing\n",
    "\n",
    "### Why Persistence Matters\n",
    "\n",
    "Production workflows need to handle interruptions:\n",
    "\n",
    "**Common Scenarios:**\n",
    "```python\n",
    "# Long-running workflow scenarios\n",
    "scenarios = [\n",
    "    \"Human approval step takes 2 hours\",\n",
    "    \"External service is down for maintenance\", \n",
    "    \"System restart during processing\",\n",
    "    \"Workflow needs debugging at specific step\",\n",
    "    \"Compliance audit requires state history\"\n",
    "]\n",
    "```\n",
    "\n",
    "**Without Persistence:**\n",
    "```python\n",
    "# Bad: Lost work on interruption\n",
    "def fragile_workflow():\n",
    "    step1_result = expensive_computation()    # 10 minutes\n",
    "    step2_result = external_api_call()        # 5 minutes\n",
    "    # System crash here = lose 15 minutes of work\n",
    "    step3_result = final_processing()\n",
    "```\n",
    "\n",
    "**With LangGraph Checkpointing:**\n",
    "```python\n",
    "# Good: Resumable workflows\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Automatic state saving at each step\n",
    "config = {\"configurable\": {\"thread_id\": \"invoice-001\"}}\n",
    "result = app.invoke(initial_state, config)\n",
    "\n",
    "# Can resume from any point\n",
    "resumed_result = app.invoke(None, config)  # Continues from last checkpoint\n",
    "```\n",
    "\n",
    "### Checkpoint Strategies\n",
    "\n",
    "**Step-by-Step Checkpointing:**\n",
    "```python\n",
    "# Save after each critical step\n",
    "workflow.add_node(\"extract\", extract_data)        # Checkpoint 1\n",
    "workflow.add_node(\"validate\", validate_data)      # Checkpoint 2  \n",
    "workflow.add_node(\"approve\", approval_decision)   # Checkpoint 3\n",
    "\n",
    "# If failure at step 3, resume from checkpoint 2\n",
    "```\n",
    "\n",
    "**Conditional Checkpointing:**\n",
    "```python\n",
    "# Only checkpoint before expensive operations\n",
    "def should_checkpoint(state):\n",
    "    return (\n",
    "        state.get(\"requires_human_approval\") or\n",
    "        state.get(\"expensive_operation_next\") or\n",
    "        state.get(\"external_dependency\")\n",
    "    )\n",
    "\n",
    "if should_checkpoint(state):\n",
    "    app.save_checkpoint(state, thread_id)\n",
    "```\n",
    "\n",
    "### State History and Auditing\n",
    "\n",
    "**Audit Trail Generation:**\n",
    "```python\n",
    "def generate_audit_trail(thread_id):\n",
    "    \"\"\"Create compliance audit trail\"\"\"\n",
    "    history = app.get_state_history({\"configurable\": {\"thread_id\": thread_id}})\n",
    "    \n",
    "    audit_trail = []\n",
    "    for i, state_snapshot in enumerate(history):\n",
    "        audit_trail.append({\n",
    "            \"step\": i + 1,\n",
    "            \"timestamp\": state_snapshot.created_at,\n",
    "            \"node\": state_snapshot.metadata.get(\"source\", \"unknown\"),\n",
    "            \"data_changes\": calculate_diff(previous_state, state_snapshot.values),\n",
    "            \"user\": state_snapshot.metadata.get(\"user\", \"system\"),\n",
    "            \"approval_status\": state_snapshot.values.get(\"approval_status\")\n",
    "        })\n",
    "    \n",
    "    return audit_trail\n",
    "```\n",
    "\n",
    "### Production Persistence Patterns\n",
    "\n",
    "**Database Checkpointing:**\n",
    "```python\n",
    "from langgraph.checkpoint import SqliteSaver\n",
    "\n",
    "# Production: Use PostgreSQL/MySQL\n",
    "sqlite_saver = SqliteSaver.from_conn_string(\"sqlite:///checkpoints.db\")\n",
    "app = workflow.compile(checkpointer=sqlite_saver)\n",
    "\n",
    "# Automatic persistence to database\n",
    "config = {\"configurable\": {\"thread_id\": \"invoice-001\"}}\n",
    "app.invoke(state, config)  # Saved to database\n",
    "```\n",
    "\n",
    "**Human-in-the-Loop Workflows:**\n",
    "```python\n",
    "# Pause before human approval steps\n",
    "app = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human_approval\"]  # Pause here\n",
    ")\n",
    "\n",
    "# Run until human step\n",
    "result = app.invoke(state, config)\n",
    "print(\"Waiting for human approval...\")\n",
    "\n",
    "# Human provides input\n",
    "human_decision = get_human_approval()\n",
    "updated_state = result.copy()\n",
    "updated_state[\"human_decision\"] = human_decision\n",
    "\n",
    "# Continue from where we left off\n",
    "final_result = app.invoke(updated_state, config)\n",
    "```\n",
    "\n",
    "Let's implement persistent workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint import MemorySaver\n",
    "\n",
    "# Create workflow with checkpointing\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile with checkpointer\n",
    "checkpointed_app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINTING DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run with thread ID for tracking\n",
    "config = {\"configurable\": {\"thread_id\": \"invoice-001\"}}\n",
    "\n",
    "checkpoint_state = {\n",
    "    \"invoice_id\": \"INV-2024-001\",\n",
    "    \"errors\": [],\n",
    "    \"warnings\": [],\n",
    "    \"steps_executed\": []\n",
    "}\n",
    "\n",
    "# Run workflow\n",
    "print(\"\\n📁 Running workflow with checkpointing...\")\n",
    "result_with_checkpoint = checkpointed_app.invoke(checkpoint_state, config)\n",
    "\n",
    "# Get state history\n",
    "print(\"\\n📜 State History:\")\n",
    "for state in checkpointed_app.get_state_history(config):\n",
    "    if state.values:\n",
    "        print(f\"  Step: {state.values.get('steps_executed', [])} \")\n",
    "        print(f\"  Status: {state.values.get('approval_status', 'processing')}\")\n",
    "    break  # Just show latest for demo\n",
    "\n",
    "print(\"\\n✅ Workflow state saved and can be resumed!\")\n",
    "print(\"This is useful for:\")\n",
    "print(\"- Long-running workflows\")\n",
    "print(\"- Human-in-the-loop approval steps\")\n",
    "print(\"- Debugging and auditing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Learnings\n",
    "\n",
    "### The LangGraph Revolution\n",
    "\n",
    "**From Code to Graphs:**\n",
    "```python\n",
    "# Traditional: Imperative programming\n",
    "def process_invoice(invoice_id):\n",
    "    data = extract(invoice_id)\n",
    "    if data.valid:\n",
    "        parallel_validate(data)\n",
    "        if all_checks_pass():\n",
    "            return approve()\n",
    "    return reject()\n",
    "\n",
    "# LangGraph: Declarative workflow\n",
    "workflow = StateGraph(InvoiceState)\n",
    "workflow.add_node(\"extract\", extract_data)\n",
    "workflow.add_conditional_edges(\"extract\", route_validation)\n",
    "workflow.add_parallel_validation_nodes()\n",
    "app = workflow.compile()\n",
    "```\n",
    "\n",
    "### Core LangGraph Concepts\n",
    "\n",
    "**State Management:**\n",
    "- TypedDict defines data flow structure\n",
    "- Automatic state merging across nodes\n",
    "- Immutable state updates prevent race conditions\n",
    "- Built-in error and metadata tracking\n",
    "\n",
    "**Graph Architecture:**\n",
    "- Visual workflow representation\n",
    "- Conditional routing based on state\n",
    "- Parallel execution for independent steps\n",
    "- Fan-out/fan-in patterns for complex flows\n",
    "\n",
    "**Production Features:**\n",
    "- Checkpointing for workflow persistence\n",
    "- State history for audit trails\n",
    "- Human-in-the-loop capabilities\n",
    "- Error recovery and graceful degradation\n",
    "\n",
    "### Performance Benefits\n",
    "\n",
    "**Parallel Processing:**\n",
    "```python\n",
    "# Sequential: 6 seconds total\n",
    "validate_vat()      # 2 seconds\n",
    "check_risk()        # 3 seconds  \n",
    "verify_terms()      # 1 second\n",
    "\n",
    "# Parallel: 3 seconds total (max of all)\n",
    "await asyncio.gather(\n",
    "    validate_vat(),\n",
    "    check_risk(),\n",
    "    verify_terms()\n",
    ")\n",
    "# 50% performance improvement\n",
    "```\n",
    "\n",
    "**Resource Optimization:**\n",
    "- CPU cores utilized efficiently\n",
    "- I/O operations don't block each other\n",
    "- Memory usage optimized through state management\n",
    "- Bottleneck identification through graph analysis\n",
    "\n",
    "### When to Use LangGraph\n",
    "\n",
    "**Perfect For:**\n",
    "- Multi-step workflows with dependencies\n",
    "- Processes requiring human approval\n",
    "- Long-running operations needing persistence\n",
    "- Complex business logic with conditional paths\n",
    "- Systems requiring audit trails\n",
    "\n",
    "**Consider Alternatives For:**\n",
    "- Simple linear transformations\n",
    "- Real-time sub-second operations  \n",
    "- Stateless functions\n",
    "- Workflows that never need interruption\n",
    "\n",
    "### Architecture Patterns\n",
    "\n",
    "**Fan-out/Fan-in:**\n",
    "```\n",
    "Extract → [Validate ∥ Check ∥ Verify] → Decide\n",
    "```\n",
    "\n",
    "**Conditional Routing:**\n",
    "```\n",
    "Extract → Condition → {High-Value, Standard, Error} → Process\n",
    "```\n",
    "\n",
    "**Human-in-the-Loop:**\n",
    "```\n",
    "Auto-Process → Human-Review → Continue/Reject → Complete\n",
    "```\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "✅ **State Design**: Type-safe, comprehensive state schema  \n",
    "✅ **Error Handling**: Graceful degradation and recovery  \n",
    "✅ **Performance**: Parallel execution where possible  \n",
    "✅ **Persistence**: Checkpointing for long operations  \n",
    "✅ **Monitoring**: State history and audit trails  \n",
    "✅ **Security**: Input validation and authorization  \n",
    "\n",
    "### Next Steps: Integration and Deployment\n",
    "\n",
    "In the next sessions, we'll explore:\n",
    "- **Real OCR Integration**: Replace mock data with actual document processing\n",
    "- **LLM-Powered Decisions**: Add intelligent reasoning to approval logic\n",
    "- **API Integration**: Connect to external systems and databases\n",
    "- **Production Deployment**: Scale workflows for enterprise use\n",
    "- **Monitoring and Observability**: Track performance and errors in production\n",
    "\n",
    "The foundation we've built with LangGraph will support all these advanced capabilities!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
