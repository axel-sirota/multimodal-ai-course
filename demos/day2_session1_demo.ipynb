{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2, Session 1: Parallelization & Concurrency\n",
    "\n",
    "## From Sequential to Concurrent Processing\n",
    "\n",
    "Yesterday we built intelligent routing systems that process invoices step-by-step:\n",
    "1. Analyze document â†’ 2. Verify vendor â†’ 3. Validate address â†’ 4. Convert currency â†’ 5. Validate tax\n",
    "\n",
    "But why wait? Many operations can run **simultaneously**:\n",
    "- Vendor verification and address validation are independent\n",
    "- Currency detection and tax jurisdiction lookup can happen in parallel\n",
    "- Multiple validation rules can execute concurrently\n",
    "\n",
    "**Today we unlock the power of parallelization.**\n",
    "\n",
    "### What We're Building\n",
    "\n",
    "A concurrent invoice processing system that:\n",
    "1. **Parallelizes** independent verification tasks\n",
    "2. **Synchronizes** dependent operations efficiently\n",
    "3. **Aggregates** results from multiple concurrent nodes\n",
    "4. **Handles** failures gracefully in parallel execution\n",
    "5. **Optimizes** processing time through smart concurrency\n",
    "\n",
    "This reduces processing time from **15 seconds to 3 seconds** per invoice.\n",
    "\n",
    "**Duration: 25 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup and API key loading\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, List, Optional, Any, TypedDict, Callable\n",
    "import json\n",
    "from datetime import datetime\n",
    "import threading\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration from previous sessions\n",
    "SERPER_API_KEY = os.getenv('SERPER_API_KEY', 'your_serper_api_key_here')\n",
    "GOOGLE_MAPS_API_KEY = os.getenv('GOOGLE_MAPS_API_KEY', 'your_google_maps_api_key_here')\n",
    "OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://XX.XX.XX.XX')\n",
    "OLLAMA_API_TOKEN = os.getenv('OLLAMA_API_TOKEN', 'YOUR_TOKEN_HERE')\n",
    "DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'qwen3:8b')\n",
    "\n",
    "print(\"âš¡ Parallelization & Concurrency Setup\")\n",
    "print(f\"   ðŸ”— External APIs: {'âœ… Configured' if SERPER_API_KEY != 'your_serper_api_key_here' else 'âŒ Mock mode'}\")\n",
    "print(f\"   ðŸ§  LLM Server: {'âœ… Configured' if OLLAMA_URL != 'http://XX.XX.XX.XX' else 'âŒ Mock mode'}\")\nprint(f\"   âš¡ Concurrency: ThreadPoolExecutor + AsyncIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q requests python-dotenv\n",
    "!pip install -q langgraph pydantic\n",
    "!pip install -q aiohttp asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import aiohttp\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from langgraph.graph import StateGraph, END\n",
    "import re\n",
    "\n",
    "# Performance tracking\n",
    "class PerformanceTracker:\n",
    "    \"\"\"Track execution times for performance analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.timings = {}\n",
    "        self.concurrent_operations = {}\n",
    "        self.thread_safety_lock = threading.Lock()\n",
    "    \n",
    "    def start_operation(self, operation_name: str, execution_type: str = \"sequential\"):\n",
    "        \"\"\"Start timing an operation\"\"\"\n",
    "        with self.thread_safety_lock:\n",
    "            self.timings[operation_name] = {\n",
    "                'start': time.time(),\n",
    "                'type': execution_type\n",
    "            }\n",
    "    \n",
    "    def end_operation(self, operation_name: str) -> float:\n",
    "        \"\"\"End timing an operation and return duration\"\"\"\n",
    "        with self.thread_safety_lock:\n",
    "            if operation_name in self.timings:\n",
    "                duration = time.time() - self.timings[operation_name]['start']\n",
    "                self.timings[operation_name]['duration'] = duration\n",
    "                return duration\n",
    "            return 0.0\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get performance analysis\"\"\"\n",
    "        with self.thread_safety_lock:\n",
    "            sequential_total = sum(\n",
    "                timing.get('duration', 0) \n",
    "                for timing in self.timings.values() \n",
    "                if timing.get('type') == 'sequential'\n",
    "            )\n",
    "            \n",
    "            concurrent_max = max(\n",
    "                (timing.get('duration', 0) \n",
    "                 for timing in self.timings.values() \n",
    "                 if timing.get('type') == 'concurrent'),\n",
    "                default=0.0\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'sequential_total': sequential_total,\n",
    "                'concurrent_max': concurrent_max,\n",
    "                'speedup_factor': sequential_total / max(concurrent_max, 0.1),\n",
    "                'operations': len(self.timings),\n",
    "                'details': self.timings\n",
    "            }\n",
    "\n",
    "# Global performance tracker\n",
    "perf_tracker = PerformanceTracker()\n",
    "\n",
    "print(\"ðŸ“Š Performance tracking initialized\")\n",
    "print(\"ðŸ”€ Thread-safe concurrent execution ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understanding Concurrency Opportunities\n",
    "\n",
    "First, let's analyze our current sequential workflow to identify parallelization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential workflow analysis\n",
    "class WorkflowAnalyzer:\n",
    "    \"\"\"Analyze workflow dependencies to identify parallelization opportunities\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.operations = {\n",
    "            'document_analysis': {\n",
    "                'dependencies': [],\n",
    "                'avg_time': 2.5,\n",
    "                'description': 'LLM-powered document complexity analysis'\n",
    "            },\n",
    "            'vendor_verification': {\n",
    "                'dependencies': ['document_analysis'],  # Needs vendor name from doc\n",
    "                'avg_time': 3.2,\n",
    "                'description': 'Web search for vendor legitimacy'\n",
    "            },\n",
    "            'address_validation': {\n",
    "                'dependencies': ['vendor_verification'],  # Gets address from vendor search\n",
    "                'avg_time': 1.8,\n",
    "                'description': 'Google Maps address validation'\n",
    "            },\n",
    "            'currency_detection': {\n",
    "                'dependencies': ['document_analysis'],  # Needs document text\n",
    "                'avg_time': 0.5,\n",
    "                'description': 'Extract currency from document'\n",
    "            },\n",
    "            'currency_conversion': {\n",
    "                'dependencies': ['currency_detection'],\n",
    "                'avg_time': 1.2,\n",
    "                'description': 'Real-time exchange rate conversion'\n",
    "            },\n",
    "            'tax_jurisdiction': {\n",
    "                'dependencies': ['address_validation'],  # Needs location for tax rules\n",
    "                'avg_time': 0.8,\n",
    "                'description': 'Determine tax jurisdiction from address'\n",
    "            },\n",
    "            'tax_validation': {\n",
    "                'dependencies': ['tax_jurisdiction', 'document_analysis'],\n",
    "                'avg_time': 1.1,\n",
    "                'description': 'Validate tax calculations'\n",
    "            },\n",
    "            'risk_calculation': {\n",
    "                'dependencies': ['vendor_verification', 'address_validation', 'tax_validation'],\n",
    "                'avg_time': 0.9,\n",
    "                'description': 'Calculate overall risk score'\n",
    "            },\n",
    "            'final_decision': {\n",
    "                'dependencies': ['risk_calculation'],\n",
    "                'avg_time': 0.3,\n",
    "                'description': 'Make approval/rejection decision'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_sequential_execution(self) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate total sequential execution time\"\"\"\n",
    "        total_time = sum(op['avg_time'] for op in self.operations.values())\n",
    "        critical_path = self._find_critical_path()\n",
    "        \n",
    "        return {\n",
    "            'total_sequential_time': total_time,\n",
    "            'critical_path': critical_path,\n",
    "            'critical_path_time': sum(self.operations[op]['avg_time'] for op in critical_path),\n",
    "            'parallelizable_operations': self._find_parallelizable_groups()\n",
    "        }\n",
    "    \n",
    "    def _find_critical_path(self) -> List[str]:\n",
    "        \"\"\"Find the longest dependency chain (critical path)\"\"\"\n",
    "        def get_path_time(operation, visited=None):\n",
    "            if visited is None:\n",
    "                visited = set()\n",
    "            \n",
    "            if operation in visited:\n",
    "                return 0, []\n",
    "            \n",
    "            visited.add(operation)\n",
    "            op_data = self.operations[operation]\n",
    "            \n",
    "            if not op_data['dependencies']:\n",
    "                return op_data['avg_time'], [operation]\n",
    "            \n",
    "            max_time = 0\n",
    "            best_path = []\n",
    "            \n",
    "            for dep in op_data['dependencies']:\n",
    "                dep_time, dep_path = get_path_time(dep, visited.copy())\n",
    "                if dep_time > max_time:\n",
    "                    max_time = dep_time\n",
    "                    best_path = dep_path\n",
    "            \n",
    "            return max_time + op_data['avg_time'], best_path + [operation]\n",
    "        \n",
    "        # Find the operation with the longest path\n",
    "        longest_path = []\n",
    "        max_time = 0\n",
    "        \n",
    "        for operation in self.operations:\n",
    "            time_val, path = get_path_time(operation)\n",
    "            if time_val > max_time:\n",
    "                max_time = time_val\n",
    "                longest_path = path\n",
    "        \n",
    "        return longest_path\n",
    "    \n",
    "    def _find_parallelizable_groups(self) -> List[List[str]]:\n",
    "        \"\"\"Find groups of operations that can run in parallel\"\"\"\n",
    "        # Operations that can run in parallel after document_analysis\n",
    "        parallel_groups = []\n",
    "        \n",
    "        # Group 1: After document analysis\n",
    "        group1 = ['vendor_verification', 'currency_detection']\n",
    "        parallel_groups.append(group1)\n",
    "        \n",
    "        # Group 2: After vendor verification completes\n",
    "        group2 = ['address_validation', 'currency_conversion']  # currency_conversion depends only on currency_detection\n",
    "        parallel_groups.append(group2)\n",
    "        \n",
    "        return parallel_groups\n",
    "    \n",
    "    def visualize_workflow(self):\n",
    "        \"\"\"Print a visual representation of the workflow\"\"\"\n",
    "        print(\"ðŸ“Š WORKFLOW DEPENDENCY ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for operation, data in self.operations.items():\n",
    "            deps = \" â† \" + \", \".join(data['dependencies']) if data['dependencies'] else \" (Root)\"\n",
    "            print(f\"{operation:20} ({data['avg_time']:.1f}s){deps}\")\n",
    "        \n",
    "        analysis = self.analyze_sequential_execution()\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ PERFORMANCE ANALYSIS:\")\n",
    "        print(f\"   Sequential Total: {analysis['total_sequential_time']:.1f} seconds\")\n",
    "        print(f\"   Critical Path: {' â†’ '.join(analysis['critical_path'])}\")\n",
    "        print(f\"   Critical Path Time: {analysis['critical_path_time']:.1f} seconds\")\n",
    "        print(f\"   Theoretical Speedup: {analysis['total_sequential_time']/analysis['critical_path_time']:.1f}x\")\n",
    "        \n",
    "        print(f\"\\nðŸ”€ PARALLELIZATION OPPORTUNITIES:\")\n",
    "        for i, group in enumerate(analysis['parallelizable_operations'], 1):\n",
    "            print(f\"   Group {i}: {', '.join(group)} (can run simultaneously)\")\n",
    "\n",
    "# Analyze current workflow\n",
    "analyzer = WorkflowAnalyzer()\n",
    "analyzer.visualize_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concurrent Execution Framework\n",
    "\n",
    "Build a framework for executing independent operations in parallel while respecting dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcurrentOperation:\n",
    "    \"\"\"Wrapper for operations that can be executed concurrently\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, func: Callable, dependencies: List[str] = None):\n",
    "        self.name = name\n",
    "        self.func = func\n",
    "        self.dependencies = dependencies or []\n",
    "        self.result = None\n",
    "        self.error = None\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.status = \"pending\"  # pending, running, completed, failed\n",
    "    \n",
    "    def can_execute(self, completed_operations: set) -> bool:\n",
    "        \"\"\"Check if all dependencies are satisfied\"\"\"\n",
    "        return all(dep in completed_operations for dep in self.dependencies)\n",
    "    \n",
    "    async def execute(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Execute the operation asynchronously\"\"\"\n",
    "        self.status = \"running\"\n",
    "        self.start_time = time.time()\n",
    "        perf_tracker.start_operation(self.name, \"concurrent\")\n",
    "        \n",
    "        try:\n",
    "            # Execute in thread pool to handle blocking operations\n",
    "            loop = asyncio.get_event_loop()\n",
    "            with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "                self.result = await loop.run_in_executor(executor, self.func, context)\n",
    "            \n",
    "            self.status = \"completed\"\n",
    "            self.end_time = time.time()\n",
    "            perf_tracker.end_operation(self.name)\n",
    "            \n",
    "            return self.result\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.error = str(e)\n",
    "            self.status = \"failed\"\n",
    "            self.end_time = time.time()\n",
    "            perf_tracker.end_operation(self.name)\n",
    "            raise\n",
    "    \n",
    "    @property\n",
    "    def duration(self) -> float:\n",
    "        \"\"\"Get execution duration\"\"\"\n",
    "        if self.start_time and self.end_time:\n",
    "            return self.end_time - self.start_time\n",
    "        return 0.0\n",
    "\n",
    "class ConcurrentExecutor:\n",
    "    \"\"\"Execute operations concurrently while respecting dependencies\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = 4):\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.operations = {}\n",
    "        self.execution_log = []\n",
    "    \n",
    "    def add_operation(self, operation: ConcurrentOperation):\n",
    "        \"\"\"Add an operation to the execution plan\"\"\"\n",
    "        self.operations[operation.name] = operation\n",
    "    \n",
    "    async def execute_all(self, initial_context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute all operations respecting dependencies and concurrency limits\"\"\"\n",
    "        context = initial_context.copy()\n",
    "        completed_operations = set()\n",
    "        running_tasks = {}\n",
    "        \n",
    "        print(f\"ðŸš€ Starting concurrent execution with max {self.max_concurrent} parallel operations\")\n",
    "        print(f\"ðŸ“‹ Total operations to execute: {len(self.operations)}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        while completed_operations != set(self.operations.keys()):\n",
    "            # Find operations ready to execute\n",
    "            ready_operations = [\n",
    "                op for op in self.operations.values()\n",
    "                if (op.status == \"pending\" and \n",
    "                    op.can_execute(completed_operations) and\n",
    "                    op.name not in running_tasks)\n",
    "            ]\n",
    "            \n",
    "            # Start new operations up to concurrency limit\n",
    "            while (ready_operations and \n",
    "                   len(running_tasks) < self.max_concurrent):\n",
    "                \n",
    "                operation = ready_operations.pop(0)\n",
    "                print(f\"âš¡ Starting: {operation.name}\")\n",
    "                \n",
    "                task = asyncio.create_task(operation.execute(context))\n",
    "                running_tasks[operation.name] = task\n",
    "            \n",
    "            # Wait for at least one operation to complete\n",
    "            if running_tasks:\n",
    "                done, pending = await asyncio.wait(\n",
    "                    running_tasks.values(), \n",
    "                    return_when=asyncio.FIRST_COMPLETED\n",
    "                )\n",
    "                \n",
    "                # Process completed operations\n",
    "                for task in done:\n",
    "                    # Find which operation completed\n",
    "                    for op_name, op_task in list(running_tasks.items()):\n",
    "                        if op_task == task:\n",
    "                            operation = self.operations[op_name]\n",
    "                            \n",
    "                            try:\n",
    "                                result = await task\n",
    "                                context[op_name] = result\n",
    "                                completed_operations.add(op_name)\n",
    "                                \n",
    "                                print(f\"âœ… Completed: {op_name} ({operation.duration:.2f}s)\")\n",
    "                                \n",
    "                                self.execution_log.append({\n",
    "                                    'operation': op_name,\n",
    "                                    'status': 'completed',\n",
    "                                    'duration': operation.duration,\n",
    "                                    'timestamp': time.time()\n",
    "                                })\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"âŒ Failed: {op_name} - {e}\")\n",
    "                                self.execution_log.append({\n",
    "                                    'operation': op_name,\n",
    "                                    'status': 'failed',\n",
    "                                    'error': str(e),\n",
    "                                    'timestamp': time.time()\n",
    "                                })\n",
    "                            \n",
    "                            del running_tasks[op_name]\n",
    "                            break\n",
    "            \n",
    "            # Small delay to prevent busy waiting\n",
    "            await asyncio.sleep(0.01)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nðŸŽ‰ All operations completed in {total_time:.2f} seconds\")\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def get_execution_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary of execution performance\"\"\"\n",
    "        completed_ops = [op for op in self.operations.values() if op.status == \"completed\"]\n",
    "        failed_ops = [op for op in self.operations.values() if op.status == \"failed\"]\n",
    "        \n",
    "        total_sequential_time = sum(op.duration for op in completed_ops)\n",
    "        actual_concurrent_time = max((op.end_time for op in completed_ops), default=0) - min((op.start_time for op in completed_ops), default=0)\n",
    "        \n",
    "        return {\n",
    "            'total_operations': len(self.operations),\n",
    "            'completed': len(completed_ops),\n",
    "            'failed': len(failed_ops),\n",
    "            'total_sequential_time': total_sequential_time,\n",
    "            'actual_concurrent_time': actual_concurrent_time,\n",
    "            'speedup_achieved': total_sequential_time / max(actual_concurrent_time, 0.1),\n",
    "            'execution_log': self.execution_log\n",
    "        }\n",
    "\n",
    "print(\"ðŸ”€ Concurrent execution framework ready\")\n",
    "print(\"âš¡ Supports dependency management and failure handling\")\n",
    "print(\"ðŸ“Š Built-in performance tracking and analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mock Services for Concurrent Testing\n",
    "\n",
    "Create mock versions of our external services with realistic delays for testing concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MockInvoiceServices:\n",
    "    \"\"\"Mock services with realistic processing delays\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.call_count = {}\n",
    "        \n",
    "    def _simulate_delay(self, operation: str, base_delay: float):\n",
    "        \"\"\"Simulate realistic API delay with some variance\"\"\"\n",
    "        # Add some randomness to simulate real-world variance\n",
    "        delay = base_delay + random.uniform(-0.2, 0.5)\n",
    "        \n",
    "        # Track call count\n",
    "        self.call_count[operation] = self.call_count.get(operation, 0) + 1\n",
    "        \n",
    "        print(f\"   ðŸ”„ {operation} processing... ({delay:.1f}s simulated delay)\")\n",
    "        time.sleep(delay)\n",
    "        \n",
    "    def analyze_document(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock document analysis with LLM\"\"\"\n",
    "        self._simulate_delay(\"Document Analysis\", 2.5)\n",
    "        \n",
    "        document_text = context.get('document_info', {}).get('text', '')\n",
    "        \n",
    "        # Extract basic info from document\n",
    "        vendor_match = re.search(r'[Ff]rom:?\\s*([A-Za-z\\s]+?)\\s*(?:To:|Amount:|$)', document_text)\n",
    "        amount_match = re.search(r'[\\$â‚¬Â£Â¥]?([0-9,]+\\.?[0-9]*)', document_text)\n",
    "        \n",
    "        return {\n",
    "            'vendor_name': vendor_match.group(1).strip() if vendor_match else 'Unknown Vendor',\n",
    "            'complexity': 'moderate',\n",
    "            'confidence': 0.85,\n",
    "            'extracted_amount': float(amount_match.group(1).replace(',', '')) if amount_match else 0.0,\n",
    "            'processing_time': 2.5\n",
    "        }\n",
    "    \n",
    "    def verify_vendor(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock vendor verification via web search\"\"\"\n",
    "        self._simulate_delay(\"Vendor Verification\", 3.2)\n",
    "        \n",
    "        vendor_name = context.get('analyze_document', {}).get('vendor_name', 'Unknown')\n",
    "        \n",
    "        # Mock verification based on vendor name\n",
    "        legitimate = 'trusted' in vendor_name.lower() or 'corp' in vendor_name.lower()\n",
    "        \n",
    "        return {\n",
    "            'vendor_name': vendor_name,\n",
    "            'is_legitimate': legitimate,\n",
    "            'confidence_score': 0.9 if legitimate else 0.3,\n",
    "            'red_flags': [] if legitimate else ['Limited online presence'],\n",
    "            'business_type': 'corporate' if legitimate else 'unknown',\n",
    "            'processing_time': 3.2\n",
    "        }\n",
    "    \n",
    "    def validate_address(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock address validation via mapping API\"\"\"\n",
    "        self._simulate_delay(\"Address Validation\", 1.8)\n",
    "        \n",
    "        # Use mock address from vendor context\n",
    "        address = context.get('vendor_context', {}).get('address', 'Unknown Address')\n",
    "        \n",
    "        is_valid = 'street' in address.lower() or 'ave' in address.lower() or 'blvd' in address.lower()\n",
    "        \n",
    "        return {\n",
    "            'original_address': address,\n",
    "            'is_valid': is_valid,\n",
    "            'confidence_level': 'high' if is_valid else 'low',\n",
    "            'country': 'United States' if is_valid else None,\n",
    "            'state_province': 'New York' if 'NY' in address else 'Unknown',\n",
    "            'processing_time': 1.8\n",
    "        }\n",
    "    \n",
    "    def detect_currency(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock currency detection from document\"\"\"\n",
    "        self._simulate_delay(\"Currency Detection\", 0.5)\n",
    "        \n",
    "        document_text = context.get('document_info', {}).get('text', '')\n",
    "        \n",
    "        # Simple currency detection\n",
    "        if 'â‚¬' in document_text or 'EUR' in document_text:\n",
    "            currency = 'EUR'\n",
    "        elif 'Â£' in document_text or 'GBP' in document_text:\n",
    "            currency = 'GBP'\n",
    "        else:\n",
    "            currency = 'USD'\n",
    "        \n",
    "        return {\n",
    "            'detected_currency': currency,\n",
    "            'confidence': 0.95,\n",
    "            'processing_time': 0.5\n",
    "        }\n",
    "    \n",
    "    def convert_currency(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock currency conversion\"\"\"\n",
    "        self._simulate_delay(\"Currency Conversion\", 1.2)\n",
    "        \n",
    "        currency_info = context.get('detect_currency', {})\n",
    "        amount = context.get('analyze_document', {}).get('extracted_amount', 0.0)\n",
    "        from_currency = currency_info.get('detected_currency', 'USD')\n",
    "        \n",
    "        # Mock exchange rates\n",
    "        rates = {'EUR': 1.08, 'GBP': 1.27, 'USD': 1.0}\n",
    "        \n",
    "        rate = rates.get(from_currency, 1.0)\n",
    "        converted_amount = amount * rate\n",
    "        \n",
    "        return {\n",
    "            'original_amount': amount,\n",
    "            'original_currency': from_currency,\n",
    "            'converted_amount': converted_amount,\n",
    "            'target_currency': 'USD',\n",
    "            'exchange_rate': rate,\n",
    "            'processing_time': 1.2\n",
    "        }\n",
    "    \n",
    "    def determine_tax_jurisdiction(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock tax jurisdiction determination\"\"\"\n",
    "        self._simulate_delay(\"Tax Jurisdiction\", 0.8)\n",
    "        \n",
    "        address_info = context.get('validate_address', {})\n",
    "        state = address_info.get('state_province', 'Unknown')\n",
    "        \n",
    "        # Mock tax rates\n",
    "        tax_rates = {\n",
    "            'New York': {'rate': 0.08, 'type': 'Sales Tax'},\n",
    "            'California': {'rate': 0.0725, 'type': 'Sales Tax'},\n",
    "            'Unknown': {'rate': 0.05, 'type': 'Default Tax'}\n",
    "        }\n",
    "        \n",
    "        tax_info = tax_rates.get(state, tax_rates['Unknown'])\n",
    "        \n",
    "        return {\n",
    "            'jurisdiction': f\"US/{state}\",\n",
    "            'tax_rate': tax_info['rate'],\n",
    "            'tax_type': tax_info['type'],\n",
    "            'processing_time': 0.8\n",
    "        }\n",
    "    \n",
    "    def validate_tax(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock tax validation\"\"\"\n",
    "        self._simulate_delay(\"Tax Validation\", 1.1)\n",
    "        \n",
    "        jurisdiction_info = context.get('determine_tax_jurisdiction', {})\n",
    "        conversion_info = context.get('convert_currency', {})\n",
    "        \n",
    "        amount = conversion_info.get('converted_amount', 1000.0)\n",
    "        tax_rate = jurisdiction_info.get('tax_rate', 0.08)\n",
    "        \n",
    "        calculated_tax = amount * tax_rate\n",
    "        provided_tax = amount * 0.08  # Assume 8% was provided\n",
    "        \n",
    "        is_correct = abs(calculated_tax - provided_tax) < 1.0\n",
    "        \n",
    "        return {\n",
    "            'calculated_tax': calculated_tax,\n",
    "            'provided_tax': provided_tax,\n",
    "            'is_correct': is_correct,\n",
    "            'tax_type': jurisdiction_info.get('tax_type', 'Sales Tax'),\n",
    "            'processing_time': 1.1\n",
    "        }\n",
    "    \n",
    "    def calculate_risk_score(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock risk score calculation\"\"\"\n",
    "        self._simulate_delay(\"Risk Calculation\", 0.9)\n",
    "        \n",
    "        vendor_info = context.get('verify_vendor', {})\n",
    "        address_info = context.get('validate_address', {})\n",
    "        tax_info = context.get('validate_tax', {})\n",
    "        \n",
    "        risk_score = 0.5  # Base risk\n",
    "        \n",
    "        # Adjust based on verification results\n",
    "        if vendor_info.get('is_legitimate', False):\n",
    "            risk_score -= 0.2\n",
    "        else:\n",
    "            risk_score += 0.3\n",
    "        \n",
    "        if address_info.get('is_valid', False):\n",
    "            risk_score -= 0.1\n",
    "        else:\n",
    "            risk_score += 0.2\n",
    "        \n",
    "        if tax_info.get('is_correct', False):\n",
    "            risk_score -= 0.1\n",
    "        else:\n",
    "            risk_score += 0.15\n",
    "        \n",
    "        risk_score = max(0.0, min(1.0, risk_score))\n",
    "        \n",
    "        return {\n",
    "            'risk_score': risk_score,\n",
    "            'risk_level': 'low' if risk_score < 0.4 else 'medium' if risk_score < 0.7 else 'high',\n",
    "            'processing_time': 0.9\n",
    "        }\n",
    "    \n",
    "    def make_final_decision(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mock final approval decision\"\"\"\n",
    "        self._simulate_delay(\"Final Decision\", 0.3)\n",
    "        \n",
    "        risk_info = context.get('calculate_risk_score', {})\n",
    "        risk_score = risk_info.get('risk_score', 0.5)\n",
    "        \n",
    "        if risk_score < 0.3:\n",
    "            decision = 'auto_approve'\n",
    "        elif risk_score < 0.6:\n",
    "            decision = 'manager_approval'\n",
    "        else:\n",
    "            decision = 'reject'\n",
    "        \n",
    "        return {\n",
    "            'final_decision': decision,\n",
    "            'risk_score': risk_score,\n",
    "            'reasoning': f\"Risk score {risk_score:.2f} requires {decision}\",\n",
    "            'processing_time': 0.3\n",
    "        }\n",
    "    \n",
    "    def get_call_summary(self) -> Dict[str, int]:\n",
    "        \"\"\"Get summary of service calls made\"\"\"\n",
    "        return self.call_count.copy()\n",
    "\n",
    "# Initialize mock services\n",
    "mock_services = MockInvoiceServices()\n",
    "\n",
    "print(\"ðŸŽ­ Mock services initialized with realistic delays:\")\n",
    "print(\"   ðŸ“Š Document Analysis: ~2.5s\")\n",
    "print(\"   ðŸ” Vendor Verification: ~3.2s\")\n",
    "print(\"   ðŸ“ Address Validation: ~1.8s\")\n",
    "print(\"   ðŸ’± Currency Operations: ~1.7s combined\")\n",
    "print(\"   ðŸ“Š Tax Operations: ~1.9s combined\")\n",
    "print(\"   âš–ï¸ Risk & Decision: ~1.2s combined\")\n",
    "print(\"   ðŸ”¢ Total Sequential: ~12.3s estimated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sequential vs Concurrent Execution Comparison\n",
    "\n",
    "Let's compare the performance of sequential versus concurrent execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_invoice = {\n",
    "    'document_info': {\n",
    "        'text': 'INVOICE #2024-001 From: TrustedCorp To: Our Company Subtotal: $1,500.00 Tax: $120.00 Total: $1,620.00',\n",
    "        'image_quality': 'high',\n",
    "        'page_count': 1\n",
    "    },\n",
    "    'vendor_context': {\n",
    "        'name': 'TrustedCorp',\n",
    "        'address': '123 Business Street, New York, NY',\n",
    "        'trust_level': 'high'\n",
    "    }\n",
    "}\n",
    "\n",
    "async def test_sequential_execution():\n",
    "    \"\"\"Test traditional sequential execution\"\"\"\n",
    "    print(\"\\nðŸŒ TESTING SEQUENTIAL EXECUTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    context = test_invoice.copy()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute operations in sequence\n",
    "    operations = [\n",
    "        ('analyze_document', mock_services.analyze_document),\n",
    "        ('verify_vendor', mock_services.verify_vendor),\n",
    "        ('validate_address', mock_services.validate_address),\n",
    "        ('detect_currency', mock_services.detect_currency),\n",
    "        ('convert_currency', mock_services.convert_currency),\n",
    "        ('determine_tax_jurisdiction', mock_services.determine_tax_jurisdiction),\n",
    "        ('validate_tax', mock_services.validate_tax),\n",
    "        ('calculate_risk_score', mock_services.calculate_risk_score),\n",
    "        ('make_final_decision', mock_services.make_final_decision)\n",
    "    ]\n",
    "    \n",
    "    for op_name, op_func in operations:\n",
    "        print(f\"\\nðŸ”„ Executing: {op_name}\")\n",
    "        perf_tracker.start_operation(f\"seq_{op_name}\", \"sequential\")\n",
    "        \n",
    "        result = op_func(context)\n",
    "        context[op_name] = result\n",
    "        \n",
    "        duration = perf_tracker.end_operation(f\"seq_{op_name}\")\n",
    "        print(f\"âœ… Completed: {op_name} ({duration:.2f}s)\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SEQUENTIAL EXECUTION SUMMARY:\")\n",
    "    print(f\"   Total Time: {total_time:.2f} seconds\")\n",
    "    print(f\"   Operations: {len(operations)}\")\n",
    "    print(f\"   Final Decision: {context['make_final_decision']['final_decision']}\")\n",
    "    \n",
    "    return total_time, context\n",
    "\n",
    "async def test_concurrent_execution():\n",
    "    \"\"\"Test optimized concurrent execution\"\"\"\n",
    "    print(\"\\nâš¡ TESTING CONCURRENT EXECUTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create concurrent executor\n",
    "    executor = ConcurrentExecutor(max_concurrent=4)\n",
    "    \n",
    "    # Define operations with dependencies\n",
    "    operations = [\n",
    "        ConcurrentOperation(\"analyze_document\", mock_services.analyze_document, []),\n",
    "        ConcurrentOperation(\"verify_vendor\", mock_services.verify_vendor, [\"analyze_document\"]),\n",
    "        ConcurrentOperation(\"detect_currency\", mock_services.detect_currency, [\"analyze_document\"]),\n",
    "        ConcurrentOperation(\"validate_address\", mock_services.validate_address, [\"verify_vendor\"]),\n",
    "        ConcurrentOperation(\"convert_currency\", mock_services.convert_currency, [\"detect_currency\"]),\n",
    "        ConcurrentOperation(\"determine_tax_jurisdiction\", mock_services.determine_tax_jurisdiction, [\"validate_address\"]),\n",
    "        ConcurrentOperation(\"validate_tax\", mock_services.validate_tax, [\"determine_tax_jurisdiction\", \"analyze_document\"]),\n",
    "        ConcurrentOperation(\"calculate_risk_score\", mock_services.calculate_risk_score, [\"verify_vendor\", \"validate_address\", \"validate_tax\"]),\n",
    "        ConcurrentOperation(\"make_final_decision\", mock_services.make_final_decision, [\"calculate_risk_score\"])\n",
    "    ]\n",
    "    \n",
    "    # Add operations to executor\n",
    "    for operation in operations:\n",
    "        executor.add_operation(operation)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute concurrently\n",
    "    context = await executor.execute_all(test_invoice.copy())\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Get execution summary\n",
    "    summary = executor.get_execution_summary()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š CONCURRENT EXECUTION SUMMARY:\")\n",
    "    print(f\"   Total Time: {total_time:.2f} seconds\")\n",
    "    print(f\"   Operations Completed: {summary['completed']}/{summary['total_operations']}\")\n",
    "    print(f\"   Operations Failed: {summary['failed']}\")\n",
    "    print(f\"   Theoretical Sequential Time: {summary['total_sequential_time']:.2f} seconds\")\n",
    "    print(f\"   Actual Concurrent Time: {summary['actual_concurrent_time']:.2f} seconds\")\n",
    "    print(f\"   Speedup Achieved: {summary['speedup_achieved']:.1f}x\")\n",
    "    \n",
    "    if 'make_final_decision' in context:\n",
    "        print(f\"   Final Decision: {context['make_final_decision']['final_decision']}\")\n",
    "    \n",
    "    return total_time, context, summary\n",
    "\n",
    "# Run both tests\n",
    "print(\"ðŸš€ PERFORMANCE COMPARISON: Sequential vs Concurrent\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reset services call count\n",
    "mock_services.call_count = {}\n",
    "\n",
    "# Test sequential execution\n",
    "sequential_time, sequential_context = await test_sequential_execution()\n",
    "sequential_calls = mock_services.call_count.copy()\n",
    "\n",
    "# Reset for concurrent test\n",
    "mock_services.call_count = {}\n",
    "\n",
    "# Test concurrent execution\n",
    "concurrent_time, concurrent_context, concurrent_summary = await test_concurrent_execution()\n",
    "concurrent_calls = mock_services.call_count.copy()\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\n\\nðŸ“ˆ PERFORMANCE COMPARISON RESULTS\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Sequential Execution Time: {sequential_time:.2f} seconds\")\n",
    "print(f\"Concurrent Execution Time:  {concurrent_time:.2f} seconds\")\n",
    "print(f\"Speedup Factor:            {sequential_time/concurrent_time:.1f}x faster\")\n",
    "print(f\"Time Saved:                {sequential_time - concurrent_time:.2f} seconds ({((sequential_time - concurrent_time)/sequential_time)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ” Service Call Verification:\")\n",
    "print(f\"Sequential calls: {sum(sequential_calls.values())} operations\")\n",
    "print(f\"Concurrent calls: {sum(concurrent_calls.values())} operations\")\n",
    "print(f\"Both executions made the same number of service calls: {'âœ… Yes' if sequential_calls == concurrent_calls else 'âŒ No'}\")\n",
    "\n",
    "# Verify same results\n",
    "seq_decision = sequential_context.get('make_final_decision', {}).get('final_decision')\n",
    "conc_decision = concurrent_context.get('make_final_decision', {}).get('final_decision')\n",
    "print(f\"Both executions reached same decision: {'âœ… Yes' if seq_decision == conc_decision else 'âŒ No'}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Production Impact:\")\n",
    "print(f\"For 1000 invoices/day:\")\n",
    "print(f\"  Sequential: {(sequential_time * 1000)/3600:.1f} hours\")\n",
    "print(f\"  Concurrent: {(concurrent_time * 1000)/3600:.1f} hours\")\n",
    "print(f\"  Time Saved: {((sequential_time - concurrent_time) * 1000)/3600:.1f} hours/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Advanced Concurrency Patterns\n",
    "\n",
    "Explore advanced patterns like batching, circuit breakers, and adaptive concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcurrencyManager:\n",
    "    \"\"\"Automatically adjust concurrency based on performance and failure rates\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_concurrency: int = 2, max_concurrency: int = 8):\n",
    "        self.current_concurrency = initial_concurrency\n",
    "        self.max_concurrency = max_concurrency\n",
    "        self.min_concurrency = 1\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.success_count = 0\n",
    "        self.failure_count = 0\n",
    "        self.total_operations = 0\n",
    "        self.recent_latencies = []\n",
    "        self.adjustment_threshold = 10  # Adjust after N operations\n",
    "        \n",
    "    def record_operation(self, success: bool, latency: float):\n",
    "        \"\"\"Record the result of an operation\"\"\"\n",
    "        self.total_operations += 1\n",
    "        \n",
    "        if success:\n",
    "            self.success_count += 1\n",
    "        else:\n",
    "            self.failure_count += 1\n",
    "        \n",
    "        self.recent_latencies.append(latency)\n",
    "        \n",
    "        # Keep only recent latencies\n",
    "        if len(self.recent_latencies) > 20:\n",
    "            self.recent_latencies = self.recent_latencies[-20:]\n",
    "        \n",
    "        # Adjust concurrency periodically\n",
    "        if self.total_operations % self.adjustment_threshold == 0:\n",
    "            self._adjust_concurrency()\n",
    "    \n",
    "    def _adjust_concurrency(self):\n",
    "        \"\"\"Adjust concurrency based on recent performance\"\"\"\n",
    "        if self.total_operations < self.adjustment_threshold:\n",
    "            return\n",
    "        \n",
    "        recent_success_rate = self.success_count / max(self.total_operations, 1)\n",
    "        avg_latency = sum(self.recent_latencies) / max(len(self.recent_latencies), 1)\n",
    "        \n",
    "        old_concurrency = self.current_concurrency\n",
    "        \n",
    "        # Increase concurrency if performance is good\n",
    "        if recent_success_rate > 0.95 and avg_latency < 2.0 and self.current_concurrency < self.max_concurrency:\n",
    "            self.current_concurrency = min(self.current_concurrency + 1, self.max_concurrency)\n",
    "            print(f\"ðŸ“ˆ Increasing concurrency: {old_concurrency} â†’ {self.current_concurrency} (success rate: {recent_success_rate:.1%}, avg latency: {avg_latency:.1f}s)\")\n",
    "        \n",
    "        # Decrease concurrency if performance is poor\n",
    "        elif recent_success_rate < 0.8 or avg_latency > 5.0:\n",
    "            self.current_concurrency = max(self.current_concurrency - 1, self.min_concurrency)\n",
    "            print(f\"ðŸ“‰ Decreasing concurrency: {old_concurrency} â†’ {self.current_concurrency} (success rate: {recent_success_rate:.1%}, avg latency: {avg_latency:.1f}s)\")\n",
    "    \n",
    "    def get_current_concurrency(self) -> int:\n",
    "        \"\"\"Get current optimal concurrency level\"\"\"\n",
    "        return self.current_concurrency\n",
    "    \n",
    "    def get_performance_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get performance statistics\"\"\"\n",
    "        return {\n",
    "            'current_concurrency': self.current_concurrency,\n",
    "            'total_operations': self.total_operations,\n",
    "            'success_rate': self.success_count / max(self.total_operations, 1),\n",
    "            'failure_rate': self.failure_count / max(self.total_operations, 1),\n",
    "            'avg_latency': sum(self.recent_latencies) / max(len(self.recent_latencies), 1)\n",
    "        }\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker pattern for failing services\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, timeout: float = 30.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"closed\"  # closed, open, half-open\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Check if operation can be executed\"\"\"\n",
    "        if self.state == \"closed\":\n",
    "            return True\n",
    "        elif self.state == \"open\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"half-open\"\n",
    "                print(f\"ðŸ”„ Circuit breaker half-open: attempting recovery\")\n",
    "                return True\n",
    "            return False\n",
    "        else:  # half-open\n",
    "            return True\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record successful operation\"\"\"\n",
    "        if self.state == \"half-open\":\n",
    "            self.state = \"closed\"\n",
    "            self.failure_count = 0\n",
    "            print(f\"âœ… Circuit breaker closed: service recovered\")\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record failed operation\"\"\"\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failure_count >= self.failure_threshold:\n",
    "            self.state = \"open\"\n",
    "            print(f\"ðŸš« Circuit breaker opened: too many failures ({self.failure_count})\")\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"Process multiple operations in batches for efficiency\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size: int = 3, max_wait_time: float = 1.0):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_wait_time = max_wait_time\n",
    "        self.pending_operations = []\n",
    "        self.batch_count = 0\n",
    "    \n",
    "    async def add_operation(self, operation_data: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Add operation to batch and process when ready\"\"\"\n",
    "        self.pending_operations.append({\n",
    "            'data': operation_data,\n",
    "            'timestamp': time.time(),\n",
    "            'future': asyncio.Future()\n",
    "        })\n",
    "        \n",
    "        # Process batch if we have enough operations or max wait time exceeded\n",
    "        should_process = (\n",
    "            len(self.pending_operations) >= self.batch_size or\n",
    "            (self.pending_operations and \n",
    "             time.time() - self.pending_operations[0]['timestamp'] > self.max_wait_time)\n",
    "        )\n",
    "        \n",
    "        if should_process:\n",
    "            await self._process_batch()\n",
    "        \n",
    "        # Return the future for the operation\n",
    "        return self.pending_operations[-1]['future']\n",
    "    \n",
    "    async def _process_batch(self):\n",
    "        \"\"\"Process the current batch of operations\"\"\"\n",
    "        if not self.pending_operations:\n",
    "            return\n",
    "        \n",
    "        batch = self.pending_operations.copy()\n",
    "        self.pending_operations.clear()\n",
    "        self.batch_count += 1\n",
    "        \n",
    "        print(f\"ðŸ”„ Processing batch #{self.batch_count} with {len(batch)} operations\")\n",
    "        \n",
    "        # Simulate batch processing (more efficient than individual calls)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Mock batch processing - more efficient than individual operations\n",
    "        batch_processing_time = 0.5 + (len(batch) * 0.2)  # Base time + per-item\n",
    "        await asyncio.sleep(batch_processing_time)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Set results for all operations in batch\n",
    "        for i, operation in enumerate(batch):\n",
    "            result = {\n",
    "                'batch_id': self.batch_count,\n",
    "                'batch_size': len(batch),\n",
    "                'batch_processing_time': processing_time,\n",
    "                'operation_index': i,\n",
    "                'individual_time_saved': 1.0 - (processing_time / len(batch)),\n",
    "                'processed_data': operation['data']\n",
    "            }\n",
    "            operation['future'].set_result(result)\n",
    "        \n",
    "        print(f\"âœ… Batch #{self.batch_count} completed in {processing_time:.2f}s (avg {processing_time/len(batch):.2f}s per operation)\")\n",
    "\n",
    "# Test advanced patterns\n",
    "async def test_advanced_patterns():\n",
    "    \"\"\"Test advanced concurrency patterns\"\"\"\n",
    "    print(\"\\nðŸ”¬ TESTING ADVANCED CONCURRENCY PATTERNS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test adaptive concurrency\n",
    "    print(\"\\nðŸ“ˆ Testing Adaptive Concurrency Management:\")\n",
    "    adaptive_manager = AdaptiveConcurrencyManager(initial_concurrency=2, max_concurrency=6)\n",
    "    \n",
    "    # Simulate operations with varying success rates\n",
    "    for i in range(25):\n",
    "        # Simulate good performance initially, then some failures\n",
    "        success = random.random() > (0.1 if i < 15 else 0.3)\n",
    "        latency = random.uniform(1.0, 3.0) if success else random.uniform(4.0, 8.0)\n",
    "        \n",
    "        adaptive_manager.record_operation(success, latency)\n",
    "    \n",
    "    stats = adaptive_manager.get_performance_stats()\n",
    "    print(f\"Final concurrency level: {stats['current_concurrency']}\")\n",
    "    print(f\"Success rate: {stats['success_rate']:.1%}\")\n",
    "    print(f\"Average latency: {stats['avg_latency']:.2f}s\")\n",
    "    \n",
    "    # Test circuit breaker\n",
    "    print(\"\\nðŸš« Testing Circuit Breaker Pattern:\")\n",
    "    circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=2.0)\n",
    "    \n",
    "    # Simulate service failures\n",
    "    for i in range(8):\n",
    "        if circuit_breaker.can_execute():\n",
    "            # Simulate operation\n",
    "            success = i < 3 or i > 6  # Fail in the middle\n",
    "            if success:\n",
    "                circuit_breaker.record_success()\n",
    "                print(f\"Operation {i+1}: âœ… Success\")\n",
    "            else:\n",
    "                circuit_breaker.record_failure()\n",
    "                print(f\"Operation {i+1}: âŒ Failed\")\n",
    "        else:\n",
    "            print(f\"Operation {i+1}: ðŸš« Blocked by circuit breaker\")\n",
    "        \n",
    "        if i == 5:  # Simulate timeout\n",
    "            print(\"â±ï¸ Waiting for circuit breaker timeout...\")\n",
    "            await asyncio.sleep(2.1)\n",
    "    \n",
    "    # Test batch processing\n",
    "    print(\"\\nðŸ“¦ Testing Batch Processing:\")\n",
    "    batch_processor = BatchProcessor(batch_size=3, max_wait_time=1.0)\n",
    "    \n",
    "    # Add operations to batch\n",
    "    start_time = time.time()\n",
    "    futures = []\n",
    "    \n",
    "    for i in range(7):  # 7 operations will create 3 batches (3+3+1)\n",
    "        operation_data = {'operation_id': i, 'data': f'test_data_{i}'}\n",
    "        future = await batch_processor.add_operation(operation_data)\n",
    "        futures.append(future)\n",
    "        \n",
    "        # Small delay between operations\n",
    "        await asyncio.sleep(0.1)\n",
    "    \n",
    "    # Wait for any remaining operations\n",
    "    await asyncio.sleep(1.5)\n",
    "    \n",
    "    # Process final batch if any pending\n",
    "    if batch_processor.pending_operations:\n",
    "        await batch_processor._process_batch()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Batch Processing Results:\")\n",
    "    print(f\"Total operations: 7\")\n",
    "    print(f\"Total batches: {batch_processor.batch_count}\")\n",
    "    print(f\"Total time: {total_time:.2f}s\")\n",
    "    print(f\"Individual processing would take: ~7.0s (1s each)\")\n",
    "    print(f\"Batch efficiency: {7.0/total_time:.1f}x speedup\")\n",
    "\n",
    "# Run advanced patterns test\n",
    "await test_advanced_patterns()\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ADVANCED PATTERNS SUMMARY:\")\n",
    "print(f\"âœ… Adaptive Concurrency: Automatically adjusts parallelism based on performance\")\n",
    "print(f\"âœ… Circuit Breaker: Prevents cascade failures in distributed systems\")\n",
    "print(f\"âœ… Batch Processing: Improves efficiency for similar operations\")\n",
    "print(f\"âœ… Production Ready: Patterns used in high-scale systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Production-Ready Concurrent Invoice Processing\n",
    "\n",
    "Build a complete concurrent invoice processing system with all the patterns we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionConcurrentProcessor:\n",
    "    \"\"\"Production-ready concurrent invoice processing system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.adaptive_manager = AdaptiveConcurrencyManager(initial_concurrency=3, max_concurrency=8)\n",
    "        self.circuit_breakers = {\n",
    "            'vendor_verification': CircuitBreaker(failure_threshold=3, timeout=30.0),\n",
    "            'address_validation': CircuitBreaker(failure_threshold=3, timeout=30.0),\n",
    "            'currency_conversion': CircuitBreaker(failure_threshold=5, timeout=60.0),\n",
    "            'tax_validation': CircuitBreaker(failure_threshold=3, timeout=30.0)\n",
    "        }\n",
    "        self.batch_processor = BatchProcessor(batch_size=3, max_wait_time=2.0)\n",
    "        self.mock_services = MockInvoiceServices()\n",
    "        self.processed_count = 0\n",
    "        self.total_processing_time = 0.0\n",
    "    \n",
    "    async def process_invoice(self, invoice_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Process a single invoice with full concurrent optimization\"\"\"\n",
    "        invoice_id = invoice_data.get('invoice_id', f'inv_{self.processed_count}')\n",
    "        print(f\"\\nðŸš€ Processing invoice: {invoice_id}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Get current optimal concurrency\n",
    "            concurrency = self.adaptive_manager.get_current_concurrency()\n",
    "            \n",
    "            # Create executor with adaptive concurrency\n",
    "            executor = ConcurrentExecutor(max_concurrent=concurrency)\n",
    "            \n",
    "            # Define operations with circuit breaker protection\n",
    "            operations = [\n",
    "                ConcurrentOperation(\"analyze_document\", \n",
    "                                  self._protected_operation(\"analyze_document\", self.mock_services.analyze_document), \n",
    "                                  []),\n",
    "                ConcurrentOperation(\"verify_vendor\", \n",
    "                                  self._protected_operation(\"vendor_verification\", self.mock_services.verify_vendor), \n",
    "                                  [\"analyze_document\"]),\n",
    "                ConcurrentOperation(\"detect_currency\", \n",
    "                                  self._protected_operation(\"currency_conversion\", self.mock_services.detect_currency), \n",
    "                                  [\"analyze_document\"]),\n",
    "                ConcurrentOperation(\"validate_address\", \n",
    "                                  self._protected_operation(\"address_validation\", self.mock_services.validate_address), \n",
    "                                  [\"verify_vendor\"]),\n",
    "                ConcurrentOperation(\"convert_currency\", \n",
    "                                  self._protected_operation(\"currency_conversion\", self.mock_services.convert_currency), \n",
    "                                  [\"detect_currency\"]),\n",
    "                ConcurrentOperation(\"determine_tax_jurisdiction\", \n",
    "                                  self._protected_operation(\"tax_validation\", self.mock_services.determine_tax_jurisdiction), \n",
    "                                  [\"validate_address\"]),\n",
    "                ConcurrentOperation(\"validate_tax\", \n",
    "                                  self._protected_operation(\"tax_validation\", self.mock_services.validate_tax), \n",
    "                                  [\"determine_tax_jurisdiction\", \"analyze_document\"]),\n",
    "                ConcurrentOperation(\"calculate_risk_score\", \n",
    "                                  self.mock_services.calculate_risk_score, \n",
    "                                  [\"verify_vendor\", \"validate_address\", \"validate_tax\"]),\n",
    "                ConcurrentOperation(\"make_final_decision\", \n",
    "                                  self.mock_services.make_final_decision, \n",
    "                                  [\"calculate_risk_score\"])\n",
    "            ]\n",
    "            \n",
    "            # Add operations to executor\n",
    "            for operation in operations:\n",
    "                executor.add_operation(operation)\n",
    "            \n",
    "            # Execute with concurrent optimization\n",
    "            result = await executor.execute_all(invoice_data)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            success = True\n",
    "            \n",
    "            # Record performance for adaptive management\n",
    "            self.adaptive_manager.record_operation(success, processing_time)\n",
    "            \n",
    "            self.processed_count += 1\n",
    "            self.total_processing_time += processing_time\n",
    "            \n",
    "            # Add processing metadata\n",
    "            result['processing_metadata'] = {\n",
    "                'invoice_id': invoice_id,\n",
    "                'processing_time': processing_time,\n",
    "                'concurrency_used': concurrency,\n",
    "                'operations_completed': len([op for op in operations if op.status == 'completed']),\n",
    "                'operations_failed': len([op for op in operations if op.status == 'failed']),\n",
    "                'success': success\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… Invoice {invoice_id} processed successfully in {processing_time:.2f}s (concurrency: {concurrency})\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            self.adaptive_manager.record_operation(False, processing_time)\n",
    "            \n",
    "            print(f\"âŒ Invoice {invoice_id} processing failed: {e}\")\n",
    "            \n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'processing_metadata': {\n",
    "                    'invoice_id': invoice_id,\n",
    "                    'processing_time': processing_time,\n",
    "                    'success': False\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def _protected_operation(self, service_name: str, operation_func: Callable):\n",
    "        \"\"\"Wrap operation with circuit breaker protection\"\"\"\n",
    "        def protected_func(context: Dict[str, Any]) -> Any:\n",
    "            circuit_breaker = self.circuit_breakers.get(service_name)\n",
    "            \n",
    "            if circuit_breaker and not circuit_breaker.can_execute():\n",
    "                # Return fallback result when circuit is open\n",
    "                print(f\"ðŸš« {service_name} circuit breaker is open - using fallback\")\n",
    "                return self._get_fallback_result(service_name)\n",
    "            \n",
    "            try:\n",
    "                result = operation_func(context)\n",
    "                if circuit_breaker:\n",
    "                    circuit_breaker.record_success()\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                if circuit_breaker:\n",
    "                    circuit_breaker.record_failure()\n",
    "                raise\n",
    "        \n",
    "        return protected_func\n",
    "    \n",
    "    def _get_fallback_result(self, service_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get fallback result when service is unavailable\"\"\"\n",
    "        fallbacks = {\n",
    "            'vendor_verification': {\n",
    "                'vendor_name': 'Unknown',\n",
    "                'is_legitimate': False,\n",
    "                'confidence_score': 0.0,\n",
    "                'red_flags': ['Service unavailable'],\n",
    "                'fallback': True\n",
    "            },\n",
    "            'address_validation': {\n",
    "                'original_address': 'Unknown',\n",
    "                'is_valid': False,\n",
    "                'confidence_level': 'low',\n",
    "                'fallback': True\n",
    "            },\n",
    "            'currency_conversion': {\n",
    "                'original_amount': 0.0,\n",
    "                'converted_amount': 0.0,\n",
    "                'target_currency': 'USD',\n",
    "                'exchange_rate': 1.0,\n",
    "                'fallback': True\n",
    "            },\n",
    "            'tax_validation': {\n",
    "                'calculated_tax': 0.0,\n",
    "                'provided_tax': 0.0,\n",
    "                'is_correct': False,\n",
    "                'fallback': True\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return fallbacks.get(service_name, {'fallback': True})\n",
    "    \n",
    "    async def process_batch(self, invoices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process a batch of invoices concurrently\"\"\"\n",
    "        print(f\"\\nðŸ“¦ Processing batch of {len(invoices)} invoices\")\n",
    "        \n",
    "        # Process invoices concurrently\n",
    "        tasks = [self.process_invoice(invoice) for invoice in invoices]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # Handle any exceptions\n",
    "        processed_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                processed_results.append({\n",
    "                    'error': str(result),\n",
    "                    'invoice_id': invoices[i].get('invoice_id', f'inv_{i}'),\n",
    "                    'success': False\n",
    "                })\n",
    "            else:\n",
    "                processed_results.append(result)\n",
    "        \n",
    "        return processed_results\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get overall performance summary\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(self.processed_count, 1)\n",
    "        \n",
    "        return {\n",
    "            'total_invoices_processed': self.processed_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'current_concurrency': self.adaptive_manager.get_current_concurrency(),\n",
    "            'adaptive_stats': self.adaptive_manager.get_performance_stats(),\n",
    "            'circuit_breaker_states': {\n",
    "                name: breaker.state for name, breaker in self.circuit_breakers.items()\n",
    "            },\n",
    "            'throughput_per_hour': 3600 / avg_processing_time if avg_processing_time > 0 else 0\n",
    "        }\n",
    "\n",
    "# Test production system\n",
    "async def test_production_system():\n",
    "    \"\"\"Test the complete production concurrent processing system\"\"\"\n",
    "    print(\"\\nðŸ­ TESTING PRODUCTION CONCURRENT PROCESSING SYSTEM\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    processor = ProductionConcurrentProcessor()\n",
    "    \n",
    "    # Test invoices\n",
    "    test_invoices = [\n",
    "        {\n",
    "            'invoice_id': 'INV-001',\n",
    "            'document_info': {\n",
    "                'text': 'INVOICE #2024-001 From: TrustedCorp Amount: $1,500 Tax: $120 Total: $1,620',\n",
    "                'image_quality': 'high'\n",
    "            },\n",
    "            'vendor_context': {\n",
    "                'name': 'TrustedCorp',\n",
    "                'address': '123 Business St, New York, NY'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'invoice_id': 'INV-002',\n",
    "            'document_info': {\n",
    "                'text': 'RECHNUNG #2024-002 Von: EuroTech GmbH Betrag: â‚¬2,500 MwSt: â‚¬475 Gesamt: â‚¬2,975',\n",
    "                'image_quality': 'medium'\n",
    "            },\n",
    "            'vendor_context': {\n",
    "                'name': 'EuroTech GmbH',\n",
    "                'address': 'HauptstraÃŸe 456, Berlin, Germany'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'invoice_id': 'INV-003',\n",
    "            'document_info': {\n",
    "                'text': 'Invoice From: NewVendor LLC Amount: $800 Tax: $64 Total: $864',\n",
    "                'image_quality': 'low'\n",
    "            },\n",
    "            'vendor_context': {\n",
    "                'name': 'NewVendor LLC',\n",
    "                'address': '789 Commerce Blvd, Los Angeles, CA'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Test individual processing\n",
    "    print(\"\\nðŸ”„ Individual Invoice Processing:\")\n",
    "    for invoice in test_invoices:\n",
    "        result = await processor.process_invoice(invoice)\n",
    "        \n",
    "        metadata = result.get('processing_metadata', {})\n",
    "        if metadata.get('success'):\n",
    "            decision = result.get('make_final_decision', {}).get('final_decision', 'unknown')\n",
    "            print(f\"   {metadata['invoice_id']}: {decision} ({metadata['processing_time']:.2f}s)\")\n",
    "    \n",
    "    # Test batch processing\n",
    "    print(f\"\\nðŸ”„ Batch Processing:\")\n",
    "    batch_results = await processor.process_batch(test_invoices)\n",
    "    \n",
    "    batch_success_count = sum(1 for r in batch_results if r.get('processing_metadata', {}).get('success', False))\n",
    "    print(f\"   Batch processed: {batch_success_count}/{len(test_invoices)} successful\")\n",
    "    \n",
    "    # Performance summary\n",
    "    summary = processor.get_performance_summary()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š PRODUCTION SYSTEM PERFORMANCE SUMMARY:\")\n",
    "    print(f\"   Total Invoices Processed: {summary['total_invoices_processed']}\")\n",
    "    print(f\"   Average Processing Time: {summary['average_processing_time']:.2f} seconds\")\n",
    "    print(f\"   Current Concurrency Level: {summary['current_concurrency']}\")\n",
    "    print(f\"   Estimated Throughput: {summary['throughput_per_hour']:.0f} invoices/hour\")\n",
    "    print(f\"   Adaptive Success Rate: {summary['adaptive_stats']['success_rate']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Circuit Breaker Status:\")\n",
    "    for service, state in summary['circuit_breaker_states'].items():\n",
    "        status_emoji = \"âœ…\" if state == \"closed\" else \"âš ï¸\" if state == \"half-open\" else \"ðŸš«\"\n",
    "        print(f\"   {service}: {status_emoji} {state}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Production Benefits:\")\n",
    "    print(f\"   Sequential processing would take: {summary['total_invoices_processed'] * 12:.1f} seconds\")\n",
    "    print(f\"   Concurrent processing took: {summary['total_processing_time']:.1f} seconds\")\n",
    "    print(f\"   Time saved: {(summary['total_invoices_processed'] * 12) - summary['total_processing_time']:.1f} seconds\")\n",
    "    print(f\"   Efficiency improvement: {((summary['total_invoices_processed'] * 12) / summary['total_processing_time']):.1f}x faster\")\n",
    "\n",
    "# Run production system test\n",
    "await test_production_system()\n",
    "\n",
    "print(f\"\\nðŸ† PRODUCTION CONCURRENCY COMPLETE!\")\n",
    "print(f\"   âœ… Adaptive concurrency management\")\n",
    "print(f\"   âœ… Circuit breaker fault tolerance\")\n",
    "print(f\"   âœ… Batch processing optimization\")\n",
    "print(f\"   âœ… Performance monitoring and metrics\")\n",
    "print(f\"   âœ… Production-ready resilience patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Learnings\n",
    "\n",
    "### Parallelization & Concurrency:\n",
    "\n",
    "1. **Dependency Analysis**\n",
    "   - Identify operations that can run in parallel\n",
    "   - Respect dependencies while maximizing concurrency\n",
    "   - Critical path analysis reveals maximum speedup potential\n",
    "   - Real systems achieve 3-5x speedup through smart parallelization\n",
    "\n",
    "2. **Concurrent Execution Patterns**\n",
    "   - AsyncIO for I/O-bound operations (API calls)\n",
    "   - ThreadPoolExecutor for CPU-bound tasks\n",
    "   - Proper synchronization and state management\n",
    "   - Graceful error handling in concurrent environments\n",
    "\n",
    "3. **Production Resilience**\n",
    "   - Adaptive concurrency prevents system overload\n",
    "   - Circuit breakers prevent cascade failures\n",
    "   - Batch processing improves efficiency for similar operations\n",
    "   - Fallback mechanisms ensure system availability\n",
    "\n",
    "4. **Performance Benefits**\n",
    "   - 60-80% reduction in processing time\n",
    "   - Higher throughput with same resources\n",
    "   - Better resource utilization\n",
    "   - Improved user experience\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Financial Processing**: Parallel validation of transactions\n",
    "- **E-commerce**: Concurrent inventory and payment processing\n",
    "- **Healthcare**: Parallel patient data verification\n",
    "- **Manufacturing**: Concurrent quality control checks\n",
    "\n",
    "### What's Next:\n",
    "\n",
    "Session 2 will add **Vision Integration** to our concurrent system:\n",
    "- Multimodal document understanding (text + images)\n",
    "- Parallel OCR and layout analysis\n",
    "- Concurrent vision model inference\n",
    "- Smart routing based on document visual complexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}