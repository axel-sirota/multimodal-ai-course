{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, Session 2 - Lab: Building Your First ReAct Agent\n",
    "\n",
    "## Implementing Reasoning + Acting Patterns\n",
    "\n",
    "In this lab, you'll build a complete ReAct agent from scratch that processes invoices using the Thought ‚Üí Action ‚Üí Observation loop. This hands-on exercise will teach you how agents make decisions and execute tools based on reasoning.\n",
    "\n",
    "### Lab Objectives\n",
    "\n",
    "By completing this lab, you will:\n",
    "1. Implement a ReAct agent class with proper state management\n",
    "2. Create invoice processing tools that simulate real business operations\n",
    "3. Design LLM prompts that guide agent reasoning\n",
    "4. Handle errors and edge cases in agent workflows\n",
    "5. Compare agent performance vs simple function calls\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "You've successfully completed this lab when you can:\n",
    "- ‚úÖ Agent processes a complete invoice workflow autonomously\n",
    "- ‚úÖ Agent handles at least one error scenario gracefully\n",
    "- ‚úÖ Agent reasoning is visible and logical\n",
    "- ‚úÖ Tools return structured, useful information\n",
    "- ‚úÖ Compare agent vs non-agent approaches\n",
    "\n",
    "### Time Estimate: 60 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup and Real Data Download (15 minutes)\n",
    "\n",
    "First, let's download real invoice images and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download real invoice and receipt images\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Dropbox shared link for the folder\n",
    "dropbox_url = \"https://www.dropbox.com/scl/fo/m9hyfmvi78snwv0nh34mo/AMEXxwXMLAOeve-_yj12ck8?rlkey=urinkikgiuven0fro7r4x5rcu&st=hv3of7g7&dl=1\"\n",
    "\n",
    "print(f\"Downloading real invoice data from: {dropbox_url}\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(dropbox_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Read the content as a zip file\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        # Extract all contents to a directory named 'downloaded_images'\n",
    "        z.extractall(\"downloaded_images\")\n",
    "\n",
    "    print(\"‚úÖ Downloaded and extracted images to 'downloaded_images' folder.\")\n",
    "    \n",
    "    # List downloaded files\n",
    "    for root, dirs, files in os.walk(\"downloaded_images\"):\n",
    "        for file in files:\n",
    "            print(f\"  üìÑ {os.path.join(root, file)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading images: {e}\")\n",
    "\n",
    "# Configuration for course server\n",
    "OLLAMA_URL = \"http://XX.XX.XX.XX\"  # Instructor provides\n",
    "API_TOKEN = \"YOUR_TOKEN_HERE\"      \n",
    "MODEL = \"qwen3:8b\"                 \n",
    "\n",
    "print(\"\\n‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Create LLM Connection Function\n",
    "\n",
    "**Your Task**: Implement a function to call the course LLM server.\n",
    "\n",
    "**Requirements**:\n",
    "- Handle API authentication with the bearer token\n",
    "- Include proper error handling\n",
    "- Return just the response text\n",
    "- Add a fallback for when server is unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt, model=MODEL):\n",
    "    \"\"\"\n",
    "    Call the LLM with a prompt and return the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the LLM\n",
    "        model (str): The model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: The LLM response\n",
    "    \"\"\"\n",
    "    # TODO: Implement the LLM call\n",
    "    # 1. Set up headers with Authorization bearer token\n",
    "    # 2. Create request payload with model and prompt\n",
    "    # 3. Make POST request to {OLLAMA_URL}/think\n",
    "    # 4. Handle errors gracefully\n",
    "    # 5. Return just the response text\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "def check_server_health():\n",
    "    \"\"\"\n",
    "    Check if the LLM server is healthy and accessible.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if server is healthy\n",
    "    \"\"\"\n",
    "    # TODO: Implement health check\n",
    "    # 1. Make GET request to {OLLAMA_URL}/health\n",
    "    # 2. Check response status and content\n",
    "    # 3. Return True/False based on result\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "print(\"Testing LLM connection...\")\n",
    "if check_server_health():\n",
    "    response = call_llm(\"Hello! Please respond with 'LLM is working correctly.'\")\n",
    "    print(f\"LLM Response: {response}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Server not available. Will use mock responses for this lab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating Invoice Processing Tools (15 minutes)\n",
    "\n",
    "Agents need tools to interact with the world. We'll create realistic invoice processing tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Implement Invoice Data Extraction Tool\n",
    "\n",
    "**Your Task**: Create a tool that extracts structured data from invoice IDs.\n",
    "\n",
    "**Requirements**:\n",
    "- Support at least 3 different invoice IDs\n",
    "- Return structured JSON with vendor, amount, date, etc.\n",
    "- Handle invalid invoice IDs gracefully\n",
    "- Include realistic business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_invoice_data(invoice_id):\n",
    "    \"\"\"\n",
    "    Extract structured data from an invoice ID.\n",
    "    \n",
    "    Args:\n",
    "        invoice_id (str): The invoice identifier\n",
    "        \n",
    "    Returns:\n",
    "        dict: Invoice data or error information\n",
    "    \"\"\"\n",
    "    # TODO: Create a mock database of invoices\n",
    "    # Include at least 3 invoices with different characteristics:\n",
    "    # - One standard invoice (< $10K)\n",
    "    # - One large invoice (> $25K) \n",
    "    # - One with unusual payment terms\n",
    "    # \n",
    "    # Each invoice should have:\n",
    "    # - invoice_id, vendor, amount, currency, date\n",
    "    # - payment_terms, due_date, line_items\n",
    "    # - contact_info, tax_info\n",
    "    \n",
    "    mock_invoices = {\n",
    "        # Your invoice data here\n",
    "    }\n",
    "    \n",
    "    # TODO: Implement lookup logic\n",
    "    # 1. Check if invoice_id exists in mock_invoices\n",
    "    # 2. Return invoice data if found\n",
    "    # 3. Return error structure if not found\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test your tool\n",
    "print(\"Testing invoice extraction tool...\")\n",
    "test_result = extract_invoice_data(\"INV-2024-001\")\n",
    "print(json.dumps(test_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Implement Business Rules Validation Tool\n",
    "\n",
    "**Your Task**: Create a tool that validates invoices against business rules.\n",
    "\n",
    "**Requirements**:\n",
    "- Check amount thresholds (auto-approve < $5K, manager approval < $25K, CFO approval > $25K)\n",
    "- Validate payment terms (Net 30/60/90)\n",
    "- Check vendor approval status\n",
    "- Return detailed validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_business_rules(invoice_data):\n",
    "    \"\"\"\n",
    "    Validate an invoice against business rules.\n",
    "    \n",
    "    Args:\n",
    "        invoice_data (dict): Invoice data from extraction\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results with approval recommendation\n",
    "    \"\"\"\n",
    "    # TODO: Define business rules\n",
    "    rules = {\n",
    "        'amount_thresholds': {\n",
    "            'auto_approve': 5000,\n",
    "            'manager_approval': 25000,\n",
    "            'cfo_approval': 100000\n",
    "        },\n",
    "        'approved_vendors': [\n",
    "            # Add some approved vendor names\n",
    "        ],\n",
    "        'valid_payment_terms': ['Net 30', 'Net 60', 'Net 90']\n",
    "    }\n",
    "    \n",
    "    validation_result = {\n",
    "        'is_valid': True,\n",
    "        'approval_level': 'auto',\n",
    "        'issues': [],\n",
    "        'warnings': [],\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # TODO: Implement validation logic\n",
    "    # 1. Extract amount and check thresholds\n",
    "    # 2. Validate vendor is in approved list\n",
    "    # 3. Check payment terms are acceptable\n",
    "    # 4. Set appropriate approval level\n",
    "    # 5. Add issues/warnings as needed\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    return validation_result\n",
    "\n",
    "def check_vendor_history(vendor_name):\n",
    "    \"\"\"\n",
    "    Look up vendor payment history and risk assessment.\n",
    "    \n",
    "    Args:\n",
    "        vendor_name (str): Name of the vendor\n",
    "        \n",
    "    Returns:\n",
    "        dict: Vendor history and risk information\n",
    "    \"\"\"\n",
    "    # TODO: Create mock vendor database\n",
    "    # Include risk scores, payment history, etc.\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "def calculate_due_date(invoice_date, payment_terms):\n",
    "    \"\"\"\n",
    "    Calculate the payment due date.\n",
    "    \n",
    "    Args:\n",
    "        invoice_date (str): Invoice date in YYYY-MM-DD format\n",
    "        payment_terms (str): Payment terms like 'Net 30'\n",
    "        \n",
    "    Returns:\n",
    "        dict: Due date information\n",
    "    \"\"\"\n",
    "    # TODO: Implement date calculation\n",
    "    # 1. Parse invoice_date string\n",
    "    # 2. Extract days from payment_terms\n",
    "    # 3. Calculate due_date\n",
    "    # 4. Return formatted result\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test your validation tools\n",
    "print(\"Testing business rules validation...\")\n",
    "sample_invoice = extract_invoice_data(\"INV-2024-001\")\n",
    "if sample_invoice.get('status') == 'success':\n",
    "    validation = validate_business_rules(sample_invoice['data'])\n",
    "    print(json.dumps(validation, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Building the ReAct Agent (20 minutes)\n",
    "\n",
    "Now we'll implement the core ReAct agent that uses reasoning to guide actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Implement ReAct Agent Class\n",
    "\n",
    "**Your Task**: Create a ReAct agent that follows the Thought ‚Üí Action ‚Üí Observation pattern.\n",
    "\n",
    "**Requirements**:\n",
    "- Parse LLM responses into structured actions\n",
    "- Execute tools based on agent decisions\n",
    "- Maintain conversation history\n",
    "- Handle errors gracefully\n",
    "- Limit maximum steps to prevent infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    \"\"\"\n",
    "    ReAct agent that uses reasoning to guide actions for invoice processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_function, tools, max_steps=10):\n",
    "        \"\"\"\n",
    "        Initialize the ReAct agent.\n",
    "        \n",
    "        Args:\n",
    "            llm_function: Function to call LLM\n",
    "            tools: Dictionary of available tools\n",
    "            max_steps: Maximum steps before stopping\n",
    "        \"\"\"\n",
    "        self.llm_function = llm_function\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "        self.history = []\n",
    "    \n",
    "    def create_prompt(self, task, observations=\"\"):\n",
    "        \"\"\"\n",
    "        Create a prompt for the LLM that guides ReAct reasoning.\n",
    "        \n",
    "        Args:\n",
    "            task (str): The task to complete\n",
    "            observations (str): Previous observations\n",
    "            \n",
    "        Returns:\n",
    "            str: Formatted prompt for LLM\n",
    "        \"\"\"\n",
    "        # TODO: Create a comprehensive prompt that:\n",
    "        # 1. Explains the ReAct pattern\n",
    "        # 2. Lists available tools with descriptions\n",
    "        # 3. Shows the required output format\n",
    "        # 4. Includes the current task and observations\n",
    "        # 5. Asks for THOUGHT, ACTION, and PARAMS\n",
    "        \n",
    "        tool_descriptions = \"\\n\".join([\n",
    "            f\"- {name}: {func.__doc__.split('.')[0] if func.__doc__ else 'No description'}\"\n",
    "            for name, func in self.tools.items()\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        # Your prompt here\n",
    "        # Include:\n",
    "        # - Role definition\n",
    "        # - Available tools\n",
    "        # - Response format\n",
    "        # - Current task\n",
    "        # - Previous observations\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def parse_response(self, response):\n",
    "        \"\"\"\n",
    "        Parse LLM response into structured thought, action, and parameters.\n",
    "        \n",
    "        Args:\n",
    "            response (str): Raw LLM response\n",
    "            \n",
    "        Returns:\n",
    "            dict: Parsed response with thought, action, params\n",
    "        \"\"\"\n",
    "        # TODO: Implement response parsing\n",
    "        # 1. Look for THOUGHT:, ACTION:, PARAMS: markers\n",
    "        # 2. Extract content after each marker\n",
    "        # 3. Handle cases where format is not perfect\n",
    "        # 4. Return structured dictionary\n",
    "        \n",
    "        parsed = {\n",
    "            \"thought\": \"\",\n",
    "            \"action\": \"\",\n",
    "            \"params\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Your parsing code here:\n",
    "        \n",
    "        \n",
    "        return parsed\n",
    "    \n",
    "    def execute_action(self, action, params):\n",
    "        \"\"\"\n",
    "        Execute the chosen action with given parameters.\n",
    "        \n",
    "        Args:\n",
    "            action (str): Action to execute\n",
    "            params (str): Parameters for the action\n",
    "            \n",
    "        Returns:\n",
    "            dict: Execution result\n",
    "        \"\"\"\n",
    "        # TODO: Implement action execution\n",
    "        # 1. Check if action is 'FINISH'\n",
    "        # 2. Look up tool in self.tools\n",
    "        # 3. Parse parameters (JSON or string)\n",
    "        # 4. Execute tool with error handling\n",
    "        # 5. Return structured result\n",
    "        \n",
    "        if action == \"FINISH\":\n",
    "            return {\"type\": \"final_answer\", \"result\": params}\n",
    "        \n",
    "        # Your execution code here:\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def run(self, task):\n",
    "        \"\"\"\n",
    "        Run the agent on a task until completion or max steps.\n",
    "        \n",
    "        Args:\n",
    "            task (str): The task to complete\n",
    "            \n",
    "        Returns:\n",
    "            str: Final result or None if failed\n",
    "        \"\"\"\n",
    "        observations = \"\"\n",
    "        \n",
    "        print(f\"\\nüìã TASK: {task}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            print(f\"\\nüîÑ Step {step + 1}:\")\n",
    "            \n",
    "            # TODO: Implement the main reasoning loop\n",
    "            # 1. Create prompt with task and observations\n",
    "            # 2. Get LLM response\n",
    "            # 3. Parse response into thought/action/params\n",
    "            # 4. Display thought and action\n",
    "            # 5. Execute action\n",
    "            # 6. Handle final answer or continue\n",
    "            # 7. Update observations for next step\n",
    "            \n",
    "            # Your main loop code here:\n",
    "            \n",
    "            \n",
    "            pass\n",
    "        \n",
    "        print(\"\\n‚ö†Ô∏è Max steps reached without completion\")\n",
    "        return None\n",
    "\n",
    "# Test your agent implementation\n",
    "print(\"ReAct Agent class created. Ready for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Create Agent Tools Registry\n",
    "\n",
    "**Your Task**: Create a registry of tools for your agent to use.\n",
    "\n",
    "**Requirements**:\n",
    "- Include all the tools you've implemented\n",
    "- Add clear descriptions for the LLM\n",
    "- Test each tool individually\n",
    "- Ensure tools have consistent interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create tools registry\n",
    "# Include all your implemented tools with clear names\n",
    "\n",
    "tools = {\n",
    "    # \"extract_invoice\": extract_invoice_data,\n",
    "    # \"validate_rules\": validate_business_rules,\n",
    "    # \"check_vendor\": check_vendor_history,\n",
    "    # \"calculate_due\": calculate_due_date\n",
    "}\n",
    "\n",
    "# Test each tool\n",
    "print(\"Testing all tools...\")\n",
    "for tool_name, tool_func in tools.items():\n",
    "    print(f\"\\nüîß {tool_name}: {tool_func.__doc__.split('.')[0] if tool_func.__doc__ else 'No description'}\")\n",
    "\n",
    "# Create mock LLM for testing if server unavailable\n",
    "def mock_llm(prompt):\n",
    "    \"\"\"\n",
    "    Mock LLM responses for testing when server is unavailable.\n",
    "    \"\"\"\n",
    "    # TODO: Create realistic mock responses based on prompt content\n",
    "    # Look at prompt content to determine appropriate response\n",
    "    \n",
    "    if \"Previous observations:\" in prompt and \"Step 1\" not in prompt:\n",
    "        # Subsequent steps\n",
    "        pass\n",
    "    else:\n",
    "        # First step\n",
    "        pass\n",
    "    \n",
    "    # Your mock responses here\n",
    "    return \"THOUGHT: Mock response\\nACTION: extract_invoice\\nPARAMS: INV-2024-001\"\n",
    "\n",
    "# Choose LLM function\n",
    "if check_server_health():\n",
    "    llm_function = call_llm\n",
    "    print(\"\\n‚úÖ Using real LLM server\")\nelse:\n",
    "    llm_function = mock_llm\n",
    "    print(\"\\n‚ö†Ô∏è Using mock LLM responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Agent Testing and Evaluation (10 minutes)\n",
    "\n",
    "Let's test your agent with different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Test Basic Invoice Processing\n",
    "\n",
    "**Your Task**: Test your agent with a standard invoice processing workflow.\n",
    "\n",
    "**Expected Flow**:\n",
    "1. Extract invoice data\n",
    "2. Validate business rules\n",
    "3. Check vendor history\n",
    "4. Calculate due date\n",
    "5. Make approval recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and test your agent\n",
    "# 1. Instantiate ReActAgent with your tools\n",
    "# 2. Run on a standard invoice processing task\n",
    "# 3. Observe the reasoning process\n",
    "\n",
    "# Your agent testing code here:\n",
    "\n",
    "\n",
    "# Test task\n",
    "task = \"Process invoice INV-2024-001 and provide a complete approval recommendation with reasoning.\"\n",
    "\n",
    "# Run agent\n",
    "print(\"\\nRunning agent on standard invoice...\")\n",
    "# result = agent.run(task)\n",
    "# print(f\"\\nFinal Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Test Error Handling\n",
    "\n",
    "**Your Task**: Test how your agent handles error scenarios.\n",
    "\n",
    "**Test Cases**:\n",
    "- Invalid invoice ID\n",
    "- High-risk vendor\n",
    "- Unusual payment terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test error scenarios\n",
    "# Create test cases that should trigger different error paths\n",
    "\n",
    "error_test_cases = [\n",
    "    \"Process invoice INV-INVALID-999 and handle any errors gracefully.\",\n",
    "    \"Process invoice with an unknown vendor and assess risks.\",\n",
    "    \"Process invoice with unusual payment terms and validate.\"\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(error_test_cases, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ERROR TEST CASE {i}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Your error testing code here:\n",
    "    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3: Compare Agent vs Non-Agent Approach\n",
    "\n",
    "**Your Task**: Compare your agent with a simple function-based approach.\n",
    "\n",
    "**Requirements**:\n",
    "- Implement a non-agent invoice processor\n",
    "- Compare results, flexibility, and error handling\n",
    "- Document the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_invoice_processor(invoice_id):\n",
    "    \"\"\"\n",
    "    Simple function-based invoice processor (no agent reasoning).\n",
    "    \n",
    "    Args:\n",
    "        invoice_id (str): Invoice to process\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing results\n",
    "    \"\"\"\n",
    "    # TODO: Implement simple sequential processing\n",
    "    # 1. Extract invoice data\n",
    "    # 2. Validate business rules\n",
    "    # 3. Return results\n",
    "    # No reasoning, no error recovery, just linear steps\n",
    "    \n",
    "    # Your simple processor code here:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# TODO: Compare approaches\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: Agent vs Simple Function\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_invoice = \"INV-2024-001\"\n",
    "\n",
    "# Test simple approach\n",
    "print(\"\\nüì± SIMPLE FUNCTION APPROACH:\")\n",
    "print(\"-\" * 40)\n",
    "# simple_result = simple_invoice_processor(test_invoice)\n",
    "# print(f\"Result: {simple_result}\")\n",
    "\n",
    "# Test agent approach\n",
    "print(\"\\nü§ñ AGENT APPROACH:\")\n",
    "print(\"-\" * 40)\n",
    "# agent_result = agent.run(f\"Process invoice {test_invoice}\")\n",
    "# print(f\"Result: {agent_result}\")\n",
    "\n",
    "print(\"\\nüìä COMPARISON ANALYSIS:\")\n",
    "print(\"Simple Function:\")\n",
    "print(\"  ‚úì Fast and predictable\")\n",
    "print(\"  ‚úì Easy to debug\")\n",
    "print(\"  ‚úó No error recovery\")\n",
    "print(\"  ‚úó No reasoning visible\")\n",
    "print(\"  ‚úó Hard to adapt to new scenarios\")\n",
    "\n",
    "print(\"\\nAgent Approach:\")\n",
    "print(\"  ‚úì Reasoning is transparent\")\n",
    "print(\"  ‚úì Can handle unexpected scenarios\")\n",
    "print(\"  ‚úì Self-correcting\")\n",
    "print(\"  ‚úó Slower due to LLM calls\")\n",
    "print(\"  ‚úó Less predictable\")\n",
    "print(\"  ‚úó Requires prompt engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Summary and Self-Assessment\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "If you've completed all tasks, you've successfully:\n",
    "- ‚úÖ Built a complete ReAct agent from scratch\n",
    "- ‚úÖ Implemented realistic invoice processing tools\n",
    "- ‚úÖ Created LLM prompts that guide reasoning\n",
    "- ‚úÖ Handled errors and edge cases\n",
    "- ‚úÖ Compared agent vs traditional approaches\n",
    "\n",
    "### Self-Assessment Questions\n",
    "\n",
    "Answer these to check your understanding:\n",
    "\n",
    "1. **What are the key components of the ReAct pattern?**\n",
    "   - Your answer:\n",
    "\n",
    "2. **How does agent reasoning help with error handling?**\n",
    "   - Your answer:\n",
    "\n",
    "3. **When would you choose an agent over a simple function?**\n",
    "   - Your answer:\n",
    "\n",
    "4. **What role do tools play in agent capabilities?**\n",
    "   - Your answer:\n",
    "\n",
    "5. **How could you improve your agent's performance?**\n",
    "   - Your answer:\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next session, you'll learn how to:\n",
    "- Use LangGraph for complex agent workflows\n",
    "- Implement parallel tool execution\n",
    "- Add state management and checkpointing\n",
    "- Build production-ready agent systems\n",
    "\n",
    "### Additional Challenges (Optional)\n",
    "\n",
    "If you finish early, try these:\n",
    "1. Add a tool for currency conversion\n",
    "2. Implement a vendor risk scoring system\n",
    "3. Add memory so agent remembers previous invoices\n",
    "4. Create a tool that generates approval emails\n",
    "5. Add timing and performance metrics to your agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}