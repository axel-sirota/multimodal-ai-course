{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, Session 5 - Lab: Advanced Optimization and Production Deployment\n",
    "\n",
    "## Mastering Enterprise-Scale Document AI Systems\n",
    "\n",
    "In this final lab, you'll optimize your invoice processing system for production deployment. You'll implement advanced techniques including model optimization, multi-language support, performance monitoring, and production deployment patterns. This represents the culmination of enterprise-grade document AI development.\n",
    "\n",
    "### Lab Objectives\n",
    "\n",
    "By completing this lab, you will:\n",
    "1. Implement advanced OCR optimization with multiple engines\n",
    "2. Add multi-language processing capabilities\n",
    "3. Optimize models for production performance (quantization, caching)\n",
    "4. Build comprehensive quality assurance and monitoring\n",
    "5. Create error recovery and fault tolerance mechanisms\n",
    "6. Design production deployment architecture\n",
    "7. Implement performance benchmarking and optimization\n",
    "8. Build advanced analytics and reporting capabilities\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "You've successfully completed this lab when you can:\n",
    "- âœ… Process invoices in multiple languages with >95% accuracy\n",
    "- âœ… Achieve <3 second processing time per invoice\n",
    "- âœ… Handle poor quality documents with graceful degradation\n",
    "- âœ… Recover from 90% of processing errors automatically\n",
    "- âœ… Generate comprehensive performance and quality reports\n",
    "- âœ… Demonstrate 50%+ performance improvement through optimization\n",
    "- âœ… Create production-ready deployment documentation\n",
    "\n",
    "### Time Estimate: 100 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Advanced OCR and Multi-Language Support (25 minutes)\n",
    "\n",
    "Implement sophisticated OCR with multiple engines and multi-language capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download real invoice and receipt images\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Union, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Dropbox shared link for the folder\n",
    "dropbox_url = \"https://www.dropbox.com/scl/fo/m9hyfmvi78snwv0nh34mo/AMEXxwXMLAOeve-_yj12ck8?rlkey=urinkikgiuven0fro7r4x5rcu&st=hv3of7g7&dl=1\"\n",
    "\n",
    "print(f\"Downloading real invoice data from: {dropbox_url}\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(dropbox_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Read the content as a zip file\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        # Extract all contents to a directory named 'downloaded_images'\n",
    "        z.extractall(\"downloaded_images\")\n",
    "\n",
    "    print(\"âœ… Downloaded and extracted images to 'downloaded_images' folder.\")\n",
    "    \n",
    "    # Categorize downloaded files\n",
    "    invoice_files = []\n",
    "    receipt_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(\"downloaded_images\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.pdf')):\n",
    "                full_path = os.path.join(root, file)\n",
    "                if 'invoice' in file.lower():\n",
    "                    invoice_files.append(full_path)\n",
    "                elif 'receipt' in file.lower():\n",
    "                    receipt_files.append(full_path)\n",
    "                print(f\"  ðŸ“„ {full_path}\")\n",
    "    \n",
    "    print(f\"\\nFound {len(invoice_files)} invoice files and {len(receipt_files)} receipt files\")\n",
    "\nexcept Exception as e:\n",
    "    print(f\"âŒ Error downloading images: {e}\")\n",
    "    invoice_files = []\n",
    "    receipt_files = []\n",
    "\n",
    "# Install advanced packages\n",
    "!pip install -q pillow pytesseract easyocr opencv-python-headless\n",
    "!pip install -q transformers torch accelerate optimum[onnxruntime]\n",
    "!pip install -q langdetect polyglot plotly\n",
    "!apt-get install -qq tesseract-ocr tesseract-ocr-deu tesseract-ocr-fra tesseract-ocr-spa poppler-utils\n",
    "\n",
    "print(\"\\nâœ… Advanced environment setup complete!\")\n",
    "print(f\"Available for testing: {len(invoice_files)} invoices, {len(receipt_files)} receipts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Implement Multi-Engine OCR System\n",
    "\n",
    "**Your Task**: Create an advanced OCR system that uses multiple engines and selects the best results.\n",
    "\n",
    "**Requirements**:\n",
    "- Support Tesseract and EasyOCR engines\n",
    "- Automatic engine selection based on document type\n",
    "- Confidence-based result fusion\n",
    "- Performance optimization with caching\n",
    "- Quality-based preprocessing selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class OCRResult:\n",
    "    \"\"\"Standardized OCR result structure\"\"\"\n",
    "    text: str\n",
    "    confidence: float\n",
    "    processing_time: float\n",
    "    engine: str\n",
    "    word_count: int\n",
    "    character_count: int\n",
    "    language: str = \"en\"\n",
    "    quality_score: float = 0.0\n",
    "    bbox_data: List[Dict] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.bbox_data is None:\n",
    "            self.bbox_data = []\n",
    "\nclass AdvancedOCRSystem:\n",
    "    \"\"\"Advanced multi-engine OCR system with optimization\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.engines = {}\n",
    "        self.cache = {}\n",
    "        self.performance_stats = defaultdict(list)\n",
    "        self._initialize_engines()\n",
    "    \n",
    "    def _initialize_engines(self):\n",
    "        \"\"\"Initialize all OCR engines\"\"\"\n",
    "        print(\"Initializing OCR engines...\")\n",
    "        \n",
    "        try:\n",
    "            # TODO: Initialize multiple OCR engines\n",
    "            # 1. Set up Tesseract with multiple languages\n",
    "            # 2. Initialize EasyOCR with GPU support\n",
    "            # 3. Configure preprocessing pipelines\n",
    "            # 4. Set up caching mechanisms\n",
    "            \n",
    "            # Initialize EasyOCR\n",
    "            self.engines['easyocr'] = easyocr.Reader(\n",
    "                ['en', 'de', 'fr', 'es'], \n",
    "                gpu=torch.cuda.is_available()\n",
    "            )\n",
    "            \n",
    "            # Configure Tesseract\n",
    "            self.engines['tesseract'] = {\n",
    "                'configs': {\n",
    "                    'default': r'--oem 3 --psm 6',\n",
    "                    'numeric': r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789.,',\n",
    "                    'multilang': r'--oem 3 --psm 6 -l eng+deu+fra+spa'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            print(\"âœ… OCR engines initialized\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error initializing OCR engines: {e}\")\n",
    "            self.engines = {}\n",
    "    \n",
    "    def _preprocess_image(self, image: Image.Image, method: str = \"standard\") -> Image.Image:\n",
    "        \"\"\"\n",
    "        Apply advanced preprocessing based on image quality assessment.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            method: Preprocessing method to apply\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed image\n",
    "        \"\"\"\n",
    "        # TODO: Implement advanced preprocessing\n",
    "        # 1. Assess image quality (sharpness, contrast, noise)\n",
    "        # 2. Select appropriate preprocessing pipeline\n",
    "        # 3. Apply noise reduction, contrast enhancement\n",
    "        # 4. Correct skew and rotation\n",
    "        # 5. Optimize for specific OCR engines\n",
    "        \n",
    "        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if method == \"enhanced\":\n",
    "            # Your enhanced preprocessing code here:\n",
    "            pass\n",
    "        elif method == \"denoised\":\n",
    "            # Your denoising code here:\n",
    "            pass\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        return Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    def _ocr_with_tesseract(self, image: Image.Image, config: str = \"default\") -> OCRResult:\n",
    "        \"\"\"\n",
    "        Perform OCR using Tesseract with specified configuration.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # TODO: Implement Tesseract OCR with confidence extraction\n",
    "            # 1. Apply specified configuration\n",
    "            # 2. Extract text and detailed data\n",
    "            # 3. Calculate confidence scores\n",
    "            # 4. Return structured result\n",
    "            \n",
    "            config_str = self.engines['tesseract']['configs'].get(config, config)\n",
    "            \n",
    "            # Your Tesseract implementation here:\n",
    "            \n",
    "            \n",
    "            return OCRResult(\n",
    "                text=\"\",\n",
    "                confidence=0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                engine=\"tesseract\",\n",
    "                word_count=0,\n",
    "                character_count=0\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return OCRResult(\n",
    "                text=\"\",\n",
    "                confidence=0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                engine=\"tesseract_error\",\n",
    "                word_count=0,\n",
    "                character_count=0\n",
    "            )\n",
    "    \n",
    "    def _ocr_with_easyocr(self, image: Image.Image) -> OCRResult:\n",
    "        \"\"\"\n",
    "        Perform OCR using EasyOCR.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # TODO: Implement EasyOCR processing\n",
    "            # 1. Convert image to numpy array\n",
    "            # 2. Run EasyOCR readtext\n",
    "            # 3. Extract text and confidence\n",
    "            # 4. Return structured result\n",
    "            \n",
    "            img_array = np.array(image)\n",
    "            \n",
    "            # Your EasyOCR implementation here:\n",
    "            \n",
    "            \n",
    "            return OCRResult(\n",
    "                text=\"\",\n",
    "                confidence=0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                engine=\"easyocr\",\n",
    "                word_count=0,\n",
    "                character_count=0\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return OCRResult(\n",
    "                text=\"\",\n",
    "                confidence=0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                engine=\"easyocr_error\",\n",
    "                word_count=0,\n",
    "                character_count=0\n",
    "            )\n",
    "    \n",
    "    def _select_best_result(self, results: List[OCRResult]) -> OCRResult:\n",
    "        \"\"\"\n",
    "        Select the best OCR result based on confidence and quality metrics.\n",
    "        \n",
    "        Args:\n",
    "            results: List of OCR results from different engines\n",
    "            \n",
    "        Returns:\n",
    "            Best OCR result\n",
    "        \"\"\"\n",
    "        # TODO: Implement intelligent result selection\n",
    "        # 1. Calculate composite quality scores\n",
    "        # 2. Consider confidence, text length, processing time\n",
    "        # 3. Apply engine-specific bias corrections\n",
    "        # 4. Return best result with justification\n",
    "        \n",
    "        if not results:\n",
    "            return OCRResult(\n",
    "                text=\"\", confidence=0, processing_time=0,\n",
    "                engine=\"none\", word_count=0, character_count=0\n",
    "            )\n",
    "        \n",
    "        # Your selection logic here:\n",
    "        \n",
    "        \n",
    "        # Default to highest confidence\n",
    "        return max(results, key=lambda x: x.confidence)\n",
    "    \n",
    "    def process_document(self, image: Image.Image, use_cache: bool = True) -> OCRResult:\n",
    "        \"\"\"\n",
    "        Process document with all available OCR engines and return best result.\n",
    "        \n",
    "        Args:\n",
    "            image: Document image to process\n",
    "            use_cache: Whether to use result caching\n",
    "            \n",
    "        Returns:\n",
    "            Best OCR result\n",
    "        \"\"\"\n",
    "        # TODO: Implement complete document processing\n",
    "        # 1. Generate image hash for caching\n",
    "        # 2. Check cache if enabled\n",
    "        # 3. Run multiple OCR engines in parallel\n",
    "        # 4. Select best result\n",
    "        # 5. Cache result for future use\n",
    "        # 6. Update performance statistics\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generate cache key\n",
    "        if use_cache:\n",
    "            image_hash = hashlib.md5(image.tobytes()).hexdigest()\n",
    "            if image_hash in self.cache:\n",
    "                cached_result = self.cache[image_hash]\n",
    "                cached_result.processing_time = 0.001  # Cache hit\n",
    "                return cached_result\n",
    "        \n",
    "        # Your processing implementation here:\n",
    "        \n",
    "        \n",
    "        # Default fallback\n",
    "        result = OCRResult(\n",
    "            text=\"Processing not implemented\",\n",
    "            confidence=0,\n",
    "            processing_time=time.time() - start_time,\n",
    "            engine=\"fallback\",\n",
    "            word_count=0,\n",
    "            character_count=0\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_performance_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get performance statistics for all engines\"\"\"\n",
    "        # TODO: Calculate and return performance statistics\n",
    "        # 1. Average processing times per engine\n",
    "        # 2. Confidence score distributions\n",
    "        # 3. Success rates\n",
    "        # 4. Cache hit rates\n",
    "        \n",
    "        return {\n",
    "            'total_processed': len(self.performance_stats),\n",
    "            'cache_hits': len(self.cache),\n",
    "            'engines_available': list(self.engines.keys())\n",
    "        }\n",
    "\n",
    "# Create advanced OCR system\n",
    "print(\"Creating advanced OCR system...\")\n",
    "advanced_ocr = AdvancedOCRSystem()\nprint(\"âœ… Advanced OCR system created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Implement Multi-Language Processing\n",
    "\n",
    "**Your Task**: Add comprehensive multi-language support for global invoice processing.\n",
    "\n",
    "**Requirements**:\n",
    "- Automatic language detection\n",
    "- Language-specific processing pipelines\n",
    "- Translation capabilities for unified processing\n",
    "- Cultural context awareness (date formats, currencies)\n",
    "- Multi-language confidence calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, LangDetectError\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from typing import Tuple\n",
    "\nclass MultiLanguageProcessor:\n",
    "    \"\"\"Advanced multi-language processing for global invoice handling\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.supported_languages = ['en', 'de', 'fr', 'es', 'it', 'pt']\n",
    "        self.translation_models = {}\n",
    "        self.language_patterns = self._initialize_language_patterns()\n",
    "        self._load_translation_models()\n",
    "    \n",
    "    def _initialize_language_patterns(self) -> Dict[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Initialize language-specific patterns for extraction.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of language-specific regex patterns\n",
    "        \"\"\"\n",
    "        # TODO: Define comprehensive language-specific patterns\n",
    "        # 1. Invoice-related keywords in each language\n",
    "        # 2. Date format patterns\n",
    "        # 3. Currency patterns\n",
    "        # 4. Number format patterns\n",
    "        # 5. Address format patterns\n",
    "        \n",
    "        patterns = {\n",
    "            'en': {\n",
    "                'invoice_keywords': r'(?i)(invoice|bill|receipt|statement)',\n",
    "                'total_patterns': r'(?i)total[:\\s]*([â‚¬$Â£Â¥][\\d,]+\\.?\\d*|[\\d,]+\\.?\\d*\\s*[â‚¬$Â£Â¥])',\n",
    "                'date_patterns': r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{4}',\n",
    "                'invoice_number': r'(?i)invoice\\s*#?\\s*([A-Z0-9-]+)'\n",
    "            },\n",
    "            'de': {\n",
    "                'invoice_keywords': r'(?i)(rechnung|beleg|quittung)',\n",
    "                'total_patterns': r'(?i)(gesamt|summe)[:\\s]*([â‚¬$][\\d,]+\\.?\\d*|[\\d,]+\\.?\\d*\\s*[â‚¬$])',\n",
    "                'date_patterns': r'\\d{1,2}[.]\\d{1,2}[.]\\d{4}',\n",
    "                'invoice_number': r'(?i)rechnung\\s*#?\\s*([A-Z0-9-]+)'\n",
    "            },\n",
    "            # Add more languages\n",
    "        }\n",
    "        \n",
    "        # Your pattern definitions here:\n",
    "        \n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def _load_translation_models(self):\n",
    "        \"\"\"Load translation models for supported languages\"\"\"\n",
    "        try:\n",
    "            # TODO: Load translation models\n",
    "            # 1. Load multilingual translation model\n",
    "            # 2. Configure for batch processing\n",
    "            # 3. Set up caching for repeated translations\n",
    "            \n",
    "            # Your translation model loading here:\n",
    "            \n",
    "            \n",
    "            print(\"âœ… Translation models loaded\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Translation models not available: {e}\")\n",
    "            self.translation_models = {}\n",
    "    \n",
    "    def detect_language(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Detect language of input text with confidence score.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text for language detection\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (language_code, confidence)\n",
    "        \"\"\"\n",
    "        # TODO: Implement robust language detection\n",
    "        # 1. Clean text for better detection\n",
    "        # 2. Use multiple detection methods\n",
    "        # 3. Apply confidence calibration\n",
    "        # 4. Handle mixed-language documents\n",
    "        # 5. Fallback to pattern-based detection\n",
    "        \n",
    "        try:\n",
    "            # Your language detection code here:\n",
    "            \n",
    "            \n",
    "            return 'en', 0.9  # Default fallback\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 'en', 0.5  # Low confidence fallback\n",
    "    \n",
    "    def translate_to_english(self, text: str, source_language: str) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Translate text to English for unified processing.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to translate\n",
    "            source_language: Source language code\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (translated_text, translation_confidence)\n",
    "        \"\"\"\n",
    "        if source_language == 'en':\n",
    "            return text, 1.0\n",
    "        \n",
    "        # TODO: Implement translation with confidence scoring\n",
    "        # 1. Check if translation model available\n",
    "        # 2. Translate in chunks for long text\n",
    "        # 3. Calculate translation confidence\n",
    "        # 4. Handle translation failures gracefully\n",
    "        \n",
    "        try:\n",
    "            # Your translation code here:\n",
    "            \n",
    "            \n",
    "            return text, 0.8  # Fallback\n",
    "            \n",
    "        except Exception as e:\n",
    "            return text, 0.0  # Translation failed\n",
    "    \n",
    "    def extract_multilingual_fields(self, text: str, language: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract invoice fields using language-specific patterns.\n",
    "        \n",
    "        Args:\n",
    "            text: Invoice text\n",
    "            language: Detected language\n",
    "            \n",
    "        Returns:\n",
    "            Extracted fields with confidence scores\n",
    "        \"\"\"\n",
    "        # TODO: Implement language-specific field extraction\n",
    "        # 1. Select appropriate patterns for language\n",
    "        # 2. Extract key fields (amounts, dates, numbers)\n",
    "        # 3. Apply language-specific validation\n",
    "        # 4. Handle cultural variations (date/number formats)\n",
    "        # 5. Return structured results\n",
    "        \n",
    "        patterns = self.language_patterns.get(language, self.language_patterns['en'])\n",
    "        \n",
    "        result = {\n",
    "            'language': language,\n",
    "            'invoice_number': None,\n",
    "            'total_amount': None,\n",
    "            'dates': [],\n",
    "            'vendor_info': None,\n",
    "            'confidence_scores': {}\n",
    "        }\n",
    "        \n",
    "        # Your extraction code here:\n",
    "        \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_multilingual_document(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete multilingual document processing pipeline.\n",
    "        \n",
    "        Args:\n",
    "            text: Document text to process\n",
    "            \n",
    "        Returns:\n",
    "            Complete processing results\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        result = {\n",
    "            'original_language': 'unknown',\n",
    "            'language_confidence': 0.0,\n",
    "            'original_extraction': {},\n",
    "            'translated_text': '',\n",
    "            'translation_confidence': 0.0,\n",
    "            'unified_extraction': {},\n",
    "            'processing_time': 0.0,\n",
    "            'status': 'processing'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # TODO: Implement complete multilingual processing\n",
    "            # 1. Detect document language\n",
    "            # 2. Extract information in original language\n",
    "            # 3. Translate to English if needed\n",
    "            # 4. Extract information from translated text\n",
    "            # 5. Combine and validate results\n",
    "            # 6. Return unified output\n",
    "            \n",
    "            # Your processing pipeline here:\n",
    "            \n",
    "            \n",
    "            result['status'] = 'completed'\n",
    "            result['processing_time'] = time.time() - start_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            result['status'] = 'failed'\n",
    "            result['error'] = str(e)\n",
    "            result['processing_time'] = time.time() - start_time\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Create multi-language processor\n",
    "print(\"Creating multi-language processor...\")\n",
    "multilang_processor = MultiLanguageProcessor()\nprint(\"âœ… Multi-language processor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Model Optimization and Performance Tuning (20 minutes)\n",
    "\n",
    "Optimize AI models for production performance and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Implement Model Optimization Pipeline\n",
    "\n",
    "**Your Task**: Create a comprehensive model optimization system for production deployment.\n",
    "\n",
    "**Requirements**:\n",
    "- Model quantization for faster inference\n",
    "- Intelligent caching with LRU eviction\n",
    "- Batch processing optimization\n",
    "- Memory management and cleanup\n",
    "- Performance monitoring and profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Task 2.2: Analyze and Optimize BLIP-2 Q-former Architecture (15 minutes)\n\n**Assessment Focus**: This task directly addresses **Assessment Question 3** about BLIP-2's Q-former role in vision tasks.\n\n**Your Task**: Implement Q-former analysis and visualization tools to understand how BLIP-2 bridges vision and language modalities for invoice processing.\n\n**Requirements**:\n- Extract and visualize Q-former attention patterns for invoice documents\n- Analyze query embedding interactions with visual features\n- Compare performance with direct vision-to-language approaches\n- Optimize Q-former parameters for invoice-specific processing\n- Demonstrate business impact of Q-former architecture\n\n**Learning Outcomes**:\n- Understand cross-attention mechanisms in multimodal AI\n- Visualize how Q-former queries extract relevant information\n- Optimize multimodal models for specific document types\n- Appreciate the architectural innovation that makes BLIP-2 effective\n\n**Why This Matters for Production**:\nBLIP-2's Q-former is the key innovation that enables efficient vision-language understanding without expensive joint training. Understanding its architecture is crucial for optimizing document AI systems and knowing when to use BLIP-2 vs alternatives.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn.functional as F\nfrom transformers import Blip2Processor, Blip2ForConditionalGeneration\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom PIL import Image, ImageDraw\nimport cv2\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass QformerAnalysisResult:\n    \"\"\"Results from Q-former architecture analysis\"\"\"\n    attention_patterns: Dict[str, np.ndarray]\n    query_specializations: Dict[int, Dict[str, float]]\n    architectural_insights: Dict[str, Any]\n    performance_metrics: Dict[str, float]\n    business_impact: Dict[str, Any]\n\nclass QformerDocumentAnalyzer:\n    \"\"\"Advanced Q-former analysis for document understanding optimization\"\"\"\n    \n    def __init__(self):\n        self.model = None\n        self.processor = None\n        self.is_available = False\n        self._load_model()\n    \n    def _load_model(self):\n        \"\"\"Load BLIP-2 model for Q-former analysis\"\"\"\n        try:\n            # TODO: Load BLIP-2 model for analysis\n            # 1. Load pre-trained BLIP-2 (smaller variant for memory efficiency)\n            # 2. Set model to evaluation mode\n            # 3. Move to GPU if available\n            # 4. Enable attention extraction hooks\n            \n            print(\"Loading BLIP-2 model for Q-former analysis...\")\n            \n            # Your model loading code here:\n            # self.processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n            # self.model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16)\n            \n            \n            self.is_available = True\n            print(\"âœ… BLIP-2 model loaded for Q-former analysis\")\n            \n        except Exception as e:\n            print(f\"âš ï¸ BLIP-2 not available for analysis: {e}\")\n            self.is_available = False\n    \n    def explain_qformer_architecture(self):\n        \"\"\"\n        Provide detailed explanation of Q-former architecture.\n        \n        This method explains the key components and innovations of Q-former\n        for Assessment Question 3.\n        \"\"\"\n        print(\"ðŸ—ï¸ Q-FORMER ARCHITECTURE EXPLANATION\")\n        print(\"=\" * 60)\n        \n        print(\"\\\\nðŸ“‹ ASSESSMENT QUESTION 3: What is the role of BLIP-2's Q-former in vision tasks?\")\n        print(\"-\" * 60)\n        \n        # TODO: Implement comprehensive Q-former explanation\n        # 1. Explain the architectural components\n        # 2. Describe the query mechanism\n        # 3. Show cross-attention and self-attention roles\n        # 4. Explain why it's better than alternatives\n        # 5. Demonstrate with invoice processing examples\n        \n        print(\"\\\\nðŸ”‘ KEY ANSWER POINTS:\")\n        print(\"1. Q-former queries image embeddings to generate textual outputs\")\n        print(\"2. Uses cross-attention to extract relevant visual information\")\n        print(\"3. Uses self-attention to integrate information between queries\")\n        print(\"4. Enables efficient training by keeping vision/language models frozen\")\n        print(\"5. Provides scalable bridge between vision and language modalities\")\n        \n        architecture_components = {\n            \"Learnable Queries (32 vectors)\": {\n                \"role\": \"Extract specific information from image features\",\n                \"size\": \"32 x 768 embeddings\",\n                \"advantage\": \"Fixed computational cost regardless of image size\",\n                \"invoice_application\": \"Specialized queries for headers, line items, totals\"\n            },\n            \"Cross-Attention Mechanism\": {\n                \"role\": \"Allow queries to attend to relevant image regions\",\n                \"mechanism\": \"Queries attend to 196 ViT patch features (14x14 grid)\",\n                \"advantage\": \"Selective information extraction, not dense combination\",\n                \"invoice_application\": \"Focus on document structure and layout patterns\"\n            },\n            \"Self-Attention Integration\": {\n                \"role\": \"Enable information sharing between queries\",\n                \"mechanism\": \"Queries communicate to build coherent understanding\",\n                \"advantage\": \"Holistic document understanding with relationships\",\n                \"invoice_application\": \"Connect vendor info with amounts, dates with items\"\n            }\n        }\n        \n        print(\"\\\\nðŸ“Š ARCHITECTURAL COMPONENTS:\")\n        for component, details in architecture_components.items():\n            print(f\"\\\\nðŸ”¸ {component}:\")\n            for key, value in details.items():\n                print(f\"   {key.title()}: {value}\")\n        \n        # Your additional explanation code here:\n        \n        \n        return architecture_components\n    \n    def analyze_attention_patterns(self, image: Image.Image, question: str) -> Dict[str, Any]:\n        \"\"\"\n        Analyze Q-former attention patterns for invoice processing.\n        \n        Args:\n            image: Invoice image to analyze\n            question: Question to ask about the invoice\n            \n        Returns:\n            Attention pattern analysis results\n        \"\"\"\n        if not self.is_available:\n            print(\"âš ï¸ BLIP-2 model not available for attention analysis\")\n            return self._create_mock_attention_analysis()\n        \n        print(f\"ðŸ” Analyzing Q-former attention patterns...\")\n        print(f\"Question: {question}\")\n        \n        try:\n            # TODO: Implement attention pattern extraction\n            # 1. Process image and question through BLIP-2\n            # 2. Extract attention weights from Q-former layers\n            # 3. Analyze cross-attention patterns (queries â†’ image)\n            # 4. Analyze self-attention patterns (queries â†’ queries)\n            # 5. Visualize attention on image regions\n            \n            # Your attention analysis code here:\n            \n            \n            return self._create_mock_attention_analysis()\n            \n        except Exception as e:\n            print(f\"Error in attention analysis: {e}\")\n            return self._create_mock_attention_analysis()\n    \n    def _create_mock_attention_analysis(self) -> Dict[str, Any]:\n        \"\"\"Create realistic mock attention analysis for demonstration\"\"\"\n        return {\n            \"cross_attention_patterns\": {\n                \"query_1_4_header\": {\"attention_score\": 0.85, \"top_regions\": [\"top-left\", \"top-center\"]},\n                \"query_5_12_billing\": {\"attention_score\": 0.78, \"top_regions\": [\"upper-left\", \"center-left\"]},\n                \"query_13_24_items\": {\"attention_score\": 0.92, \"top_regions\": [\"center\", \"lower-center\"]},\n                \"query_25_32_totals\": {\"attention_score\": 0.89, \"top_regions\": [\"bottom-right\", \"center-right\"]}\n            },\n            \"self_attention_strength\": 0.74,\n            \"query_specialization_score\": 0.87,\n            \"information_integration_score\": 0.82\n        }\n    \n    def compare_architectures(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Compare Q-former with alternative vision-language architectures.\n        \n        This addresses the comparative understanding needed for Assessment Question 3.\n        \"\"\"\n        print(\"\\\\nðŸ“Š ARCHITECTURAL COMPARISON FOR ASSESSMENT\")\n        print(\"=\" * 60)\n        \n        # TODO: Implement comprehensive architectural comparison\n        # 1. Define comparison metrics\n        # 2. Analyze training efficiency\n        # 3. Compare inference performance\n        # 4. Evaluate scalability\n        # 5. Assess document-specific performance\n        \n        architectures = {\n            \"BLIP-2 Q-former\": {\n                \"training_paradigm\": \"Frozen encoders + trainable bridge\",\n                \"parameters_trained\": \"32M (Q-former only)\",\n                \"vision_language_coupling\": \"Explicit queries bridge modalities\",\n                \"document_suitability\": \"Excellent - query specialization\",\n                \"efficiency_score\": 9.5,\n                \"accuracy_score\": 9.0,\n                \"scalability_score\": 9.0,\n                \"key_advantage\": \"Efficient training with superior performance\"\n            },\n            \"End-to-End Joint Training\": {\n                \"training_paradigm\": \"All components trained together\",\n                \"parameters_trained\": \"Billions (entire model)\",\n                \"vision_language_coupling\": \"Implicit feature fusion\",\n                \"document_suitability\": \"Good but resource intensive\",\n                \"efficiency_score\": 4.0,\n                \"accuracy_score\": 8.5,\n                \"scalability_score\": 6.0,\n                \"key_advantage\": \"Can achieve high accuracy with massive data\"\n            },\n            \"CLIP-style Contrastive\": {\n                \"training_paradigm\": \"Contrastive vision-text learning\",\n                \"parameters_trained\": \"400M+ (both encoders)\",\n                \"vision_language_coupling\": \"Similarity in joint space\",\n                \"document_suitability\": \"Poor - not designed for generation\",\n                \"efficiency_score\": 7.0,\n                \"accuracy_score\": 6.0,\n                \"scalability_score\": 8.0,\n                \"key_advantage\": \"Good for image-text matching tasks\"\n            }\n        }\n        \n        print(\"\\\\nðŸ† COMPARISON RESULTS:\")\n        for arch_name, metrics in architectures.items():\n            print(f\"\\\\nðŸ“‹ {arch_name}:\")\n            print(f\"   Training: {metrics['training_paradigm']}\")\n            print(f\"   Parameters: {metrics['parameters_trained']}\")\n            print(f\"   Document Suitability: {metrics['document_suitability']}\")\n            print(f\"   Efficiency: {metrics['efficiency_score']}/10\")\n            print(f\"   Accuracy: {metrics['accuracy_score']}/10\")\n            print(f\"   Advantage: {metrics['key_advantage']}\")\n        \n        # Your comparison implementation here:\n        \n        \n        return architectures\n    \n    def optimize_for_invoices(self, sample_invoices: List[Image.Image]) -> Dict[str, Any]:\n        \"\"\"\n        Demonstrate Q-former optimization for invoice-specific processing.\n        \n        Args:\n            sample_invoices: List of invoice images for optimization\n            \n        Returns:\n            Optimization results and recommendations\n        \"\"\"\n        print(\"\\\\nâš¡ Q-FORMER OPTIMIZATION FOR INVOICE PROCESSING\")\n        print(\"=\" * 60)\n        \n        optimization_results = {\n            \"baseline_performance\": {},\n            \"optimized_performance\": {},\n            \"optimization_strategies\": [],\n            \"business_impact\": {}\n        }\n        \n        # TODO: Implement invoice-specific optimization\n        # 1. Analyze current performance on invoices\n        # 2. Identify optimization opportunities\n        # 3. Implement query specialization\n        # 4. Measure performance improvements\n        # 5. Calculate business impact\n        \n        print(\"\\\\nðŸŽ¯ OPTIMIZATION STRATEGIES:\")\n        strategies = [\n            {\n                \"name\": \"Query Specialization Training\",\n                \"description\": \"Train queries to specialize in invoice components\",\n                \"expected_improvement\": \"25-30% accuracy gain on specific fields\",\n                \"implementation\": \"Fine-tune with invoice-structured objectives\"\n            },\n            {\n                \"name\": \"Attention Pattern Optimization\",\n                \"description\": \"Optimize attention for document layouts\",\n                \"expected_improvement\": \"40% faster inference with maintained accuracy\",\n                \"implementation\": \"Sparse attention patterns, region-aware masking\"\n            },\n            {\n                \"name\": \"Multi-Resolution Processing\",\n                \"description\": \"Process at multiple scales simultaneously\",\n                \"expected_improvement\": \"Better handling of fine details and structure\",\n                \"implementation\": \"Hierarchical Q-former with different input scales\"\n            }\n        ]\n        \n        for i, strategy in enumerate(strategies, 1):\n            print(f\"\\\\n{i}. {strategy['name']}:\")\n            print(f\"   Description: {strategy['description']}\")\n            print(f\"   Expected Improvement: {strategy['expected_improvement']}\")\n            print(f\"   Implementation: {strategy['implementation']}\")\n        \n        # Mock business impact calculation\n        optimization_results[\"business_impact\"] = {\n            \"accuracy_improvement\": \"25-40%\",\n            \"processing_speed\": \"1.5-2x faster\",\n            \"cost_reduction\": \"60-80% vs alternatives\",\n            \"roi_timeline\": \"3-6 months\"\n        }\n        \n        # Your optimization implementation here:\n        \n        \n        return optimization_results\n    \n    def demonstrate_business_impact(self) -> Dict[str, Any]:\n        \"\"\"\n        Demonstrate the business impact of Q-former architecture for invoice processing.\n        \n        This shows why understanding Q-former is crucial for production systems.\n        \"\"\"\n        print(\"\\\\nðŸ’¼ BUSINESS IMPACT OF Q-FORMER ARCHITECTURE\")\n        print(\"=\" * 60)\n        \n        # TODO: Calculate and demonstrate business impact\n        # 1. Compare costs with alternatives\n        # 2. Show accuracy improvements\n        # 3. Demonstrate scalability benefits\n        # 4. Calculate ROI for enterprise deployment\n        \n        impact_analysis = {\n            \"cost_comparison\": {\n                \"manual_processing\": \"$5-15 per invoice\",\n                \"traditional_ocr\": \"$0.50-2.00 per invoice\", \n                \"blip2_qformer\": \"$0.10-0.30 per invoice\",\n                \"gpt4_vision\": \"$2-8 per invoice\"\n            },\n            \"accuracy_comparison\": {\n                \"manual_processing\": \"95-99% (with human errors)\",\n                \"traditional_ocr\": \"75-85% (layout issues)\",\n                \"blip2_qformer\": \"92-97% (with optimization)\",\n                \"gpt4_vision\": \"95-98% (but expensive)\"\n            },\n            \"scalability_benefits\": {\n                \"training_efficiency\": \"Only 32M parameters vs billions\",\n                \"inference_speed\": \"2-5 seconds per invoice\",\n                \"resource_requirements\": \"Single GPU can handle 1000s/hour\",\n                \"customization\": \"Easy to adapt for specific layouts\"\n            }\n        }\n        \n        print(\"\\\\nðŸ’° COST ANALYSIS:\")\n        for method, cost in impact_analysis[\"cost_comparison\"].items():\n            print(f\"   {method}: {cost}\")\n        \n        print(\"\\\\nðŸŽ¯ ACCURACY COMPARISON:\")\n        for method, accuracy in impact_analysis[\"accuracy_comparison\"].items():\n            print(f\"   {method}: {accuracy}\")\n        \n        print(\"\\\\nðŸ“ˆ Q-FORMER ADVANTAGES:\")\n        print(\"âœ… 90-95% cost reduction vs manual processing\")\n        print(\"âœ… 80-90% cost reduction vs GPT-4 Vision\")\n        print(\"âœ… 15-25% accuracy improvement vs traditional OCR\")\n        print(\"âœ… 100x faster training than end-to-end approaches\")\n        print(\"âœ… Scalable to millions of documents\")\n        \n        # Your business impact analysis here:\n        \n        \n        return impact_analysis\n    \n    def generate_assessment_summary(self) -> str:\n        \"\"\"Generate summary answer for Assessment Question 3\"\"\"\n        summary = '''\nðŸ“‹ ASSESSMENT QUESTION 3 ANSWER SUMMARY:\n\n\"What is the role of BLIP-2's Q-former in vision tasks?\"\n\nðŸ”‘ KEY ANSWER POINTS:\n\n1. **Query-Based Information Extraction**: Q-former uses 32 learnable query embeddings to extract specific information from visual features, acting as specialized \"information extractors.\"\n\n2. **Cross-Modal Bridge**: Q-former serves as a trainable bridge between frozen vision encoders and language models, enabling efficient multimodal understanding without expensive joint training.\n\n3. **Dual Attention Mechanism**: \n   - Cross-attention allows queries to selectively attend to relevant image regions\n   - Self-attention enables queries to integrate and share information with each other\n\n4. **Scalable Architecture**: Fixed computational cost regardless of image complexity, with only 32M trainable parameters vs billions in alternatives.\n\n5. **Document Understanding**: For invoices, queries specialize in different document regions (headers, line items, totals), providing structured information extraction.\n\nðŸ’¡ WHY IT MATTERS: Q-former enables BLIP-2 to achieve superior performance while being training-efficient, making it ideal for production document AI systems.\n'''\n        return summary\n\n# Create Q-former analyzer\nprint(\"Creating Q-former document analyzer...\")\nqformer_analyzer = QformerDocumentAnalyzer()\n\n# Run comprehensive Q-former analysis\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"TASK 2.2: Q-FORMER ARCHITECTURE ANALYSIS\")\nprint(\"=\"*80)\n\n# Explain architecture (addresses Assessment Question 3)\narchitecture_explanation = qformer_analyzer.explain_qformer_architecture()\n\n# Compare with alternatives\narchitecture_comparison = qformer_analyzer.compare_architectures()\n\n# Demonstrate business impact\nbusiness_impact = qformer_analyzer.demonstrate_business_impact()\n\n# Generate assessment summary\nassessment_summary = qformer_analyzer.generate_assessment_summary()\nprint(assessment_summary)\n\nprint(\"\\\\nâœ… Q-former analysis completed - Assessment Question 3 comprehensively covered!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from optimum.onnxruntime import ORTModelForTokenClassification\n",
    "import psutil\n",
    "import gc\n",
    "from collections import OrderedDict\n",
    "import threading\n",
    "from typing import Any, Callable\n",
    "\nclass LRUCache:\n",
    "    \"\"\"Thread-safe LRU cache implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity: int = 1000):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "        self.lock = threading.Lock()\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get(self, key: str) -> Any:\n",
    "        \"\"\"Get item from cache\"\"\"\n",
    "        with self.lock:\n",
    "            if key in self.cache:\n",
    "                # Move to end (most recently used)\n",
    "                self.cache.move_to_end(key)\n",
    "                self.hits += 1\n",
    "                return self.cache[key]\n",
    "            else:\n",
    "                self.misses += 1\n",
    "                return None\n",
    "    \n",
    "    def put(self, key: str, value: Any) -> None:\n",
    "        \"\"\"Put item in cache\"\"\"\n",
    "        with self.lock:\n",
    "            if key in self.cache:\n",
    "                self.cache.move_to_end(key)\n",
    "            else:\n",
    "                if len(self.cache) >= self.capacity:\n",
    "                    # Remove least recently used\n",
    "                    self.cache.popitem(last=False)\n",
    "            self.cache[key] = value\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        total_requests = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total_requests * 100) if total_requests > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'size': len(self.cache),\n",
    "            'capacity': self.capacity,\n",
    "            'hits': self.hits,\n",
    "            'misses': self.misses,\n",
    "            'hit_rate': hit_rate\n",
    "        }\n",
    "\nclass ModelOptimizer:\n",
    "    \"\"\"Advanced model optimization for production deployment\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_size: int = 1000):\n",
    "        self.cache = LRUCache(cache_size)\n",
    "        self.models = {}\n",
    "        self.performance_metrics = defaultdict(list)\n",
    "        self.memory_monitor = MemoryMonitor()\n",
    "    \n",
    "    def quantize_model(self, model_name: str, quantization_type: str = \"dynamic\") -> str:\n",
    "        \"\"\"\n",
    "        Quantize model for faster inference.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name\n",
    "            quantization_type: Type of quantization (dynamic, static, qint8)\n",
    "            \n",
    "        Returns:\n",
    "            Path to quantized model\n",
    "        \"\"\"\n",
    "        # TODO: Implement model quantization\n",
    "        # 1. Load original model\n",
    "        # 2. Apply quantization technique\n",
    "        # 3. Save quantized model\n",
    "        # 4. Validate performance\n",
    "        # 5. Return optimized model path\n",
    "        \n",
    "        print(f\"Quantizing model {model_name} with {quantization_type} quantization...\")\n",
    "        \n",
    "        try:\n",
    "            # Your quantization code here:\n",
    "            \n",
    "            \n",
    "            quantized_path = f\"./models/{model_name}_quantized\"\n",
    "            return quantized_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Quantization failed: {e}\")\n",
    "            return model_name  # Fallback to original\n",
    "    \n",
    "    def load_optimized_model(self, model_name: str, task: str = \"ner\") -> Any:\n",
    "        \"\"\"\n",
    "        Load model with all optimizations applied.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Model to load\n",
    "            task: Task type for pipeline\n",
    "            \n",
    "        Returns:\n",
    "            Optimized model pipeline\n",
    "        \"\"\"\n",
    "        cache_key = f\"{model_name}_{task}\"\n",
    "        \n",
    "        # Check cache first\n",
    "        cached_model = self.cache.get(cache_key)\n",
    "        if cached_model:\n",
    "            return cached_model\n",
    "        \n",
    "        # TODO: Load and optimize model\n",
    "        # 1. Try to load quantized version\n",
    "        # 2. Fallback to original if needed\n",
    "        # 3. Apply additional optimizations\n",
    "        # 4. Cache the optimized model\n",
    "        \n",
    "        try:\n",
    "            # Your model loading and optimization here:\n",
    "            \n",
    "            \n",
    "            # Create pipeline with optimizations\n",
    "            model_pipeline = pipeline(\n",
    "                task,\n",
    "                model=model_name,\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                # Add optimization parameters\n",
    "            )\n",
    "            \n",
    "            # Cache the model\n",
    "            self.cache.put(cache_key, model_pipeline)\n",
    "            \n",
    "            return model_pipeline\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Model loading failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def benchmark_model(self, model_pipeline: Any, test_inputs: List[str], runs: int = 10) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Benchmark model performance with various inputs.\n",
    "        \n",
    "        Args:\n",
    "            model_pipeline: Model to benchmark\n",
    "            test_inputs: List of test inputs\n",
    "            runs: Number of benchmark runs\n",
    "            \n",
    "        Returns:\n",
    "            Performance metrics\n",
    "        \"\"\"\n",
    "        # TODO: Implement comprehensive benchmarking\n",
    "        # 1. Warm up model with test runs\n",
    "        # 2. Measure inference times\n",
    "        # 3. Monitor memory usage\n",
    "        # 4. Calculate throughput\n",
    "        # 5. Return detailed metrics\n",
    "        \n",
    "        if not model_pipeline or not test_inputs:\n",
    "            return {}\n",
    "        \n",
    "        metrics = {\n",
    "            'avg_inference_time': 0.0,\n",
    "            'min_inference_time': float('inf'),\n",
    "            'max_inference_time': 0.0,\n",
    "            'throughput': 0.0,\n",
    "            'memory_usage': 0.0\n",
    "        }\n",
    "        \n",
    "        # Your benchmarking code here:\n",
    "        \n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def optimize_batch_processing(self, model_pipeline: Any, inputs: List[str], batch_size: int = 8) -> List[Any]:\n",
    "        \"\"\"\n",
    "        Optimize batch processing for better throughput.\n",
    "        \n",
    "        Args:\n",
    "            model_pipeline: Model to use\n",
    "            inputs: List of inputs to process\n",
    "            batch_size: Optimal batch size\n",
    "            \n",
    "        Returns:\n",
    "            Batch processing results\n",
    "        \"\"\"\n",
    "        # TODO: Implement optimized batch processing\n",
    "        # 1. Group inputs into optimal batches\n",
    "        # 2. Process batches with memory management\n",
    "        # 3. Handle variable-length inputs\n",
    "        # 4. Collect and merge results\n",
    "        # 5. Monitor performance\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Your batch processing code here:\n",
    "        \n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def cleanup_memory(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Clean up memory and return memory statistics.\n",
    "        \n",
    "        Returns:\n",
    "            Memory statistics before and after cleanup\n",
    "        \"\"\"\n",
    "        # TODO: Implement comprehensive memory cleanup\n",
    "        # 1. Record initial memory usage\n",
    "        # 2. Clear model caches\n",
    "        # 3. Run garbage collection\n",
    "        # 4. Clear GPU memory if available\n",
    "        # 5. Return memory statistics\n",
    "        \n",
    "        before_memory = self.memory_monitor.get_memory_usage()\n",
    "        \n",
    "        # Your cleanup code here:\n",
    "        \n",
    "        \n",
    "        after_memory = self.memory_monitor.get_memory_usage()\n",
    "        \n",
    "        return {\n",
    "            'before_cleanup': before_memory,\n",
    "            'after_cleanup': after_memory,\n",
    "            'memory_freed': before_memory['ram_used'] - after_memory['ram_used']\n",
    "        }\n",
    "    \n",
    "    def get_optimization_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive optimization report\"\"\"\n",
    "        return {\n",
    "            'cache_stats': self.cache.get_stats(),\n",
    "            'memory_stats': self.memory_monitor.get_memory_usage(),\n",
    "            'models_loaded': len(self.models),\n",
    "            'performance_metrics': dict(self.performance_metrics)\n",
    "        }\n",
    "\nclass MemoryMonitor:\n",
    "    \"\"\"Monitor system and GPU memory usage\"\"\"\n",
    "    \n",
    "    def get_memory_usage(self) -> Dict[str, float]:\n",
    "        \"\"\"Get current memory usage statistics\"\"\"\n",
    "        # System memory\n",
    "        ram = psutil.virtual_memory()\n",
    "        \n",
    "        stats = {\n",
    "            'ram_total': ram.total / (1024**3),  # GB\n",
    "            'ram_used': ram.used / (1024**3),\n",
    "            'ram_percent': ram.percent\n",
    "        }\n",
    "        \n",
    "        # GPU memory if available\n",
    "        if torch.cuda.is_available():\n",
    "            stats.update({\n",
    "                'gpu_allocated': torch.cuda.memory_allocated() / (1024**3),\n",
    "                'gpu_reserved': torch.cuda.memory_reserved() / (1024**3)\n",
    "            })\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Create model optimizer\n",
    "print(\"Creating model optimizer...\")\n",
    "model_optimizer = ModelOptimizer(cache_size=100)\nprint(\"âœ… Model optimizer created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Advanced Quality Assurance and Error Recovery (20 minutes)\n",
    "\n",
    "Build comprehensive QA and error recovery systems for production reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Implement Advanced Quality Assurance System\n",
    "\n",
    "**Your Task**: Create a comprehensive quality assurance system with automated error detection and recovery.\n",
    "\n",
    "**Requirements**:\n",
    "- Multi-dimensional quality scoring\n",
    "- Automated error detection and classification\n",
    "- Self-healing mechanisms\n",
    "- Quality trend analysis\n",
    "- Alerting and notification systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "import statistics\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\nclass QualityLevel(Enum):\n",
    "    EXCELLENT = \"excellent\"\n",
    "    GOOD = \"good\"\n",
    "    ACCEPTABLE = \"acceptable\"\n",
    "    POOR = \"poor\"\n",
    "    UNACCEPTABLE = \"unacceptable\"\n",
    "\nclass ErrorSeverity(Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n@dataclass\n",
    "class QualityMetrics:\n",
    "    \"\"\"Comprehensive quality metrics for document processing\"\"\"\n",
    "    overall_score: float = 0.0\n",
    "    confidence_score: float = 0.0\n",
    "    completeness_score: float = 0.0\n",
    "    accuracy_score: float = 0.0\n",
    "    consistency_score: float = 0.0\n",
    "    processing_speed_score: float = 0.0\n",
    "    \n",
    "    # Component scores\n",
    "    ocr_quality: float = 0.0\n",
    "    extraction_quality: float = 0.0\n",
    "    validation_quality: float = 0.0\n",
    "    \n",
    "    # Error indicators\n",
    "    errors_detected: List[str] = field(default_factory=list)\n",
    "    warnings_detected: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Metadata\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    processing_time: float = 0.0\n",
    "    \n",
    "    def get_quality_level(self) -> QualityLevel:\n",
    "        \"\"\"Determine overall quality level\"\"\"\n",
    "        if self.overall_score >= 95:\n",
    "            return QualityLevel.EXCELLENT\n",
    "        elif self.overall_score >= 85:\n",
    "            return QualityLevel.GOOD\n",
    "        elif self.overall_score >= 70:\n",
    "            return QualityLevel.ACCEPTABLE\n",
    "        elif self.overall_score >= 50:\n",
    "            return QualityLevel.POOR\n",
    "        else:\n",
    "            return QualityLevel.UNACCEPTABLE\n",
    "\n@dataclass\n",
    "class ProcessingError:\n",
    "    \"\"\"Detailed error information\"\"\"\n",
    "    error_id: str\n",
    "    error_type: str\n",
    "    severity: ErrorSeverity\n",
    "    message: str\n",
    "    component: str\n",
    "    timestamp: str\n",
    "    context: Dict[str, Any] = field(default_factory=dict)\n",
    "    recovery_attempted: bool = False\n",
    "    recovery_successful: bool = False\n",
    "    recovery_method: Optional[str] = None\n",
    "\nclass AdvancedQualityAssurance:\n",
    "    \"\"\"Comprehensive quality assurance system with error recovery\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.quality_history = []\n",
    "        self.error_history = []\n",
    "        self.quality_thresholds = self._initialize_thresholds()\n",
    "        self.recovery_strategies = self._initialize_recovery_strategies()\n",
    "        self.alert_handlers = []\n",
    "    \n",
    "    def _initialize_thresholds(self) -> Dict[str, float]:\n",
    "        \"\"\"Initialize quality thresholds for different metrics\"\"\"\n",
    "        return {\n",
    "            'min_overall_score': 70.0,\n",
    "            'min_confidence': 60.0,\n",
    "            'min_completeness': 80.0,\n",
    "            'max_processing_time': 10.0,\n",
    "            'min_ocr_quality': 75.0,\n",
    "            'min_extraction_quality': 70.0\n",
    "        }\n",
    "    \n",
    "    def _initialize_recovery_strategies(self) -> Dict[str, Callable]:\n",
    "        \"\"\"Initialize error recovery strategies\"\"\"\n",
    "        return {\n",
    "            'poor_ocr_quality': self._recover_poor_ocr,\n",
    "            'extraction_failure': self._recover_extraction_failure,\n",
    "            'validation_errors': self._recover_validation_errors,\n",
    "            'timeout_error': self._recover_timeout,\n",
    "            'memory_error': self._recover_memory_error\n",
    "        }\n",
    "    \n",
    "    def assess_processing_quality(self, processing_result: Dict[str, Any]) -> QualityMetrics:\n",
    "        \"\"\"\n",
    "        Perform comprehensive quality assessment of processing results.\n",
    "        \n",
    "        Args:\n",
    "            processing_result: Complete processing result to assess\n",
    "            \n",
    "        Returns:\n",
    "            Detailed quality metrics\n",
    "        \"\"\"\n",
    "        # TODO: Implement comprehensive quality assessment\n",
    "        # 1. Assess OCR quality (confidence, text coherence)\n",
    "        # 2. Evaluate extraction completeness and accuracy\n",
    "        # 3. Check validation consistency\n",
    "        # 4. Analyze processing performance\n",
    "        # 5. Calculate composite quality scores\n",
    "        \n",
    "        metrics = QualityMetrics()\n",
    "        \n",
    "        try:\n",
    "            # Your quality assessment code here:\n",
    "            \n",
    "            \n",
    "            # Calculate overall score\n",
    "            metrics.overall_score = self._calculate_overall_score(metrics)\n",
    "            \n",
    "        except Exception as e:\n",
    "            metrics.errors_detected.append(f\"Quality assessment failed: {str(e)}\")\n",
    "            metrics.overall_score = 0.0\n",
    "        \n",
    "        # Store in history\n",
    "        self.quality_history.append(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_overall_score(self, metrics: QualityMetrics) -> float:\n",
    "        \"\"\"Calculate weighted overall quality score\"\"\"\n",
    "        # TODO: Implement weighted scoring algorithm\n",
    "        # 1. Define weights for different quality dimensions\n",
    "        # 2. Apply penalties for errors and warnings\n",
    "        # 3. Consider processing time impact\n",
    "        # 4. Calculate weighted average\n",
    "        \n",
    "        weights = {\n",
    "            'confidence': 0.25,\n",
    "            'completeness': 0.20,\n",
    "            'accuracy': 0.25,\n",
    "            'consistency': 0.15,\n",
    "            'speed': 0.15\n",
    "        }\n",
    "        \n",
    "        # Your scoring calculation here:\n",
    "        \n",
    "        \n",
    "        return 85.0  # Default score\n",
    "    \n",
    "    def detect_and_classify_errors(self, processing_result: Dict[str, Any]) -> List[ProcessingError]:\n",
    "        \"\"\"\n",
    "        Detect and classify errors in processing results.\n",
    "        \n",
    "        Args:\n",
    "            processing_result: Processing result to analyze\n",
    "            \n",
    "        Returns:\n",
    "            List of detected and classified errors\n",
    "        \"\"\"\n",
    "        # TODO: Implement comprehensive error detection\n",
    "        # 1. Scan for common error patterns\n",
    "        # 2. Classify errors by type and severity\n",
    "        # 3. Extract error context information\n",
    "        # 4. Determine recovery possibilities\n",
    "        \n",
    "        detected_errors = []\n",
    "        \n",
    "        # Your error detection code here:\n",
    "        \n",
    "        \n",
    "        return detected_errors\n",
    "    \n",
    "    def attempt_error_recovery(self, error: ProcessingError, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Attempt to recover from detected error.\n",
    "        \n",
    "        Args:\n",
    "            error: Error to recover from\n",
    "            context: Processing context for recovery\n",
    "            \n",
    "        Returns:\n",
    "            Recovery result\n",
    "        \"\"\"\n",
    "        # TODO: Implement error recovery system\n",
    "        # 1. Select appropriate recovery strategy\n",
    "        # 2. Attempt recovery with fallbacks\n",
    "        # 3. Validate recovery success\n",
    "        # 4. Update error status\n",
    "        # 5. Log recovery attempt\n",
    "        \n",
    "        recovery_result = {\n",
    "            'attempted': False,\n",
    "            'successful': False,\n",
    "            'method': None,\n",
    "            'message': '',\n",
    "            'new_result': None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Your recovery implementation here:\n",
    "            \n",
    "            \n",
    "            error.recovery_attempted = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            recovery_result['message'] = f\"Recovery failed: {str(e)}\"\n",
    "        \n",
    "        return recovery_result\n",
    "    \n",
    "    def _recover_poor_ocr(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Recover from poor OCR quality\"\"\"\n",
    "        # TODO: Implement OCR recovery strategies\n",
    "        # 1. Try different preprocessing\n",
    "        # 2. Use alternative OCR engine\n",
    "        # 3. Adjust OCR parameters\n",
    "        # 4. Apply image enhancement\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _recover_extraction_failure(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Recover from extraction failures\"\"\"\n",
    "        # TODO: Implement extraction recovery\n",
    "        # 1. Fallback to pattern-based extraction\n",
    "        # 2. Use different model\n",
    "        # 3. Apply alternative processing\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _recover_validation_errors(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Recover from validation errors\"\"\"\n",
    "        # TODO: Implement validation recovery\n",
    "        # 1. Adjust validation thresholds\n",
    "        # 2. Apply manual rules\n",
    "        # 3. Flag for human review\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _recover_timeout(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Recover from timeout errors\"\"\"\n",
    "        # TODO: Implement timeout recovery\n",
    "        # 1. Reduce processing complexity\n",
    "        # 2. Use faster models\n",
    "        # 3. Split processing into chunks\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _recover_memory_error(self, context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Recover from memory errors\"\"\"\n",
    "        # TODO: Implement memory recovery\n",
    "        # 1. Clear caches\n",
    "        # 2. Use smaller models\n",
    "        # 3. Process in smaller batches\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def generate_quality_report(self, time_period: timedelta = timedelta(hours=24)) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive quality report for specified time period.\n",
    "        \n",
    "        Args:\n",
    "            time_period: Time period for report\n",
    "            \n",
    "        Returns:\n",
    "            Quality report with trends and insights\n",
    "        \"\"\"\n",
    "        # TODO: Generate comprehensive quality report\n",
    "        # 1. Filter data by time period\n",
    "        # 2. Calculate quality trends\n",
    "        # 3. Analyze error patterns\n",
    "        # 4. Identify improvement opportunities\n",
    "        # 5. Generate actionable insights\n",
    "        \n",
    "        cutoff_time = datetime.now() - time_period\n",
    "        \n",
    "        recent_metrics = [\n",
    "            m for m in self.quality_history \n",
    "            if datetime.fromisoformat(m.timestamp) >= cutoff_time\n",
    "        ]\n",
    "        \n",
    "        if not recent_metrics:\n",
    "            return {'message': 'No data available for specified time period'}\n",
    "        \n",
    "        # Your report generation code here:\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'time_period': str(time_period),\n",
    "            'total_processed': len(recent_metrics),\n",
    "            'average_quality': 85.0,\n",
    "            'quality_trend': 'stable',\n",
    "            'top_issues': [],\n",
    "            'recommendations': []\n",
    "        }\n",
    "    \n",
    "    def setup_alerting(self, alert_handler: Callable[[str, Dict], None]):\n",
    "        \"\"\"Setup alerting for quality issues\"\"\"\n",
    "        self.alert_handlers.append(alert_handler)\n",
    "    \n",
    "    def check_and_alert(self, metrics: QualityMetrics):\n",
    "        \"\"\"Check metrics against thresholds and send alerts if needed\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # TODO: Implement alerting logic\n",
    "        # 1. Check all metrics against thresholds\n",
    "        # 2. Generate alerts for violations\n",
    "        # 3. Send alerts to handlers\n",
    "        \n",
    "        # Your alerting code here:\n",
    "        \n",
    "        \n",
    "        pass\n",
    "\n",
    "# Create advanced QA system\n",
    "print(\"Creating advanced quality assurance system...\")\n",
    "advanced_qa = AdvancedQualityAssurance()\nprint(\"âœ… Advanced QA system created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Production Integration and Deployment (20 minutes)\n",
    "\n",
    "Create the complete production-ready system with monitoring and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Build Production-Ready Master System\n",
    "\n",
    "**Your Task**: Integrate all advanced components into a production-ready invoice processing system.\n",
    "\n",
    "**Requirements**:\n",
    "- Integrate all optimization and QA components\n",
    "- Add comprehensive monitoring and analytics\n",
    "- Implement production-grade error handling\n",
    "- Create performance dashboards\n",
    "- Add system health monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import queue\n",
    "import json\n",
    "\n@dataclass\n",
    "class ProcessingRequest:\n",
    "    \"\"\"Complete processing request with metadata\"\"\"\n",
    "    request_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    file_path: str = \"\"\n",
    "    priority: str = \"normal\"  # low, normal, high, urgent\n",
    "    client_id: str = \"\"\n",
    "    created_at: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    processing_options: Dict[str, Any] = field(default_factory=dict)\n",
    "    callback_url: Optional[str] = None\n",
    "\n@dataclass\n",
    "class ProcessingResponse:\n",
    "    \"\"\"Complete processing response with all results\"\"\"\n",
    "    request_id: str\n",
    "    status: str  # processing, completed, failed, timeout\n",
    "    start_time: str\n",
    "    end_time: str\n",
    "    processing_time: float\n",
    "    \n",
    "    # Core results\n",
    "    extracted_data: Dict[str, Any] = field(default_factory=dict)\n",
    "    validation_results: Dict[str, Any] = field(default_factory=dict)\n",
    "    final_decision: str = \"\"\n",
    "    \n",
    "    # Quality and performance\n",
    "    quality_metrics: Optional[QualityMetrics] = None\n",
    "    performance_metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    \n",
    "    # Error and recovery\n",
    "    errors: List[ProcessingError] = field(default_factory=list)\n",
    "    recovery_attempts: List[Dict] = field(default_factory=list)\n",
    "    \n",
    "    # Audit trail\n",
    "    processing_steps: List[Dict] = field(default_factory=list)\n",
    "    system_metrics: Dict[str, Any] = field(default_factory=dict)\n",
    "\nclass ProductionInvoiceProcessor:\n",
    "    \"\"\"Production-ready invoice processing system with all advanced features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize all components\n",
    "        self.ocr_system = advanced_ocr\n",
    "        self.multilang_processor = multilang_processor\n",
    "        self.model_optimizer = model_optimizer\n",
    "        self.qa_system = advanced_qa\n",
    "        \n",
    "        # Processing queue and workers\n",
    "        self.processing_queue = queue.PriorityQueue()\n",
    "        self.response_cache = {}\n",
    "        self.worker_threads = []\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Monitoring and analytics\n",
    "        self.system_metrics = {\n",
    "            'total_requests': 0,\n",
    "            'successful_requests': 0,\n",
    "            'failed_requests': 0,\n",
    "            'average_processing_time': 0.0,\n",
    "            'throughput': 0.0,\n",
    "            'uptime_start': datetime.now()\n",
    "        }\n",
    "        \n",
    "        # Setup alerting\n",
    "        self.qa_system.setup_alerting(self._handle_quality_alert)\n",
    "    \n",
    "    def start_processing_workers(self, num_workers: int = 4):\n",
    "        \"\"\"\n",
    "        Start background processing workers.\n",
    "        \n",
    "        Args:\n",
    "            num_workers: Number of worker threads to start\n",
    "        \"\"\"\n",
    "        self.is_running = True\n",
    "        \n",
    "        for i in range(num_workers):\n",
    "            worker = threading.Thread(\n",
    "                target=self._worker_loop,\n",
    "                name=f\"Worker-{i+1}\",\n",
    "                daemon=True\n",
    "            )\n",
    "            worker.start()\n",
    "            self.worker_threads.append(worker)\n",
    "        \n",
    "        print(f\"âœ… Started {num_workers} processing workers\")\n",
    "    \n",
    "    def stop_processing_workers(self):\n",
    "        \"\"\"Stop all processing workers\"\"\"\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Add stop signals to queue\n",
    "        for _ in self.worker_threads:\n",
    "            self.processing_queue.put((0, None))  # High priority stop signal\n",
    "        \n",
    "        # Wait for workers to finish\n",
    "        for worker in self.worker_threads:\n",
    "            worker.join(timeout=5.0)\n",
    "        \n",
    "        print(\"âœ… All processing workers stopped\")\n",
    "    \n",
    "    def _worker_loop(self):\n",
    "        \"\"\"Main processing loop for worker threads\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                # Get next request from queue (with timeout)\n",
    "                priority, request = self.processing_queue.get(timeout=1.0)\n",
    "                \n",
    "                if request is None:  # Stop signal\n",
    "                    break\n",
    "                \n",
    "                # Process the request\n",
    "                response = self._process_request_internal(request)\n",
    "                \n",
    "                # Store response\n",
    "                self.response_cache[request.request_id] = response\n",
    "                \n",
    "                # Update metrics\n",
    "                self._update_system_metrics(response)\n",
    "                \n",
    "                # Mark task as done\n",
    "                self.processing_queue.task_done()\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue  # Timeout, check if still running\n",
    "            except Exception as e:\n",
    "                print(f\"Worker error: {e}\")\n",
    "                self.processing_queue.task_done()\n",
    "    \n",
    "    def submit_request(self, request: ProcessingRequest) -> str:\n",
    "        \"\"\"\n",
    "        Submit a processing request to the queue.\n",
    "        \n",
    "        Args:\n",
    "            request: Processing request to submit\n",
    "            \n",
    "        Returns:\n",
    "            Request ID for tracking\n",
    "        \"\"\"\n",
    "        # TODO: Implement request submission with prioritization\n",
    "        # 1. Validate request\n",
    "        # 2. Assign priority score\n",
    "        # 3. Add to processing queue\n",
    "        # 4. Return request ID\n",
    "        \n",
    "        priority_map = {'low': 4, 'normal': 3, 'high': 2, 'urgent': 1}\n",
    "        priority_score = priority_map.get(request.priority, 3)\n",
    "        \n",
    "        # Your request submission code here:\n",
    "        \n",
    "        \n",
    "        return request.request_id\n",
    "    \n",
    "    def get_request_status(self, request_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get status of a processing request.\n",
    "        \n",
    "        Args:\n",
    "            request_id: Request ID to check\n",
    "            \n",
    "        Returns:\n",
    "            Request status information\n",
    "        \"\"\"\n",
    "        if request_id in self.response_cache:\n",
    "            response = self.response_cache[request_id]\n",
    "            return {\n",
    "                'request_id': request_id,\n",
    "                'status': response.status,\n",
    "                'processing_time': response.processing_time,\n",
    "                'created_at': response.start_time\n",
    "            }\n",
    "        \n",
    "        # Check if still in queue\n",
    "        return {\n",
    "            'request_id': request_id,\n",
    "            'status': 'queued',\n",
    "            'queue_size': self.processing_queue.qsize()\n",
    "        }\n",
    "    \n",
    "    def _process_request_internal(self, request: ProcessingRequest) -> ProcessingResponse:\n",
    "        \"\"\"\n",
    "        Internal processing method with all advanced features.\n",
    "        \n",
    "        Args:\n",
    "            request: Request to process\n",
    "            \n",
    "        Returns:\n",
    "            Complete processing response\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        response = ProcessingResponse(\n",
    "            request_id=request.request_id,\n",
    "            status='processing',\n",
    "            start_time=start_time.isoformat(),\n",
    "            end_time='',\n",
    "            processing_time=0.0\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # TODO: Implement complete processing pipeline\n",
    "            # 1. Load and preprocess document\n",
    "            # 2. Run advanced OCR with multiple engines\n",
    "            # 3. Perform multi-language processing\n",
    "            # 4. Extract information with optimized models\n",
    "            # 5. Apply business rules validation\n",
    "            # 6. Perform quality assessment\n",
    "            # 7. Attempt error recovery if needed\n",
    "            # 8. Generate final decision\n",
    "            \n",
    "            # Step 1: Document ingestion\n",
    "            self._log_processing_step(response, \"document_ingestion\", \"starting\")\n",
    "            \n",
    "            # Your processing implementation here:\n",
    "            \n",
    "            \n",
    "            response.status = 'completed'\n",
    "            \n",
    "        except Exception as e:\n",
    "            response.status = 'failed'\n",
    "            error = ProcessingError(\n",
    "                error_id=str(uuid.uuid4()),\n",
    "                error_type='processing_failure',\n",
    "                severity=ErrorSeverity.HIGH,\n",
    "                message=str(e),\n",
    "                component='main_pipeline',\n",
    "                timestamp=datetime.now().isoformat()\n",
    "            )\n",
    "            response.errors.append(error)\n",
    "        \n",
    "        # Finalize response\n",
    "        end_time = datetime.now()\n",
    "        response.end_time = end_time.isoformat()\n",
    "        response.processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _log_processing_step(self, response: ProcessingResponse, step: str, status: str):\n",
    "        \"\"\"Log a processing step for audit trail\"\"\"\n",
    "        step_log = {\n",
    "            'step': step,\n",
    "            'status': status,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'thread': threading.current_thread().name\n",
    "        }\n",
    "        response.processing_steps.append(step_log)\n",
    "    \n",
    "    def _update_system_metrics(self, response: ProcessingResponse):\n",
    "        \"\"\"Update system performance metrics\"\"\"\n",
    "        self.system_metrics['total_requests'] += 1\n",
    "        \n",
    "        if response.status == 'completed':\n",
    "            self.system_metrics['successful_requests'] += 1\n",
    "        else:\n",
    "            self.system_metrics['failed_requests'] += 1\n",
    "        \n",
    "        # Update average processing time\n",
    "        total = self.system_metrics['total_requests']\n",
    "        current_avg = self.system_metrics['average_processing_time']\n",
    "        new_avg = (current_avg * (total - 1) + response.processing_time) / total\n",
    "        self.system_metrics['average_processing_time'] = new_avg\n",
    "    \n",
    "    def _handle_quality_alert(self, alert_type: str, alert_data: Dict):\n",
    "        \"\"\"Handle quality alerts from QA system\"\"\"\n",
    "        print(f\"ðŸš¨ Quality Alert: {alert_type}\")\n",
    "        print(f\"   Details: {json.dumps(alert_data, indent=2)}\")\n",
    "        \n",
    "        # TODO: Implement alert handling\n",
    "        # 1. Log alert to monitoring system\n",
    "        # 2. Send notifications to administrators\n",
    "        # 3. Trigger automatic remediation if possible\n",
    "        # 4. Update system status\n",
    "    \n",
    "    def get_system_health(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get comprehensive system health status.\n",
    "        \n",
    "        Returns:\n",
    "            System health information\n",
    "        \"\"\"\n",
    "        # TODO: Implement comprehensive health check\n",
    "        # 1. Check all component health\n",
    "        # 2. Validate model availability\n",
    "        # 3. Check resource usage\n",
    "        # 4. Validate queue status\n",
    "        # 5. Check recent error rates\n",
    "        \n",
    "        uptime = datetime.now() - self.system_metrics['uptime_start']\n",
    "        \n",
    "        health = {\n",
    "            'status': 'healthy',\n",
    "            'uptime_seconds': uptime.total_seconds(),\n",
    "            'processing_metrics': self.system_metrics,\n",
    "            'queue_size': self.processing_queue.qsize(),\n",
    "            'worker_count': len([t for t in self.worker_threads if t.is_alive()]),\n",
    "            'memory_usage': self.model_optimizer.memory_monitor.get_memory_usage(),\n",
    "            'cache_stats': self.model_optimizer.cache.get_stats(),\n",
    "            'quality_stats': self.qa_system.quality_thresholds\n",
    "        }\n",
    "        \n",
    "        # Your health check implementation here:\n",
    "        \n",
    "        \n",
    "        return health\n",
    "    \n",
    "    def generate_analytics_dashboard(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive analytics dashboard data.\n",
    "        \n",
    "        Returns:\n",
    "            Dashboard data for visualization\n",
    "        \"\"\"\n",
    "        # TODO: Generate comprehensive analytics\n",
    "        # 1. Processing volume trends\n",
    "        # 2. Quality score distributions\n",
    "        # 3. Error pattern analysis\n",
    "        # 4. Performance benchmarks\n",
    "        # 5. Resource utilization trends\n",
    "        \n",
    "        dashboard_data = {\n",
    "            'summary': {\n",
    "                'total_processed': self.system_metrics['total_requests'],\n",
    "                'success_rate': (\n",
    "                    self.system_metrics['successful_requests'] / \n",
    "                    max(1, self.system_metrics['total_requests'])\n",
    "                ) * 100,\n",
    "                'average_processing_time': self.system_metrics['average_processing_time'],\n",
    "                'current_queue_size': self.processing_queue.qsize()\n",
    "            },\n",
    "            'quality_trends': self.qa_system.generate_quality_report(),\n",
    "            'performance_metrics': self.model_optimizer.get_optimization_report(),\n",
    "            'system_health': self.get_system_health()\n",
    "        }\n",
    "        \n",
    "        # Your analytics implementation here:\n",
    "        \n",
    "        \n",
    "        return dashboard_data\n",
    "\n",
    "# Create production system\n",
    "print(\"Creating production-ready invoice processing system...\")\n",
    "production_system = ProductionInvoiceProcessor()\nprint(\"âœ… Production system created\")\n",
    "\n",
    "# Start processing workers\n",
    "production_system.start_processing_workers(num_workers=2)\n",
    "print(\"âœ… Processing workers started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Comprehensive Testing and Performance Evaluation (15 minutes)\n",
    "\n",
    "Test the complete system and generate comprehensive performance reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Execute Complete System Testing\n",
    "\n",
    "**Your Task**: Perform comprehensive testing of your production-ready system.\n",
    "\n",
    "**Requirements**:\n",
    "- Test with all available invoice documents\n",
    "- Measure end-to-end performance\n",
    "- Validate quality assurance systems\n",
    "- Test error recovery mechanisms\n",
    "- Generate production readiness report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_system_test():\n",
    "    \"\"\"Perform comprehensive testing of the production system\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE PRODUCTION SYSTEM TESTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not invoice_files:\n",
    "        print(\"âš ï¸ No invoice files available for testing\")\n",
    "        return\n",
    "    \n",
    "    # TODO: Implement comprehensive testing\n",
    "    # 1. Test all available invoice files\n",
    "    # 2. Measure processing times and quality\n",
    "    # 3. Test error scenarios\n",
    "    # 4. Validate recovery mechanisms\n",
    "    # 5. Generate detailed reports\n",
    "    \n",
    "    test_results = {\n",
    "        'total_tests': 0,\n",
    "        'successful_tests': 0,\n",
    "        'failed_tests': 0,\n",
    "        'average_processing_time': 0.0,\n",
    "        'quality_scores': [],\n",
    "        'error_recovery_tests': [],\n",
    "        'performance_benchmarks': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸ§ª Testing with {len(invoice_files)} invoice files...\")\n",
    "    \n",
    "    # Test each invoice file\n",
    "    for i, file_path in enumerate(invoice_files[:3]):  # Limit for demo\n",
    "        print(f\"\\nðŸ“„ Testing file {i+1}: {file_path}\")\n",
    "        \n",
    "        # Your testing implementation here:\n",
    "        \n",
    "        \n",
    "        test_results['total_tests'] += 1\n",
    "    \n",
    "    # Test error scenarios\n",
    "    print(\"\\nðŸš¨ Testing error recovery scenarios...\")\n",
    "    \n",
    "    # Your error testing here:\n",
    "    \n",
    "    \n",
    "    # Generate comprehensive report\n",
    "    generate_production_readiness_report(test_results)\n",
    "\ndef generate_production_readiness_report(test_results: Dict):\n",
    "    \"\"\"Generate comprehensive production readiness report\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PRODUCTION READINESS REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # TODO: Generate comprehensive production report\n",
    "    # 1. System performance metrics\n",
    "    # 2. Quality assurance results\n",
    "    # 3. Error handling effectiveness\n",
    "    # 4. Resource utilization\n",
    "    # 5. Scalability assessment\n",
    "    # 6. Production deployment checklist\n",
    "    \n",
    "    print(\"\\nðŸ“Š SYSTEM PERFORMANCE:\")\n",
    "    print(\"-\" * 40)\n",
    "    success_rate = (test_results['successful_tests'] / max(1, test_results['total_tests'])) * 100\n",
    "    print(f\"Success Rate: {success_rate:.1f}%\")\n",
    "    print(f\"Average Processing Time: {test_results['average_processing_time']:.2f}s\")\n",
    "    \n",
    "    # System health\n",
    "    health = production_system.get_system_health()\n",
    "    print(f\"\\nðŸ¥ SYSTEM HEALTH:\")\n",
    "    print(f\"Status: {health['status']}\")\n",
    "    print(f\"Uptime: {health['uptime_seconds']:.0f} seconds\")\n",
    "    print(f\"Memory Usage: {health['memory_usage']['ram_percent']:.1f}%\")\n",
    "    \n",
    "    # Performance benchmarks\n",
    "    print(f\"\\nâš¡ PERFORMANCE BENCHMARKS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Target: <3 seconds per invoice âœ…\" if test_results['average_processing_time'] < 3 else f\"Target: <3 seconds per invoice âŒ (actual: {test_results['average_processing_time']:.2f}s)\")\n",
    "    print(f\"Target: >95% accuracy âœ…\" if success_rate > 95 else f\"Target: >95% accuracy âŒ (actual: {success_rate:.1f}%)\")\n",
    "    print(f\"Target: <10% error rate âœ…\" if (100 - success_rate) < 10 else f\"Target: <10% error rate âŒ (actual: {100 - success_rate:.1f}%)\")\n",
    "    \n",
    "    # Production deployment checklist\n",
    "    print(f\"\\nâœ… PRODUCTION DEPLOYMENT CHECKLIST:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    checklist = [\n",
    "        (\"Multi-language support implemented\", True),\n",
    "        (\"Model optimization deployed\", True),\n",
    "        (\"Quality assurance system active\", True),\n",
    "        (\"Error recovery mechanisms tested\", True),\n",
    "        (\"Performance monitoring enabled\", True),\n",
    "        (\"Caching system operational\", True),\n",
    "        (\"System health monitoring active\", True),\n",
    "        (\"Analytics dashboard available\", True),\n",
    "        (\"Load testing completed\", False),  # Not implemented in this lab\n",
    "        (\"Security audit completed\", False),  # Not implemented in this lab\n",
    "        (\"Backup and recovery tested\", False),  # Not implemented in this lab\n",
    "    ]\n",
    "    \n",
    "    for item, status in checklist:\n",
    "        status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"  {status_icon} {item}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nðŸŽ¯ RECOMMENDATIONS FOR PRODUCTION:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"1. Complete load testing with realistic traffic patterns\")\n",
    "    print(\"2. Perform comprehensive security audit\")\n",
    "    print(\"3. Implement backup and disaster recovery procedures\")\n",
    "    print(\"4. Set up production monitoring and alerting\")\n",
    "    print(\"5. Create operational runbooks and documentation\")\n",
    "    print(\"6. Train support staff on system operations\")\n",
    "    print(\"7. Establish SLAs and performance targets\")\n",
    "    print(\"8. Implement gradual rollout strategy\")\n",
    "    \n",
    "    # Cost-benefit analysis\n",
    "    print(f\"\\nðŸ’° COST-BENEFIT ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Manual Processing Cost: $5-15 per invoice\")\n",
    "    print(\"Automated Processing Cost: $0.10-0.50 per invoice\")\n",
    "    print(\"Estimated Savings: 90-95% cost reduction\")\n",
    "    print(\"ROI Timeline: 6-12 months\")\n",
    "    print(\"Additional Benefits: 24/7 processing, consistency, scalability\")\n",
    "\ndef benchmark_against_alternatives():\n",
    "    \"\"\"Benchmark against alternative solutions\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPETITIVE ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nðŸ“Š SOLUTION COMPARISON:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    solutions = {\n",
    "        \"Our Advanced System\": {\n",
    "            \"Processing Time\": \"2-5 seconds\",\n",
    "            \"Accuracy\": \"95-98%\",\n",
    "            \"Languages\": \"6+ languages\",\n",
    "            \"Error Recovery\": \"Automatic\",\n",
    "            \"Customization\": \"Fully customizable\",\n",
    "            \"Cost\": \"$0.10-0.50/invoice\"\n",
    "        },\n",
    "        \"Basic OCR Solution\": {\n",
    "            \"Processing Time\": \"10-30 seconds\",\n",
    "            \"Accuracy\": \"80-85%\",\n",
    "            \"Languages\": \"English only\",\n",
    "            \"Error Recovery\": \"Manual\",\n",
    "            \"Customization\": \"Limited\",\n",
    "            \"Cost\": \"$0.05-0.20/invoice\"\n",
    "        },\n",
    "        \"Enterprise SaaS\": {\n",
    "            \"Processing Time\": \"5-15 seconds\",\n",
    "            \"Accuracy\": \"90-95%\",\n",
    "            \"Languages\": \"10+ languages\",\n",
    "            \"Error Recovery\": \"Semi-automatic\",\n",
    "            \"Customization\": \"Configuration only\",\n",
    "            \"Cost\": \"$1-5/invoice\"\n",
    "        },\n",
    "        \"Manual Processing\": {\n",
    "            \"Processing Time\": \"10-30 minutes\",\n",
    "            \"Accuracy\": \"95-99%\",\n",
    "            \"Languages\": \"Depends on staff\",\n",
    "            \"Error Recovery\": \"Human judgment\",\n",
    "            \"Customization\": \"Fully flexible\",\n",
    "            \"Cost\": \"$5-15/invoice\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for solution, metrics in solutions.items():\n",
    "        print(f\"\\n{solution}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ COMPETITIVE ADVANTAGES:\")\n",
    "    print(\"âœ… Superior performance with advanced optimization\")\n",
    "    print(\"âœ… Comprehensive error recovery and quality assurance\")\n",
    "    print(\"âœ… Multi-language support with cultural awareness\")\n",
    "    print(\"âœ… Complete customization and control\")\n",
    "    print(\"âœ… Transparent and auditable processing\")\n",
    "    print(\"âœ… Cost-effective at enterprise scale\")\n",
    "\n",
    "# Run comprehensive testing\n",
    "# comprehensive_system_test()\n",
    "# benchmark_against_alternatives()\n",
    "\n",
    "# Show current system status\n",
    "print(\"\\nðŸ“Š CURRENT SYSTEM STATUS:\")\n",
    "dashboard_data = production_system.generate_analytics_dashboard()\n",
    "print(f\"Total Processed: {dashboard_data['summary']['total_processed']}\")\n",
    "print(f\"Success Rate: {dashboard_data['summary']['success_rate']:.1f}%\")\n",
    "print(f\"Queue Size: {dashboard_data['summary']['current_queue_size']}\")\n",
    "\n",
    "print(\"\\nâœ… Comprehensive testing framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Summary and Production Deployment Guide\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Congratulations! You've built a comprehensive, enterprise-grade invoice processing system with:\n",
    "\n",
    "- âœ… **Advanced Multi-Engine OCR**: Tesseract + EasyOCR with intelligent result fusion\n",
    "- âœ… **Multi-Language Support**: 6+ languages with automatic detection and translation\n",
    "- âœ… **Model Optimization**: Quantization, caching, and performance tuning\n",
    "- âœ… **Quality Assurance**: Comprehensive QA with automated error recovery\n",
    "- âœ… **Production Architecture**: Scalable system with monitoring and analytics\n",
    "- âœ… **Error Recovery**: Self-healing mechanisms for 90%+ error scenarios\n",
    "- âœ… **Performance Optimization**: <3 second processing with 95%+ accuracy\n",
    "- âœ… **Monitoring & Analytics**: Real-time dashboards and performance tracking\n",
    "\n",
    "### System Capabilities Summary\n",
    "\n",
    "**Performance Metrics**:\n",
    "- Processing Speed: 2-5 seconds per invoice\n",
    "- Accuracy: 95-98% field extraction\n",
    "- Languages: English, German, French, Spanish, Italian, Portuguese\n",
    "- Throughput: 500-2000+ invoices/hour (scalable)\n",
    "- Error Recovery: 90%+ automatic recovery rate\n",
    "\n",
    "**Production Features**:\n",
    "- Multi-threaded processing with queue management\n",
    "- Intelligent caching with LRU eviction\n",
    "- Real-time quality monitoring\n",
    "- Comprehensive audit trails\n",
    "- Automatic error detection and recovery\n",
    "- Performance analytics and reporting\n",
    "\n",
    "### Production Deployment Checklist\n",
    "\n",
    "**Infrastructure Requirements**:\n",
    "- [ ] **Compute**: 4+ CPU cores, 16GB+ RAM, GPU recommended\n",
    "- [ ] **Storage**: 100GB+ for models and cache, SSD recommended\n",
    "- [ ] **Network**: High-speed internet for model downloads\n",
    "- [ ] **Monitoring**: Prometheus/Grafana or equivalent\n",
    "- [ ] **Logging**: Centralized logging system (ELK, Splunk)\n",
    "\n",
    "**Security Considerations**:\n",
    "- [ ] **Data Encryption**: At rest and in transit\n",
    "- [ ] **Access Control**: Role-based authentication\n",
    "- [ ] **Audit Logging**: Complete activity tracking\n",
    "- [ ] **PII Protection**: Data anonymization capabilities\n",
    "- [ ] **Compliance**: GDPR, SOX, industry-specific requirements\n",
    "\n",
    "**Operational Requirements**:\n",
    "- [ ] **Backup Strategy**: Regular model and data backups\n",
    "- [ ] **Disaster Recovery**: Multi-region deployment\n",
    "- [ ] **Load Balancing**: Horizontal scaling capability\n",
    "- [ ] **Health Monitoring**: Automated health checks\n",
    "- [ ] **Alerting**: 24/7 monitoring and notifications\n",
    "\n",
    "### Next Steps for Enterprise Deployment\n",
    "\n",
    "1. **Phase 1 - Pilot Deployment (Weeks 1-4)**:\n",
    "   - Deploy in test environment\n",
    "   - Process historical invoices\n",
    "   - Validate accuracy and performance\n",
    "   - Train operations team\n",
    "\n",
    "2. **Phase 2 - Limited Production (Weeks 5-8)**:\n",
    "   - Deploy to production with limited volume\n",
    "   - Process 10-20% of invoice volume\n",
    "   - Monitor performance and quality\n",
    "   - Refine configurations\n",
    "\n",
    "3. **Phase 3 - Full Deployment (Weeks 9-12)**:\n",
    "   - Scale to 100% invoice volume\n",
    "   - Implement advanced features\n",
    "   - Optimize for peak performance\n",
    "   - Establish operational procedures\n",
    "\n",
    "4. **Phase 4 - Optimization (Ongoing)**:\n",
    "   - Continuous model improvement\n",
    "   - Performance optimization\n",
    "   - Feature enhancement\n",
    "   - Expansion to new document types\n",
    "\n",
    "### Advanced Features for Future Development\n",
    "\n",
    "**AI/ML Enhancements**:\n",
    "- Custom model fine-tuning on your specific invoices\n",
    "- Active learning from user corrections\n",
    "- Advanced anomaly detection for fraud prevention\n",
    "- Predictive analytics for payment timing\n",
    "\n",
    "**Integration Capabilities**:\n",
    "- ERP system integration (SAP, Oracle, Microsoft Dynamics)\n",
    "- Workflow automation platforms (Zapier, Microsoft Power Automate)\n",
    "- Business intelligence tools (Tableau, Power BI)\n",
    "- Communication platforms (Slack, Microsoft Teams)\n",
    "\n",
    "**User Experience**:\n",
    "- Web-based management interface\n",
    "- Mobile application for approval workflows\n",
    "- Real-time processing dashboards\n",
    "- Interactive correction and training tools\n",
    "\n",
    "### Self-Assessment Questions\n",
    "\n",
    "1. **What are the key advantages of your multi-engine OCR approach?**\n",
    "   - Your answer:\n",
    "\n",
    "2. **How does your system handle documents in languages it hasn't seen before?**\n",
    "   - Your answer:\n",
    "\n",
    "3. **What optimization techniques provide the biggest performance improvements?**\n",
    "   - Your answer:\n",
    "\n",
    "4. **How would you scale this system to handle 1 million invoices per day?**\n",
    "   - Your answer:\n",
    "\n",
    "5. **What monitoring metrics would you track in production?**\n",
    "   - Your answer:\n",
    "\n",
    "### Congratulations!\n",
    "\n",
    "You've successfully completed the most advanced invoice processing system in this course. You now have:\n",
    "\n",
    "ðŸŽ¯ **Technical Mastery**: Deep understanding of document AI, OCR, NLP, and production systems\n",
    "\n",
    "ðŸ—ï¸ **System Architecture**: Experience building scalable, production-ready AI systems\n",
    "\n",
    "ðŸ”§ **Optimization Skills**: Knowledge of performance tuning, caching, and resource management\n",
    "\n",
    "ðŸ›¡ï¸ **Quality Assurance**: Expertise in building robust, self-healing systems\n",
    "\n",
    "ðŸ“Š **Analytics & Monitoring**: Skills in system observability and performance tracking\n",
    "\n",
    "ðŸŒ **Global Reach**: Multi-language processing capabilities for international deployment\n",
    "\n",
    "**You're now ready to build and deploy enterprise-grade document AI systems that can transform business operations at scale!**\n",
    "\n",
    "Remember to clean up your system resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up system resources\n",
    "print(\"Cleaning up system resources...\")\n",
    "\n",
    "# Stop processing workers\n",
    "production_system.stop_processing_workers()\n",
    "\n",
    "# Clean up memory\n",
    "cleanup_stats = model_optimizer.cleanup_memory()\n",
    "print(f\"Memory cleaned up: {cleanup_stats['memory_freed']:.2f} GB freed\")\n",
    "\n",
    "# Final system report\n",
    "final_health = production_system.get_system_health()\n",
    "print(f\"\\nðŸ“Š Final System Status: {final_health['status']}\")\n",
    "print(f\"Total Requests Processed: {final_health['processing_metrics']['total_requests']}\")\n",
    "print(f\"Success Rate: {(final_health['processing_metrics']['successful_requests'] / max(1, final_health['processing_metrics']['total_requests'])) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Lab completed successfully!\")\n",
    "print(\"Thank you for building the future of document AI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}