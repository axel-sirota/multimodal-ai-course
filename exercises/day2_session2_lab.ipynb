{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2, Session 2 Lab: Build Resilient Invoice Enhancement Tools\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "**Estimated Time:** 40 minutes  \n",
    "**Difficulty:** Advanced  \n",
    "**Prerequisites:** Day 2 Session 1 Lab completion\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Build Production-Ready API Tools**\n",
    "   - Create currency conversion tools with real APIs\n",
    "   - Implement VAT validation using web search\n",
    "   - Build robust error handling and fallback strategies\n",
    "\n",
    "2. **Implement Resilience Patterns**\n",
    "   - Build circuit breakers for API failure protection\n",
    "   - Create rate limiting for quota management\n",
    "   - Implement intelligent caching strategies\n",
    "\n",
    "3. **Optimize for Production**\n",
    "   - Track API costs and performance metrics\n",
    "   - Handle partial failures gracefully\n",
    "   - Build scalable tool orchestration\n",
    "\n",
    "### Real-World Application\n",
    "\n",
    "This lab simulates building an enterprise invoice processing system that:\n",
    "- Converts currencies using live exchange rates\n",
    "- Validates VAT numbers against external registries\n",
    "- Handles API outages gracefully\n",
    "- Optimizes costs through intelligent caching\n",
    "- Maintains high availability under load\n",
    "\n",
    "### Lab Structure\n",
    "\n",
    "1. **Currency Converter Tool** (10 minutes)\n",
    "2. **VAT Validator Tool** (10 minutes)  \n",
    "3. **Circuit Breaker Implementation** (8 minutes)\n",
    "4. **Tool Orchestration** (8 minutes)\n",
    "5. **Production Testing** (4 minutes)\n",
    "\n",
    "Let's build tools that work reliably in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server configuration - instructor provides actual values\n",
    "OLLAMA_URL = \"http://XX.XX.XX.XX\"  # Course server IP\n",
    "API_TOKEN = \"YOUR_TOKEN_HERE\"      # Instructor provides token\n",
    "MODEL = \"qwen3:8b\"                  # Default model on server\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "import threading\n",
    "from collections import defaultdict, deque\n",
    "import hashlib\n",
    "from enum import Enum\n",
    "import concurrent.futures\n",
    "\n",
    "# API Configuration\n",
    "EXCHANGE_RATE_API = \"https://api.exchangerate-api.com/v4/latest/{currency}\"\n",
    "SERPER_API_KEY = \"your_key_here\"  # Instructor provides or mock\n",
    "\n",
    "# Mock data for when APIs are unavailable\n",
    "MOCK_EXCHANGE_RATES = {\n",
    "    \"EUR\": {\"USD\": 1.1, \"GBP\": 0.85, \"JPY\": 120.5, \"EUR\": 1.0},\n",
    "    \"USD\": {\"EUR\": 0.91, \"GBP\": 0.77, \"JPY\": 109.5, \"USD\": 1.0},\n",
    "    \"GBP\": {\"EUR\": 1.18, \"USD\": 1.30, \"JPY\": 142.3, \"GBP\": 1.0}\n",
    "}\n",
    "\n",
    "MOCK_VAT_DATA = {\n",
    "    \"GB123456789\": {\"valid\": True, \"company\": \"TechSupplies Co.\", \"country\": \"United Kingdom\"},\n",
    "    \"NL123456789\": {\"valid\": True, \"company\": \"Dutch Tech BV\", \"country\": \"Netherlands\"},\n",
    "    \"DE123456789\": {\"valid\": True, \"company\": \"German Tech GmbH\", \"country\": \"Germany\"},\n",
    "    \"INVALID123\": {\"valid\": False, \"reason\": \"Invalid format\"}\n",
    "}\n",
    "\n",
    "# Health check\n",
    "def check_server_health():\n",
    "    \"\"\"Verify server connection\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/health\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ Server Status: {data.get('status', 'Unknown')}\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Server connection failed: {e}\")\n",
    "    return False\n",
    "\n",
    "print(\"üîó API Integration Lab Setup\")\nprint(\"üîå Connecting to course server...\")\nserver_available = check_server_health()\n\nprint(\"\\nüì¶ Installing required packages...\")\n!pip install -q requests python-dateutil\nprint(\"‚úÖ Packages ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download real invoice dataset\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "dropbox_url = \"https://www.dropbox.com/scl/fo/m9hyfmvi78snwv0nh34mo/AMEXxwXMLAOeve-_yj12ck8?rlkey=urinkikgiuven0fro7r4x5rcu&st=hv3of7g7&dl=1\"\n",
    "\n",
    "print(\"üì¶ Downloading invoice dataset...\")\n",
    "try:\n",
    "    response = requests.get(dropbox_url)\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall(\"invoice_images\")\n",
    "    print(\"‚úÖ Downloaded invoice dataset\")\n",
    "    \n",
    "    # Sample invoice data for testing\n",
    "    SAMPLE_INVOICES = [\n",
    "        {\n",
    "            \"invoice_id\": \"INV-2024-001\",\n",
    "            \"vendor\": \"TechSupplies Co.\",\n",
    "            \"amount\": 15000.00,\n",
    "            \"currency\": \"EUR\",\n",
    "            \"vat_number\": \"GB123456789\",\n",
    "            \"date\": \"2024-01-15\"\n",
    "        },\n",
    "        {\n",
    "            \"invoice_id\": \"INV-2024-002\",\n",
    "            \"vendor\": \"CloudServices Inc.\",\n",
    "            \"amount\": 8500.00,\n",
    "            \"currency\": \"USD\",\n",
    "            \"vat_number\": \"NL123456789\",\n",
    "            \"date\": \"2024-02-01\"\n",
    "        },\n",
    "        {\n",
    "            \"invoice_id\": \"INV-2024-003\",\n",
    "            \"vendor\": \"Software Solutions Ltd\",\n",
    "            \"amount\": 12500.00,\n",
    "            \"currency\": \"GBP\",\n",
    "            \"vat_number\": \"INVALID123\",\n",
    "            \"date\": \"2024-02-15\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìä Sample invoices prepared: {len(SAMPLE_INVOICES)}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå Error downloading: {e}\")\n",
    "    SAMPLE_INVOICES = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundation: Resilience Components\n",
    "\n",
    "First, let's build the foundational resilience patterns that all our tools will use.\n",
    "\n",
    "**Your Task:** Complete the cache and rate limiter implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CacheEntry:\n",
    "    \"\"\"Cache entry with expiration\"\"\"\n",
    "    value: Any\n",
    "    expires_at: datetime\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class SimpleCache:\n",
    "    \"\"\"Simple in-memory cache with TTL support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache: Dict[str, CacheEntry] = {}\n",
    "        self._lock = threading.Lock()\n",
    "        self.stats = {\n",
    "            'hits': 0,\n",
    "            'misses': 0,\n",
    "            'evictions': 0\n",
    "        }\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Get value from cache if not expired\"\"\"\n",
    "        # TODO: Implement cache retrieval with TTL checking\n",
    "        with self._lock:\n",
    "            if key in self.cache:\n",
    "                entry = self.cache[key]\n",
    "                if datetime.now() < entry.expires_at:\n",
    "                    # TODO: Increment hit counter\n",
    "                    self.stats['hits'] += 1\n",
    "                    return entry.value\n",
    "                else:\n",
    "                    # TODO: Remove expired entry and increment evictions\n",
    "                    del self.cache[key]\n",
    "                    self.stats['evictions'] += 1\n",
    "            \n",
    "            # TODO: Increment miss counter\n",
    "            self.stats['misses'] += 1\n",
    "            return None\n",
    "    \n",
    "    def set(self, key: str, value: Any, ttl_seconds: int):\n",
    "        \"\"\"Store value in cache with TTL\"\"\"\n",
    "        # TODO: Implement cache storage with expiration\n",
    "        with self._lock:\n",
    "            expires_at = datetime.now() + timedelta(seconds=ttl_seconds)\n",
    "            self.cache[key] = CacheEntry(value=value, expires_at=expires_at)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear all cache entries\"\"\"\n",
    "        with self._lock:\n",
    "            self.cache.clear()\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get cache performance statistics\"\"\"\n",
    "        total_requests = self.stats['hits'] + self.stats['misses']\n",
    "        hit_rate = self.stats['hits'] / total_requests if total_requests > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'hit_rate': hit_rate,\n",
    "            'total_entries': len(self.cache),\n",
    "            **self.stats\n",
    "        }\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"Token bucket rate limiter\"\"\"\n",
    "    \n",
    "    def __init__(self, max_calls: int, time_window: int):\n",
    "        # TODO: Initialize token bucket parameters\n",
    "        self.max_calls = max_calls\n",
    "        self.time_window = time_window  # seconds\n",
    "        self.tokens = max_calls\n",
    "        self.last_refill = time.time()\n",
    "        self._lock = threading.Lock()\n",
    "        \n",
    "        # Refill rate: tokens per second\n",
    "        self.refill_rate = max_calls / time_window\n",
    "    \n",
    "    def acquire(self) -> bool:\n",
    "        \"\"\"Try to acquire a token\"\"\"\n",
    "        # TODO: Implement token bucket logic\n",
    "        with self._lock:\n",
    "            now = time.time()\n",
    "            \n",
    "            # Calculate tokens to add based on time passed\n",
    "            time_passed = now - self.last_refill\n",
    "            tokens_to_add = time_passed * self.refill_rate\n",
    "            \n",
    "            # Add tokens up to maximum\n",
    "            self.tokens = min(self.max_calls, self.tokens + tokens_to_add)\n",
    "            self.last_refill = now\n",
    "            \n",
    "            # Check if we can consume a token\n",
    "            if self.tokens >= 1:\n",
    "                self.tokens -= 1\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "    def wait_time(self) -> float:\n",
    "        \"\"\"Get seconds to wait before next token is available\"\"\"\n",
    "        if self.tokens >= 1:\n",
    "            return 0.0\n",
    "        return (1 - self.tokens) / self.refill_rate\n",
    "\n",
    "# Test the implementations\nprint(\"üß™ Testing resilience components...\")\n\n# Test cache\ncache = SimpleCache()\ncache.set(\"test_key\", \"test_value\", 2)  # 2 second TTL\nprint(f\"Cache get: {cache.get('test_key')}\")\ntime.sleep(1)\nprint(f\"Cache get after 1s: {cache.get('test_key')}\")\ntime.sleep(1.5)\nprint(f\"Cache get after 2.5s: {cache.get('test_key')}\")\nprint(f\"Cache stats: {cache.get_stats()}\")\n\n# Test rate limiter\nrate_limiter = RateLimiter(max_calls=3, time_window=5)  # 3 calls per 5 seconds\nprint(f\"\\nRate limiter tests:\")\nfor i in range(5):\n    allowed = rate_limiter.acquire()\n    print(f\"  Request {i+1}: {'‚úÖ Allowed' if allowed else '‚ùå Rate limited'}\")\n\nprint(\"‚úÖ Resilience components ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Currency Converter Tool (10 minutes)\n",
    "\n",
    "Build a production-ready currency converter with caching and error handling.\n",
    "\n",
    "**Your Task:** Complete the CurrencyConverterTool implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrencyConverterTool:\n",
    "    \"\"\"Production-ready currency converter with resilience patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_ttl=3600, rate_limit_calls=60, rate_limit_window=60):\n",
    "        # TODO: Initialize converter components\n",
    "        self.cache = SimpleCache()\n",
    "        self.rate_limiter = RateLimiter(rate_limit_calls, rate_limit_window)\n",
    "        self.cache_ttl = cache_ttl  # 1 hour default\n",
    "        \n",
    "        # Cost tracking\n",
    "        self.api_cost_per_call = 0.001  # $0.001 per call\n",
    "        self.total_cost = 0.0\n",
    "        self.call_count = 0\n",
    "        \n",
    "        print(f\"üí± Currency converter initialized (cache: {cache_ttl}s, rate: {rate_limit_calls}/{rate_limit_window}s)\")\n",
    "    \n",
    "    def _get_cache_key(self, from_currency: str, to_currency: str) -> str:\n",
    "        \"\"\"Generate cache key for currency pair\"\"\"\n",
    "        return f\"rate_{from_currency}_{to_currency}\"\n",
    "    \n",
    "    def _call_exchange_api(self, from_currency: str) -> Dict[str, float]:\n",
    "        \"\"\"Call real exchange rate API\"\"\"\n",
    "        # TODO: Implement real API call\n",
    "        try:\n",
    "            url = EXCHANGE_RATE_API.format(currency=from_currency)\n",
    "            response = requests.get(url, timeout=5)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return data.get('rates', {})\n",
    "            else:\n",
    "                raise requests.RequestException(f\"API returned {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è API call failed: {e}\")\n",
    "            # TODO: Return mock data as fallback\n",
    "            return MOCK_EXCHANGE_RATES.get(from_currency, {})\n",
    "    \n",
    "    def get_exchange_rate(self, from_currency: str, to_currency: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get exchange rate with caching and rate limiting\"\"\"\n",
    "        # TODO: Implement complete exchange rate retrieval\n",
    "        cache_key = self._get_cache_key(from_currency, to_currency)\n",
    "        \n",
    "        # Check cache first\n",
    "        cached_rate = self.cache.get(cache_key)\n",
    "        if cached_rate is not None:\n",
    "            return {\n",
    "                'rate': cached_rate,\n",
    "                'from_cache': True,\n",
    "                'cost': 0.0\n",
    "            }\n",
    "        \n",
    "        # Check rate limit\n",
    "        if not self.rate_limiter.acquire():\n",
    "            wait_time = self.rate_limiter.wait_time()\n",
    "            return {\n",
    "                'error': f\"Rate limited. Wait {wait_time:.1f}s\",\n",
    "                'wait_time': wait_time\n",
    "            }\n",
    "        \n",
    "        # Make API call\n",
    "        try:\n",
    "            rates = self._call_exchange_api(from_currency)\n",
    "            \n",
    "            if to_currency in rates:\n",
    "                rate = rates[to_currency]\n",
    "                \n",
    "                # Cache the result\n",
    "                self.cache.set(cache_key, rate, self.cache_ttl)\n",
    "                \n",
    "                # Update cost tracking\n",
    "                self.total_cost += self.api_cost_per_call\n",
    "                self.call_count += 1\n",
    "                \n",
    "                return {\n",
    "                    'rate': rate,\n",
    "                    'from_cache': False,\n",
    "                    'cost': self.api_cost_per_call\n",
    "                }\n",
    "            else:\n",
    "                return {'error': f\"Currency {to_currency} not supported\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def convert(self, amount: float, from_currency: str, to_currency: str) -> Dict[str, Any]:\n",
    "        \"\"\"Convert amount between currencies\"\"\"\n",
    "        # TODO: Implement currency conversion\n",
    "        if from_currency == to_currency:\n",
    "            return {\n",
    "                'original_amount': amount,\n",
    "                'converted_amount': amount,\n",
    "                'rate': 1.0,\n",
    "                'from_currency': from_currency,\n",
    "                'to_currency': to_currency,\n",
    "                'cost': 0.0\n",
    "            }\n",
    "        \n",
    "        rate_result = self.get_exchange_rate(from_currency, to_currency)\n",
    "        \n",
    "        if 'error' in rate_result:\n",
    "            return rate_result\n",
    "        \n",
    "        rate = rate_result['rate']\n",
    "        converted_amount = amount * rate\n",
    "        \n",
    "        return {\n",
    "            'original_amount': amount,\n",
    "            'converted_amount': converted_amount,\n",
    "            'rate': rate,\n",
    "            'from_currency': from_currency,\n",
    "            'to_currency': to_currency,\n",
    "            'from_cache': rate_result['from_cache'],\n",
    "            'cost': rate_result['cost']\n",
    "        }\n",
    "    \n",
    "    def convert_to_multiple(self, amount: float, from_currency: str, to_currencies: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to multiple currencies in parallel\"\"\"\n",
    "        # TODO: Implement batch conversion\n",
    "        results = {}\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # Use ThreadPoolExecutor for parallel requests\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            future_to_currency = {\n",
    "                executor.submit(self.convert, amount, from_currency, to_currency): to_currency\n",
    "                for to_currency in to_currencies\n",
    "            }\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_currency):\n",
    "                to_currency = future_to_currency[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results[to_currency] = result\n",
    "                    total_cost += result.get('cost', 0)\n",
    "                except Exception as e:\n",
    "                    results[to_currency] = {'error': str(e)}\n",
    "        \n",
    "        return {\n",
    "            'conversions': results,\n",
    "            'total_cost': total_cost,\n",
    "            'currencies_processed': len(results)\n",
    "        }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get converter performance statistics\"\"\"\n",
    "        cache_stats = self.cache.get_stats()\n",
    "        \n",
    "        return {\n",
    "            'total_cost': self.total_cost,\n",
    "            'api_calls': self.call_count,\n",
    "            'cache_hit_rate': cache_stats['hit_rate'],\n",
    "            'money_saved': cache_stats['hits'] * self.api_cost_per_call,\n",
    "            'average_cost_per_conversion': self.total_cost / max(1, self.call_count)\n",
    "        }\n",
    "\n",
    "# Test the currency converter\nprint(\"üß™ Testing Currency Converter...\")\nconverter = CurrencyConverterTool()\n\n# Test single conversion\nresult = converter.convert(1000, \"EUR\", \"USD\")\nprint(f\"Convert ‚Ç¨1000 to USD: {result}\")\n\n# Test cache hit\nresult2 = converter.convert(500, \"EUR\", \"USD\")\nprint(f\"Second conversion (should hit cache): {result2.get('from_cache')}\")\n\n# Test batch conversion\nbatch_result = converter.convert_to_multiple(1000, \"EUR\", [\"USD\", \"GBP\", \"JPY\"])\nprint(f\"Batch conversion results: {len(batch_result['conversions'])} currencies\")\n\n# Show stats\nstats = converter.get_stats()\nprint(f\"Converter stats: {stats}\")\n\nprint(\"‚úÖ Currency Converter implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: VAT Validator Tool (10 minutes)\n",
    "\n",
    "Build a VAT validation tool using web search APIs.\n",
    "\n",
    "**Your Task:** Complete the VATValidatorTool implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VATValidatorTool:\n",
    "    \"\"\"VAT number validator using web search\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_ttl=86400):  # 24 hour cache\n",
    "        # TODO: Initialize VAT validator\n",
    "        self.cache = SimpleCache()\n",
    "        self.rate_limiter = RateLimiter(max_calls=2, time_window=1)  # 2 calls per second\n",
    "        self.cache_ttl = cache_ttl\n",
    "        \n",
    "        # Cost tracking\n",
    "        self.api_cost_per_call = 0.005  # $0.005 per search\n",
    "        self.total_cost = 0.0\n",
    "        self.call_count = 0\n",
    "        \n",
    "        print(f\"üîç VAT validator initialized (cache: {cache_ttl/3600:.0f}h, rate: 2/1s)\")\n",
    "    \n",
    "    def _validate_vat_format(self, vat_number: str) -> Dict[str, Any]:\n",
    "        \"\"\"Basic VAT number format validation\"\"\"\n",
    "        # TODO: Implement format validation\n",
    "        vat_number = vat_number.strip().upper()\n",
    "        \n",
    "        # Basic format patterns\n",
    "        format_patterns = {\n",
    "            'GB': (11, r'^GB\\d{9}$'),  # UK: GB + 9 digits\n",
    "            'NL': (12, r'^NL\\d{9}B\\d{2}$'),  # Netherlands: NL + 9 digits + B + 2 digits\n",
    "            'DE': (11, r'^DE\\d{9}$'),  # Germany: DE + 9 digits\n",
    "            'FR': (13, r'^FR[A-Z0-9]{2}\\d{9}$'),  # France: FR + 2 chars + 9 digits\n",
    "        }\n",
    "        \n",
    "        if len(vat_number) < 4:\n",
    "            return {'valid_format': False, 'reason': 'Too short'}\n",
    "        \n",
    "        country_code = vat_number[:2]\n",
    "        if country_code in format_patterns:\n",
    "            expected_length, pattern = format_patterns[country_code]\n",
    "            if len(vat_number) == expected_length:\n",
    "                return {'valid_format': True, 'country': country_code}\n",
    "            else:\n",
    "                return {'valid_format': False, 'reason': f'Invalid length for {country_code}'}\n",
    "        else:\n",
    "            return {'valid_format': True, 'country': 'unknown'}  # Accept unknown formats\n",
    "    \n",
    "    def _search_vat_online(self, vat_number: str, company_name: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Search for VAT number online\"\"\"\n",
    "        # TODO: Implement web search (use Serper API or mock)\n",
    "        try:\n",
    "            # For production, use real search API:\n",
    "            # query = f\"VAT number {vat_number} {company_name} company registration\"\n",
    "            # headers = {'X-API-KEY': SERPER_API_KEY}\n",
    "            # response = requests.post(\n",
    "            #     'https://google.serper.dev/search',\n",
    "            #     headers=headers,\n",
    "            #     json={'q': query}\n",
    "            # )\n",
    "            \n",
    "            # For now, use mock data\n",
    "            time.sleep(0.2)  # Simulate API delay\n",
    "            \n",
    "            if vat_number in MOCK_VAT_DATA:\n",
    "                return MOCK_VAT_DATA[vat_number]\n",
    "            else:\n",
    "                return {\n",
    "                    'valid': False,\n",
    "                    'reason': 'Not found in registry',\n",
    "                    'confidence': 0.7\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {'valid': False, 'error': str(e), 'confidence': 0.0}\n",
    "    \n",
    "    def validate(self, vat_number: str, company_name: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Validate VAT number with comprehensive checks\"\"\"\n",
    "        # TODO: Implement complete VAT validation\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Clean input\n",
    "        vat_number = vat_number.strip().upper().replace(' ', '')\n",
    "        cache_key = f\"vat_{vat_number}_{company_name}\"\n",
    "        \n",
    "        # Check cache first\n",
    "        cached_result = self.cache.get(cache_key)\n",
    "        if cached_result is not None:\n",
    "            cached_result['from_cache'] = True\n",
    "            cached_result['processing_time'] = time.time() - start_time\n",
    "            return cached_result\n",
    "        \n",
    "        # Format validation\n",
    "        format_check = self._validate_vat_format(vat_number)\n",
    "        if not format_check['valid_format']:\n",
    "            result = {\n",
    "                'vat_number': vat_number,\n",
    "                'valid': False,\n",
    "                'reason': format_check['reason'],\n",
    "                'confidence': 0.9,\n",
    "                'from_cache': False,\n",
    "                'cost': 0.0,\n",
    "                'processing_time': time.time() - start_time\n",
    "            }\n",
    "            return result\n",
    "        \n",
    "        # Rate limiting\n",
    "        if not self.rate_limiter.acquire():\n",
    "            wait_time = self.rate_limiter.wait_time()\n",
    "            return {\n",
    "                'error': f\"Rate limited. Wait {wait_time:.1f}s\",\n",
    "                'wait_time': wait_time\n",
    "            }\n",
    "        \n",
    "        # Online search\n",
    "        search_result = self._search_vat_online(vat_number, company_name)\n",
    "        \n",
    "        # Build final result\n",
    "        result = {\n",
    "            'vat_number': vat_number,\n",
    "            'valid': search_result.get('valid', False),\n",
    "            'company': search_result.get('company', 'Unknown'),\n",
    "            'country': format_check.get('country', search_result.get('country', 'Unknown')),\n",
    "            'confidence': search_result.get('confidence', 0.8),\n",
    "            'reason': search_result.get('reason', ''),\n",
    "            'from_cache': False,\n",
    "            'cost': self.api_cost_per_call,\n",
    "            'processing_time': time.time() - start_time\n",
    "        }\n",
    "        \n",
    "        # Update cost tracking\n",
    "        self.total_cost += self.api_cost_per_call\n",
    "        self.call_count += 1\n",
    "        \n",
    "        # Cache the result\n",
    "        self.cache.set(cache_key, result, self.cache_ttl)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validate_multiple(self, vat_numbers: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Validate multiple VAT numbers\"\"\"\n",
    "        # TODO: Implement batch validation\n",
    "        results = {}\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        for vat_number in vat_numbers:\n",
    "            try:\n",
    "                result = self.validate(vat_number)\n",
    "                results[vat_number] = result\n",
    "                total_cost += result.get('cost', 0)\n",
    "            except Exception as e:\n",
    "                results[vat_number] = {'error': str(e)}\n",
    "        \n",
    "        return {\n",
    "            'validations': results,\n",
    "            'total_cost': total_cost,\n",
    "            'numbers_processed': len(results),\n",
    "            'valid_count': sum(1 for r in results.values() if r.get('valid', False))\n",
    "        }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get validator performance statistics\"\"\"\n",
    "        cache_stats = self.cache.get_stats()\n",
    "        \n",
    "        return {\n",
    "            'total_cost': self.total_cost,\n",
    "            'api_calls': self.call_count,\n",
    "            'cache_hit_rate': cache_stats['hit_rate'],\n",
    "            'money_saved': cache_stats['hits'] * self.api_cost_per_call,\n",
    "            'average_cost_per_validation': self.total_cost / max(1, self.call_count)\n",
    "        }\n",
    "\n",
    "# Test the VAT validator\nprint(\"üß™ Testing VAT Validator...\")\nvat_validator = VATValidatorTool()\n",
    "\n",
    "# Test valid VAT numbers\ntest_vats = [\"GB123456789\", \"NL123456789\", \"INVALID123\"]\n\nfor vat in test_vats:\n",
    "    result = vat_validator.validate(vat)\n",
    "    print(f\"VAT {vat}: {'‚úÖ Valid' if result.get('valid') else '‚ùå Invalid'} - {result.get('company', result.get('reason', ''))}\")\n\n# Test batch validation\nbatch_result = vat_validator.validate_multiple(test_vats)\nprint(f\"\\nBatch validation: {batch_result['valid_count']}/{batch_result['numbers_processed']} valid\")\n\n# Show stats\nstats = vat_validator.get_stats()\nprint(f\"Validator stats: {stats}\")\n\nprint(\"‚úÖ VAT Validator implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Circuit Breaker Implementation (8 minutes)\n",
    "\n",
    "Implement a circuit breaker to protect against cascading failures.\n",
    "\n",
    "**Your Task:** Complete the CircuitBreaker class and test it thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitState(Enum):\n",
    "    CLOSED = \"closed\"      # Normal operation\n",
    "    OPEN = \"open\"          # Failing, reject calls\n",
    "    HALF_OPEN = \"half_open\" # Testing recovery\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker for API resilience\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold=3, timeout=30, recovery_timeout=60):\n",
    "        # TODO: Initialize circuit breaker state\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout  # Seconds to wait before trying again\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        \n",
    "        self.failure_count = 0\n",
    "        self.success_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = CircuitState.CLOSED\n",
    "        self._lock = threading.Lock()\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'total_calls': 0,\n",
    "            'successful_calls': 0,\n",
    "            'failed_calls': 0,\n",
    "            'rejected_calls': 0,\n",
    "            'state_changes': 0\n",
    "        }\n",
    "    \n",
    "    def _change_state(self, new_state: CircuitState, reason: str = \"\"):\n",
    "        \"\"\"Change circuit breaker state\"\"\"\n",
    "        old_state = self.state\n",
    "        self.state = new_state\n",
    "        self.stats['state_changes'] += 1\n",
    "        print(f\"üîÑ Circuit breaker: {old_state.value} ‚Üí {new_state.value} ({reason})\")\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function with circuit breaker protection\"\"\"\n",
    "        # TODO: Implement circuit breaker logic\n",
    "        with self._lock:\n",
    "            self.stats['total_calls'] += 1\n",
    "            \n",
    "            # Check current state\n",
    "            if self.state == CircuitState.OPEN:\n",
    "                # Check if we should try recovery\n",
    "                if self.last_failure_time and \\\n",
    "                   (time.time() - self.last_failure_time) > self.timeout:\n",
    "                    self._change_state(CircuitState.HALF_OPEN, \"timeout expired\")\n",
    "                else:\n",
    "                    # Still in open state, reject call\n",
    "                    self.stats['rejected_calls'] += 1\n",
    "                    raise Exception(\"Circuit breaker is OPEN - call rejected\")\n",
    "        \n",
    "        # Attempt the call\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            # Success - update state\n",
    "            with self._lock:\n",
    "                self.stats['successful_calls'] += 1\n",
    "                \n",
    "                if self.state == CircuitState.HALF_OPEN:\n",
    "                    # Recovery successful\n",
    "                    self.failure_count = 0\n",
    "                    self._change_state(CircuitState.CLOSED, \"recovery successful\")\n",
    "                elif self.state == CircuitState.CLOSED:\n",
    "                    # Reset failure count on success\n",
    "                    self.failure_count = 0\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Failure - update state\n",
    "            with self._lock:\n",
    "                self.stats['failed_calls'] += 1\n",
    "                self.failure_count += 1\n",
    "                self.last_failure_time = time.time()\n",
    "                \n",
    "                # Check if we should open the circuit\n",
    "                if self.failure_count >= self.failure_threshold:\n",
    "                    if self.state != CircuitState.OPEN:\n",
    "                        self._change_state(CircuitState.OPEN, f\"{self.failure_count} failures\")\n",
    "            \n",
    "            raise e\n",
    "    \n",
    "    def get_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get circuit breaker status\"\"\"\n",
    "        with self._lock:\n",
    "            success_rate = (self.stats['successful_calls'] / \n",
    "                          max(1, self.stats['total_calls']))\n",
    "            \n",
    "            return {\n",
    "                'state': self.state.value,\n",
    "                'failure_count': self.failure_count,\n",
    "                'last_failure': self.last_failure_time,\n",
    "                'success_rate': success_rate,\n",
    "                'stats': self.stats.copy()\n",
    "            }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset circuit breaker to closed state\"\"\"\n",
    "        with self._lock:\n",
    "            self.failure_count = 0\n",
    "            self.last_failure_time = None\n",
    "            if self.state != CircuitState.CLOSED:\n",
    "                self._change_state(CircuitState.CLOSED, \"manual reset\")\n",
    "\n",
    "# Test the circuit breaker\nprint(\"üß™ Testing Circuit Breaker...\")\n\n# Create a failing function for testing\nclass UnreliableService:\n",
    "    def __init__(self, failure_rate=0.7):\n",
    "        self.failure_rate = failure_rate\n",
    "        self.call_count = 0\n",
    "    \n",
    "    def unreliable_call(self):\n",
    "        self.call_count += 1\n",
    "        if self.call_count <= 3:  # First 3 calls always fail\n",
    "            raise requests.RequestException(f\"Simulated failure #{self.call_count}\")\n",
    "        return f\"Success on call #{self.call_count}\"\n",
    "\n",
    "# Test circuit breaker behavior\nservice = UnreliableService()\ncircuit_breaker = CircuitBreaker(failure_threshold=3, timeout=2)\n\nprint(\"\\nüìä Circuit Breaker Test Sequence:\")\nfor i in range(8):\n",
    "    try:\n",
    "        result = circuit_breaker.call(service.unreliable_call)\n",
    "        print(f\"  Call {i+1}: ‚úÖ {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Call {i+1}: ‚ùå {str(e)[:50]}\")\n",
    "    \n",
    "    # Show circuit state\n",
    "    status = circuit_breaker.get_status()\n",
    "    print(f\"    State: {status['state']}, Failures: {status['failure_count']}\")\n",
    "    \n",
    "    # Brief pause between calls\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Test recovery after timeout\nprint(\"\\n‚è∞ Testing recovery after timeout...\")\ntime.sleep(2.5)  # Wait for timeout\n\ntry:\n",
    "    result = circuit_breaker.call(service.unreliable_call)\n",
    "    print(f\"Recovery call: ‚úÖ {result}\")\nexcept Exception as e:\n    print(f\"Recovery call: ‚ùå {e}\")\n\nfinal_status = circuit_breaker.get_status()\nprint(f\"\\nüìà Final Stats: {final_status['stats']}\")\nprint(f\"Success Rate: {final_status['success_rate']:.1%}\")\n\nprint(\"‚úÖ Circuit Breaker implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Tool Orchestration (8 minutes)\n",
    "\n",
    "Combine all tools into a comprehensive invoice enhancement system.\n",
    "\n",
    "**Your Task:** Complete the invoice enhancement orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceEnhancementOrchestrator:\n",
    "    \"\"\"Orchestrates all tools for comprehensive invoice enhancement\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # TODO: Initialize all tools with circuit breakers\n",
    "        self.currency_converter = CurrencyConverterTool()\n",
    "        self.vat_validator = VATValidatorTool()\n",
    "        \n",
    "        # Circuit breakers for each service\n",
    "        self.currency_circuit = CircuitBreaker(failure_threshold=3, timeout=30)\n",
    "        self.vat_circuit = CircuitBreaker(failure_threshold=2, timeout=45)\n",
    "        \n",
    "        # Standard currencies for conversion\n",
    "        self.target_currencies = [\"USD\", \"EUR\", \"GBP\"]\n",
    "        \n",
    "        print(\"üéØ Invoice Enhancement Orchestrator initialized\")\n",
    "    \n",
    "    def enhance_invoice_data(self, invoice: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Enhance invoice with currency conversion and VAT validation\"\"\"\n",
    "        # TODO: Implement comprehensive invoice enhancement\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nüßæ Enhancing invoice: {invoice.get('invoice_id', 'Unknown')}\")\n",
    "        \n",
    "        enhanced_invoice = invoice.copy()\n",
    "        enhancement_metadata = {\n",
    "            'processing_start': datetime.now().isoformat(),\n",
    "            'services_used': [],\n",
    "            'total_cost': 0.0,\n",
    "            'errors': [],\n",
    "            'warnings': []\n",
    "        }\n",
    "        \n",
    "        # Extract invoice details\n",
    "        amount = invoice.get('amount', 0)\n",
    "        original_currency = invoice.get('currency', 'USD')\n",
    "        vat_number = invoice.get('vat_number')\n",
    "        \n",
    "        # 1. Currency Conversion (parallel for multiple currencies)\n",
    "        if amount > 0 and original_currency:\n",
    "            try:\n",
    "                print(f\"üí± Converting {amount} {original_currency} to multiple currencies...\")\n",
    "                \n",
    "                # Filter out the original currency\n",
    "                target_currencies = [c for c in self.target_currencies if c != original_currency]\n",
    "                \n",
    "                conversion_result = self.currency_circuit.call(\n",
    "                    self.currency_converter.convert_to_multiple,\n",
    "                    amount,\n",
    "                    original_currency,\n",
    "                    target_currencies\n",
    "                )\n",
    "                \n",
    "                enhanced_invoice['currency_conversions'] = conversion_result['conversions']\n",
    "                enhancement_metadata['total_cost'] += conversion_result['total_cost']\n",
    "                enhancement_metadata['services_used'].append('currency_converter')\n",
    "                \n",
    "                print(f\"   ‚úÖ Converted to {conversion_result['currencies_processed']} currencies\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Currency conversion failed: {e}\"\n",
    "                enhancement_metadata['errors'].append(error_msg)\n",
    "                print(f\"   ‚ùå {error_msg}\")\n",
    "        \n",
    "        # 2. VAT Validation\n",
    "        if vat_number:\n",
    "            try:\n",
    "                print(f\"üîç Validating VAT number: {vat_number}\")\n",
    "                \n",
    "                vat_result = self.vat_circuit.call(\n",
    "                    self.vat_validator.validate,\n",
    "                    vat_number,\n",
    "                    invoice.get('vendor', '')\n",
    "                )\n",
    "                \n",
    "                enhanced_invoice['vat_validation'] = vat_result\n",
    "                enhancement_metadata['total_cost'] += vat_result.get('cost', 0)\n",
    "                enhancement_metadata['services_used'].append('vat_validator')\n",
    "                \n",
    "                if vat_result.get('valid'):\n",
    "                    print(f\"   ‚úÖ VAT valid: {vat_result.get('company', 'Unknown company')}\")\n",
    "                else:\n",
    "                    warning_msg = f\"VAT validation failed: {vat_result.get('reason', 'Unknown')}\"\n",
    "                    enhancement_metadata['warnings'].append(warning_msg)\n",
    "                    print(f\"   ‚ö†Ô∏è {warning_msg}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"VAT validation failed: {e}\"\n",
    "                enhancement_metadata['errors'].append(error_msg)\n",
    "                print(f\"   ‚ùå {error_msg}\")\n",
    "        \n",
    "        # 3. Risk Assessment\n",
    "        risk_score = self._calculate_risk_score(enhanced_invoice)\n",
    "        enhanced_invoice['risk_assessment'] = risk_score\n",
    "        \n",
    "        # 4. Processing Summary\n",
    "        processing_time = time.time() - start_time\n",
    "        enhancement_metadata.update({\n",
    "            'processing_end': datetime.now().isoformat(),\n",
    "            'processing_time_seconds': processing_time,\n",
    "            'enhancement_version': '1.0'\n",
    "        })\n",
    "        \n",
    "        enhanced_invoice['enhancement_metadata'] = enhancement_metadata\n",
    "        \n",
    "        print(f\"‚úÖ Enhancement complete in {processing_time:.2f}s (cost: ${enhancement_metadata['total_cost']:.4f})\")\n",
    "        \n",
    "        return enhanced_invoice\n",
    "    \n",
    "    def _calculate_risk_score(self, invoice: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate overall risk score for the invoice\"\"\"\n",
    "        # TODO: Implement risk scoring logic\n",
    "        risk_factors = []\n",
    "        risk_score = 0.0\n",
    "        \n",
    "        # Amount-based risk\n",
    "        amount = invoice.get('amount', 0)\n",
    "        if amount > 50000:\n",
    "            risk_factors.append(\"High amount (>$50k)\")\n",
    "            risk_score += 0.3\n",
    "        elif amount > 10000:\n",
    "            risk_factors.append(\"Medium amount (>$10k)\")\n",
    "            risk_score += 0.1\n",
    "        \n",
    "        # VAT validation risk\n",
    "        vat_validation = invoice.get('vat_validation', {})\n",
    "        if not vat_validation.get('valid', True):\n",
    "            risk_factors.append(\"Invalid VAT number\")\n",
    "            risk_score += 0.4\n",
    "        \n",
    "        # Currency conversion risk\n",
    "        conversions = invoice.get('currency_conversions', {})\n",
    "        failed_conversions = sum(1 for conv in conversions.values() if 'error' in conv)\n",
    "        if failed_conversions > 0:\n",
    "            risk_factors.append(f\"{failed_conversions} currency conversion failures\")\n",
    "            risk_score += 0.2\n",
    "        \n",
    "        # Overall risk level\n",
    "        if risk_score >= 0.7:\n",
    "            risk_level = \"HIGH\"\n",
    "        elif risk_score >= 0.3:\n",
    "            risk_level = \"MEDIUM\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "        \n",
    "        return {\n",
    "            'risk_score': risk_score,\n",
    "            'risk_level': risk_level,\n",
    "            'risk_factors': risk_factors,\n",
    "            'requires_review': risk_score >= 0.5\n",
    "        }\n",
    "    \n",
    "    def process_batch(self, invoices: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Process multiple invoices in batch\"\"\"\n",
    "        # TODO: Implement batch processing\n",
    "        results = []\n",
    "        total_cost = 0.0\n",
    "        errors = 0\n",
    "        \n",
    "        print(f\"\\nüìä Processing batch of {len(invoices)} invoices...\")\n",
    "        \n",
    "        for i, invoice in enumerate(invoices):\n",
    "            try:\n",
    "                print(f\"\\n[{i+1}/{len(invoices)}] Processing {invoice.get('invoice_id', f'Invoice #{i+1}')}\")\n",
    "                enhanced = self.enhance_invoice_data(invoice)\n",
    "                results.append(enhanced)\n",
    "                total_cost += enhanced['enhancement_metadata']['total_cost']\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to process invoice {i+1}: {e}\")\n",
    "                errors += 1\n",
    "                results.append({\n",
    "                    'invoice_id': invoice.get('invoice_id', f'Invoice #{i+1}'),\n",
    "                    'error': str(e),\n",
    "                    'original_data': invoice\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'processed_invoices': results,\n",
    "            'total_processed': len(invoices),\n",
    "            'successful': len(invoices) - errors,\n",
    "            'failed': errors,\n",
    "            'total_cost': total_cost,\n",
    "            'average_cost_per_invoice': total_cost / len(invoices) if invoices else 0\n",
    "        }\n",
    "    \n",
    "    def get_performance_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive performance statistics\"\"\"\n",
    "        return {\n",
    "            'currency_converter': self.currency_converter.get_stats(),\n",
    "            'vat_validator': self.vat_validator.get_stats(),\n",
    "            'currency_circuit_breaker': self.currency_circuit.get_status(),\n",
    "            'vat_circuit_breaker': self.vat_circuit.get_status()\n",
    "        }\n",
    "\n",
    "# Test the orchestrator\nprint(\"üß™ Testing Invoice Enhancement Orchestrator...\")\norchestrator = InvoiceEnhancementOrchestrator()\n\n# Test single invoice enhancement\nif SAMPLE_INVOICES:\n    test_invoice = SAMPLE_INVOICES[0]\n    enhanced = orchestrator.enhance_invoice_data(test_invoice)\n    \n    print(f\"\\nüìã Enhancement Summary for {enhanced['invoice_id']}:\")\n    print(f\"   Services used: {enhanced['enhancement_metadata']['services_used']}\")\n    print(f\"   Total cost: ${enhanced['enhancement_metadata']['total_cost']:.4f}\")\n    print(f\"   Risk level: {enhanced['risk_assessment']['risk_level']}\")\n    print(f\"   Currencies converted: {len(enhanced.get('currency_conversions', {}))}\")\n    \n    vat_result = enhanced.get('vat_validation', {})\n    if vat_result:\n        print(f\"   VAT status: {'‚úÖ Valid' if vat_result.get('valid') else '‚ùå Invalid'}\")\n\nprint(\"\\n‚úÖ Tool Orchestration implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Production Testing (4 minutes)\n",
    "\n",
    "Test your complete system with various failure scenarios.\n",
    "\n",
    "**Your Task:** Run comprehensive tests to validate resilience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_production_tests():\n",
    "    \"\"\"Run comprehensive production tests\"\"\"\n",
    "    \n",
    "    print(\"üß™ PRODUCTION TESTING SUITE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    orchestrator = InvoiceEnhancementOrchestrator()\n",
    "    \n",
    "    # Test 1: Normal operation with all sample invoices\n",
    "    print(\"\\nüìä Test 1: Batch Processing\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if SAMPLE_INVOICES:\n",
    "        batch_result = orchestrator.process_batch(SAMPLE_INVOICES)\n",
    "        \n",
    "        print(f\"‚úÖ Batch Results:\")\n",
    "        print(f\"   Total processed: {batch_result['total_processed']}\")\n",
    "        print(f\"   Successful: {batch_result['successful']}\")\n",
    "        print(f\"   Failed: {batch_result['failed']}\")\n",
    "        print(f\"   Total cost: ${batch_result['total_cost']:.4f}\")\n",
    "        print(f\"   Average cost: ${batch_result['average_cost_per_invoice']:.4f}\")\n",
    "    \n",
    "    # Test 2: Cache performance\n",
    "    print(\"\\nüíæ Test 2: Cache Performance\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Process same invoice twice to test caching\n",
    "    if SAMPLE_INVOICES:\n",
    "        test_invoice = SAMPLE_INVOICES[0]\n",
    "        \n",
    "        print(\"First processing (cache miss):\")\n",
    "        start_time = time.time()\n",
    "        result1 = orchestrator.enhance_invoice_data(test_invoice)\n",
    "        time1 = time.time() - start_time\n",
    "        \n",
    "        print(\"\\nSecond processing (should hit cache):\")\n",
    "        start_time = time.time()\n",
    "        result2 = orchestrator.enhance_invoice_data(test_invoice)\n",
    "        time2 = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüìà Cache Performance:\")\n",
    "        print(f\"   First run: {time1:.2f}s\")\n",
    "        print(f\"   Second run: {time2:.2f}s\")\n",
    "        print(f\"   Speedup: {time1/time2:.1f}x faster\")\n",
    "    \n",
    "    # Test 3: Rate limiting\n",
    "    print(\"\\nüõë Test 3: Rate Limiting\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Create rapid fire requests to test rate limiting\n",
    "    rate_limiter = RateLimiter(max_calls=3, time_window=2)\n",
    "    \n",
    "    print(\"Testing rate limiter (3 calls per 2 seconds):\")\n",
    "    for i in range(6):\n",
    "        allowed = rate_limiter.acquire()\n",
    "        print(f\"   Request {i+1}: {'‚úÖ Allowed' if allowed else '‚ùå Rate limited'}\")\n",
    "        if not allowed:\n",
    "            wait_time = rate_limiter.wait_time()\n",
    "            print(f\"     Wait time: {wait_time:.1f}s\")\n",
    "    \n",
    "    # Test 4: Circuit breaker simulation\n",
    "    print(\"\\n‚ö° Test 4: Circuit Breaker Resilience\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Simulate service failures\n",
    "    failing_circuit = CircuitBreaker(failure_threshold=2, timeout=1)\n",
    "    \n",
    "    def failing_service():\n",
    "        \"\"\"Always fails for testing\"\"\"\n",
    "        raise requests.RequestException(\"Simulated service failure\")\n",
    "    \n",
    "    print(\"Simulating repeated service failures:\")\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            failing_circuit.call(failing_service)\n",
    "            print(f\"   Call {i+1}: ‚úÖ Success\")\n",
    "        except Exception as e:\n",
    "            status = failing_circuit.get_status()\n",
    "            print(f\"   Call {i+1}: ‚ùå {e} (State: {status['state']})\")\n",
    "    \n",
    "    # Test 5: Performance statistics\n",
    "    print(\"\\nüìä Test 5: Performance Statistics\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    stats = orchestrator.get_performance_stats()\n",
    "    \n",
    "    print(\"Currency Converter:\")\n",
    "    currency_stats = stats['currency_converter']\n",
    "    print(f\"   API calls: {currency_stats['api_calls']}\")\n",
    "    print(f\"   Cache hit rate: {currency_stats['cache_hit_rate']:.1%}\")\n",
    "    print(f\"   Money saved: ${currency_stats['money_saved']:.4f}\")\n",
    "    \n",
    "    print(\"\\nVAT Validator:\")\n",
    "    vat_stats = stats['vat_validator']\n",
    "    print(f\"   API calls: {vat_stats['api_calls']}\")\n",
    "    print(f\"   Cache hit rate: {vat_stats['cache_hit_rate']:.1%}\")\n",
    "    print(f\"   Money saved: ${vat_stats['money_saved']:.4f}\")\n",
    "    \n",
    "    print(\"\\nCircuit Breakers:\")\n",
    "    currency_circuit = stats['currency_circuit_breaker']\n",
    "    vat_circuit = stats['vat_circuit_breaker']\n",
    "    print(f\"   Currency CB: {currency_circuit['state']} (success rate: {currency_circuit['success_rate']:.1%})\")\n",
    "    print(f\"   VAT CB: {vat_circuit['state']} (success rate: {vat_circuit['success_rate']:.1%})\")\n",
    "    \n",
    "    # Test 6: Error handling\n",
    "    print(\"\\nüö® Test 6: Error Handling\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Test with malformed invoice\n",
    "    malformed_invoice = {\n",
    "        \"invoice_id\": \"MALFORMED-001\",\n",
    "        \"amount\": \"not_a_number\",\n",
    "        \"currency\": \"INVALID_CURRENCY\",\n",
    "        \"vat_number\": \"CLEARLY_INVALID\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = orchestrator.enhance_invoice_data(malformed_invoice)\n",
    "        errors = result['enhancement_metadata']['errors']\n",
    "        warnings = result['enhancement_metadata']['warnings']\n",
    "        \n",
    "        print(f\"   Errors handled: {len(errors)}\")\n",
    "        print(f\"   Warnings generated: {len(warnings)}\")\n",
    "        print(f\"   Processing completed: {'‚úÖ' if result else '‚ùå'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Unhandled error: {e}\")\n",
    "    \n",
    "    print(\"\\nüéØ PRODUCTION TESTING COMPLETE\")\n",
    "    print(\"‚úÖ All resilience patterns validated\")\n",
    "    print(\"‚úÖ Error handling confirmed\")\n",
    "    print(\"‚úÖ Performance metrics collected\")\n",
    "    print(\"‚úÖ Cost tracking operational\")\n",
    "\n",
    "# Run the complete test suite\nrun_production_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Lab Completion and Self-Assessment\n\n### What You've Built\n\nCongratulations! You've built a production-ready invoice enhancement system with:\n\n1. **Production-Ready API Tools**\n   - Currency converter with live exchange rates\n   - VAT validator using web search\n   - Comprehensive error handling and fallback strategies\n\n2. **Resilience Patterns**\n   - Circuit breakers for failure protection\n   - Rate limiting for quota management\n   - Intelligent caching for cost optimization\n\n3. **Enterprise Features**\n   - Cost tracking and optimization\n   - Performance monitoring\n   - Batch processing capabilities\n   - Comprehensive testing suite\n\n### Self-Assessment Questions\n\nRate your understanding (1-5 scale) and provide brief explanations:\n\n1. **API Integration** (1-5): ___\n   - How do you balance API costs with system reliability?\n   - What factors determine appropriate cache TTL values?\n\n2. **Circuit Breaker Pattern** (1-5): ___\n   - When should a circuit breaker open vs stay half-open?\n   - How do you tune failure thresholds for production?\n\n3. **Rate Limiting** (1-5): ___\n   - What's the difference between rate limiting and throttling?\n   - How do you handle rate limits across multiple services?\n\n4. **Caching Strategy** (1-5): ___\n   - What types of data should and shouldn't be cached?\n   - How do you invalidate stale cache entries?\n\n5. **Error Handling** (1-5): ___\n   - How do you distinguish between retryable and non-retryable errors?\n   - What information should be logged for debugging failures?\n\n### Key Production Patterns Learned\n\n**Circuit Breaker Benefits:**\n- Prevents cascade failures across services\n- Reduces unnecessary API calls during outages\n- Enables automatic recovery testing\n\n**Caching Strategy:**\n- 50-80% cost reduction with proper TTL\n- Significantly improved response times\n- Reduced load on external services\n\n**Rate Limiting:**\n- Protects against quota exhaustion\n- Enables fair resource allocation\n- Prevents service degradation\n\n**Cost Optimization:**\n- Real-time cost tracking enables budgeting\n- Cache hit rates directly impact costs\n- Batch processing reduces per-request overhead\n\n### Common Production Issues\n\n**Cache Stampede:**\n- Multiple requests for same expired data\n- Solution: Cache warming and distributed locking\n\n**Circuit Breaker Tuning:**\n- Too sensitive: Unnecessary service blocks\n- Too loose: Cascade failures not prevented\n- Solution: Monitor and adjust based on service characteristics\n\n**Rate Limit Coordination:**\n- Multiple service instances sharing quotas\n- Solution: Centralized rate limiting or distributed algorithms\n\n### Advanced Extensions\n\nIf you completed the lab early, consider these enhancements:\n\n1. **Exponential Backoff with Jitter**\n   - Implement retry logic with randomized delays\n   - Reduce thundering herd problems\n\n2. **Request Queuing**\n   - Queue requests during rate limiting\n   - Process when tokens become available\n\n3. **Metrics Collection**\n   - Export metrics to Prometheus/CloudWatch\n   - Create alerting on SLA violations\n\n4. **Health Checks**\n   - Implement comprehensive health endpoints\n   - Include dependency health status\n\n### Integration with LangGraph\n\nYour tools can be easily integrated into LangGraph workflows:\n\n```python\n# Add to existing workflow\nworkflow.add_node(\"enhance_invoice\", orchestrator.enhance_invoice_data)\nworkflow.add_node(\"convert_currency\", currency_converter_node)\nworkflow.add_node(\"validate_vat\", vat_validator_node)\n\n# Add conditional routing based on enhancement results\nworkflow.add_conditional_edges(\n    \"enhance_invoice\",\n    lambda state: \"approve\" if state[\"risk_assessment\"][\"risk_level\"] == \"LOW\" else \"review\",\n    {\"approve\": \"auto_approve\", \"review\": \"manual_review\"}\n)\n```\n\n### Next Steps\n\nTo further your API integration expertise:\n\n1. **Learn Advanced Patterns**\n   - Bulkhead pattern for resource isolation\n   - Saga pattern for distributed transactions\n\n2. **Monitor in Production**\n   - Set up comprehensive monitoring\n   - Create runbooks for common failures\n\n3. **Scale Considerations**\n   - Implement distributed caching (Redis)\n   - Use message queues for async processing\n\n**Congratulations!** You've built enterprise-grade API integration tools that can handle real production workloads reliably and cost-effectively!",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class ChromaVectorMemory:\n    \\\"\\\"\\\"Semantic memory management with Chroma for context-aware processing\\\"\\\"\\\"\n    \n    def __init__(self, collection_name=\\\"invoice_processing_lab\\\"):\n        \\\"\\\"\\\"Initialize Chroma vector database for semantic memory\\\"\\\"\\\"\n        # TODO: Initialize Chroma client and collection\n        try:\\n            self.client = chromadb.Client()\\n            self.collection_name = collection_name\\n            \\n            # Create or get collection\\n            try:\\n                self.collection = self.client.get_collection(collection_name)\\n                print(f\\\"‚úÖ Connected to existing Chroma collection: {collection_name}\\\")\\n            except:\\n                self.collection = self.client.create_collection(collection_name)\\n                print(f\\\"‚úÖ Created new Chroma collection: {collection_name}\\\")\\n            \\n            # Initialize embedding model\\n            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\\n            print(\\\"‚úÖ Sentence transformer loaded\\\")\\n            \\n        except Exception as e:\\n            print(f\\\"‚ùå Chroma initialization failed: {e}\\\")\\n            self.client = None\\n            self.collection = None\\n            self.embedding_model = None\\n    \\n    def store_processing_context(self, invoice_data: Dict[str, Any], \\n                               processing_result: Dict[str, Any], \\n                               session_id: str) -> str:\\n        \\\"\\\"\\\"Store processing context for semantic retrieval\\\"\\\"\\\"\\n        # TODO: Create and store semantic context document\\n        if not self.collection:\\n            return \\\"\\\"\\n        \\n        try:\\n            # Create context document\\n            context_parts = []\\n            \\n            # Invoice details\\n            vendor = invoice_data.get('vendor', 'unknown vendor')\\n            amount = invoice_data.get('amount', 0)\\n            currency = invoice_data.get('currency', 'USD')\\n            context_parts.append(f\\\"Invoice from {vendor} for {amount} {currency}\\\")\\n            \\n            # Processing results\\n            risk_assessment = processing_result.get('risk_assessment', {})\\n            context_parts.append(f\\\"Risk level: {risk_assessment.get('risk_level', 'unknown')}\\\")\\n            \\n            # Services used\\n            metadata = processing_result.get('enhancement_metadata', {})\\n            services = metadata.get('services_used', [])\\n            if services:\\n                context_parts.append(f\\\"Services used: {', '.join(services)}\\\")\\n            \\n            # Combine into document\\n            document = \\\" | \\\".join(context_parts)\\n            \\n            # Generate unique ID\\n            doc_id = f\\\"{session_id}_{invoice_data.get('invoice_id', 'unknown')}_{int(time.time())}\\\"\\n            \\n            # Create metadata\\n            doc_metadata = {\\n                \\\"session_id\\\": session_id,\\n                \\\"invoice_id\\\": invoice_data.get('invoice_id', ''),\\n                \\\"vendor\\\": vendor,\\n                \\\"amount\\\": amount,\\n                \\\"currency\\\": currency,\\n                \\\"risk_level\\\": risk_assessment.get('risk_level', 'unknown'),\\n                \\\"processing_time\\\": metadata.get('processing_time_seconds', 0),\\n                \\\"timestamp\\\": datetime.now().isoformat()\\n            }\\n            \\n            # Store in Chroma\\n            self.collection.add(\\n                documents=[document],\\n                ids=[doc_id],\\n                metadatas=[doc_metadata]\\n            )\\n            \\n            print(f\\\"üíæ Stored semantic context: {doc_id}\\\")\\n            return doc_id\\n            \\n        except Exception as e:\\n            print(f\\\"‚ùå Failed to store context: {e}\\\")\\n            return \\\"\\\"\\n    \\n    def find_similar_processing(self, invoice_data: Dict[str, Any], limit: int = 3) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Find similar invoice processing contexts\\\"\\\"\\\"\\n        # TODO: Search for similar processing contexts\\n        if not self.collection:\\n            return []\\n        \\n        try:\\n            # Create query from current invoice\\n            vendor = invoice_data.get('vendor', 'vendor')\\n            amount = invoice_data.get('amount', 0)\\n            currency = invoice_data.get('currency', 'USD')\\n            \\n            query = f\\\"Invoice from {vendor} for {amount} {currency}\\\"\\n            \\n            # Search for similar contexts\\n            results = self.collection.query(\\n                query_texts=[query],\\n                n_results=limit,\\n                include=['documents', 'metadatas', 'distances']\\n            )\\n            \\n            # Format results\\n            similar_contexts = []\\n            if results['documents'] and results['documents'][0]:\\n                for i, doc in enumerate(results['documents'][0]):\\n                    similar_contexts.append({\\n                        'document': doc,\\n                        'metadata': results['metadatas'][0][i],\\n                        'similarity': 1 - results['distances'][0][i]  # Convert distance to similarity\\n                    })\\n            \\n            print(f\\\"üîç Found {len(similar_contexts)} similar processing contexts\\\")\\n            return similar_contexts\\n            \\n        except Exception as e:\\n            print(f\\\"‚ùå Failed to find similar processing: {e}\\\")\\n            return []\\n    \\n    def get_processing_recommendations(self, invoice_data: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get AI-powered processing recommendations based on similar contexts\\\"\\\"\\\"\\n        # TODO: Generate recommendations from similar contexts\\n        similar_contexts = self.find_similar_processing(invoice_data, limit=5)\\n        \\n        if not similar_contexts:\\n            return {\\\"message\\\": \\\"No similar processing contexts found\\\"}\\n        \\n        # Analyze patterns from similar contexts\\n        recommendations = {\\n            \\\"processing_suggestions\\\": [],\\n            \\\"risk_insights\\\": [],\\n            \\\"api_recommendations\\\": [],\\n            \\\"confidence_score\\\": 0.0\\n        }\\n        \\n        # Extract patterns\\n        high_risk_count = 0\\n        avg_processing_time = 0\\n        common_currencies = set()\\n        \\n        for context in similar_contexts:\\n            metadata = context['metadata']\\n            \\n            # Risk patterns\\n            if metadata.get('risk_level') == 'HIGH':\\n                high_risk_count += 1\\n            \\n            # Performance patterns\\n            avg_processing_time += metadata.get('processing_time', 0)\\n            \\n            # Currency patterns\\n            common_currencies.add(metadata.get('currency', 'USD'))\\n        \\n        avg_processing_time = avg_processing_time / len(similar_contexts) if similar_contexts else 0\\n        high_risk_rate = high_risk_count / len(similar_contexts)\\n        \\n        # Generate recommendations\\n        if high_risk_rate > 0.5:\\n            recommendations[\\\"risk_insights\\\"].append(f\\\"Vendor has {high_risk_rate:.1%} high-risk rate - consider extra review\\\")\\n        \\n        if avg_processing_time > 2.0:\\n            recommendations[\\\"api_recommendations\\\"].append(\\\"Previous processing was slow - ensure caching is enabled\\\")\\n        \\n        if len(common_currencies) > 1:\\n            recommendations[\\\"processing_suggestions\\\"].append(f\\\"Vendor uses multiple currencies: {list(common_currencies)}\\\")\\n        \\n        # Calculate confidence\\n        avg_similarity = sum(c['similarity'] for c in similar_contexts) / len(similar_contexts)\\n        recommendations[\\\"confidence_score\\\"] = avg_similarity\\n        \\n        print(f\\\"üéØ Generated recommendations from {len(similar_contexts)} similar contexts\\\")\\n        return recommendations\\n    \\n    def analyze_vendor_patterns(self, vendor_name: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Analyze processing patterns for a specific vendor\\\"\\\"\\\"\\n        # TODO: Query vendor-specific patterns\\n        if not self.collection:\\n            return {\\\"error\\\": \\\"Vector memory not available\\\"}\\n        \\n        try:\\n            # Query by vendor metadata\\n            results = self.collection.query(\\n                query_texts=[f\\\"Invoice from {vendor_name}\\\"],\\n                n_results=10,\\n                where={\\\"vendor\\\": vendor_name},\\n                include=['documents', 'metadatas']\\n            )\\n            \\n            if not results['documents'] or not results['documents'][0]:\\n                return {\\\"message\\\": f\\\"No processing history found for {vendor_name}\\\"}\\n            \\n            # Analyze vendor patterns\\n            total_invoices = len(results['documents'][0])\\n            risk_levels = [meta.get('risk_level', 'UNKNOWN') for meta in results['metadatas'][0]]\\n            amounts = [meta.get('amount', 0) for meta in results['metadatas'][0]]\\n            currencies = [meta.get('currency', 'USD') for meta in results['metadatas'][0]]\\n            \\n            return {\\n                \\\"vendor_name\\\": vendor_name,\\n                \\\"total_invoices_processed\\\": total_invoices,\\n                \\\"risk_distribution\\\": {level: risk_levels.count(level) for level in set(risk_levels)},\\n                \\\"amount_range\\\": {\\\"min\\\": min(amounts), \\\"max\\\": max(amounts), \\\"avg\\\": sum(amounts) / len(amounts)},\\n                \\\"currencies_used\\\": list(set(currencies)),\\n                \\\"processing_confidence\\\": \\\"HIGH\\\" if total_invoices >= 5 else \\\"MEDIUM\\\" if total_invoices >= 2 else \\\"LOW\\\"\\n            }\\n            \\n        except Exception as e:\\n            return {\\\"error\\\": str(e)}\\n\\n# Test Chroma Vector Memory\\nprint(\\\"üß™ Testing Chroma Vector Memory...\\\")\\nchroma_memory = ChromaVectorMemory()\\n\\n# Test context storage (mock data)\\ntest_invoice = {\\n    \\\"invoice_id\\\": \\\"TEST-001\\\",\\n    \\\"vendor\\\": \\\"Test Vendor Inc.\\\",\\n    \\\"amount\\\": 5000.0,\\n    \\\"currency\\\": \\\"USD\\\"\\n}\\n\\ntest_result = {\\n    \\\"risk_assessment\\\": {\\\"risk_level\\\": \\\"LOW\\\"},\\n    \\\"enhancement_metadata\\\": {\\n        \\\"services_used\\\": [\\\"currency_converter\\\"],\\n        \\\"processing_time_seconds\\\": 1.5\\n    }\\n}\\n\\nif chroma_memory.collection:\\n    context_id = chroma_memory.store_processing_context(test_invoice, test_result, \\\"test_session\\\")\\n    recommendations = chroma_memory.get_processing_recommendations(test_invoice)\\n    print(f\\\"Recommendations: {recommendations}\\\")\\n\\nprint(\\\"‚úÖ Chroma Vector Memory implementation complete!\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class DuckDBMemoryManager:\n    \\\"\\\"\\\"Structured memory management with DuckDB for invoice processing analytics\\\"\\\"\\\"\n    \n    def __init__(self, db_path=\\\":memory:\\\"):\n        \\\"\\\"\\\"Initialize DuckDB connection and create tables\\\"\\\"\\\"\n        # TODO: Initialize DuckDB connection and create memory tables\n        try:\n            self.conn = duckdb.connect(db_path)\n            self._setup_tables()\n            print(f\\\"‚úÖ DuckDB memory manager connected: {db_path}\\\")\n        except Exception as e:\n            print(f\\\"‚ùå DuckDB initialization failed: {e}\\\")\n            self.conn = None\n    \n    def _setup_tables(self):\\n        \\\"\\\"\\\"Create tables for structured memory\\\"\\\"\\\"\\n        if not self.conn:\\n            return\\n        \\n        # TODO: Create invoice processing sessions table\\n        self.conn.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS processing_sessions (\\n                session_id VARCHAR PRIMARY KEY,\\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n                user_id VARCHAR,\\n                total_invoices INTEGER DEFAULT 0,\\n                total_cost DECIMAL(10,4) DEFAULT 0.0,\\n                session_metadata JSON\\n            )\\n        \\\"\\\"\\\")\\n        \\n        # TODO: Create invoice processing records table\\n        self.conn.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS invoice_records (\\n                record_id VARCHAR PRIMARY KEY,\\n                session_id VARCHAR,\\n                invoice_id VARCHAR,\\n                vendor_name VARCHAR,\\n                amount DECIMAL(15,2),\\n                currency VARCHAR(3),\\n                processing_time DECIMAL(8,3),\\n                risk_level VARCHAR,\\n                apis_used VARCHAR[],\\n                success BOOLEAN,\\n                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n                FOREIGN KEY (session_id) REFERENCES processing_sessions(session_id)\\n            )\\n        \\\"\\\"\\\")\\n        \\n        # TODO: Create vendor analytics table\\n        self.conn.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS vendor_analytics (\\n                vendor_id VARCHAR PRIMARY KEY,\\n                vendor_name VARCHAR,\\n                avg_amount DECIMAL(15,2),\\n                total_invoices INTEGER,\\n                avg_processing_time DECIMAL(8,3),\\n                typical_currency VARCHAR(3),\\n                risk_frequency DECIMAL(3,2),\\n                last_seen TIMESTAMP\\n            )\\n        \\\"\\\"\\\")\\n        \\n        print(\\\"‚úÖ DuckDB memory tables created\\\")\\n    \\n    def start_session(self, session_id: str, user_id: str = \\\"demo_user\\\") -> bool:\\n        \\\"\\\"\\\"Start a new processing session\\\"\\\"\\\"\\n        # TODO: Create new session record\\n        if not self.conn:\\n            return False\\n        \\n        try:\\n            self.conn.execute(\\\"\\\"\\\"\\n                INSERT INTO processing_sessions (session_id, user_id, session_metadata)\\n                VALUES (?, ?, ?)\\n            \\\"\\\"\\\", [session_id, user_id, json.dumps({\\\"started_at\\\": datetime.now().isoformat()})])\\n            \\n            print(f\\\"üìù Started session: {session_id}\\\")\\n            return True\\n        except Exception as e:\\n            print(f\\\"‚ùå Failed to start session: {e}\\\")\\n            return False\\n    \\n    def record_processing(self, session_id: str, invoice_data: Dict[str, Any], \\n                         processing_result: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Record invoice processing details\\\"\\\"\\\"\\n        # TODO: Store processing record and update analytics\\n        if not self.conn:\\n            return \\\"\\\"\\n        \\n        record_id = f\\\"rec_{int(time.time() * 1000)}\\\"\\n        \\n        try:\\n            # Extract processing details\\n            metadata = processing_result.get('enhancement_metadata', {})\\n            processing_time = metadata.get('processing_time_seconds', 0)\\n            risk_assessment = processing_result.get('risk_assessment', {})\\n            \\n            # Insert processing record\\n            self.conn.execute(\\\"\\\"\\\"\\n                INSERT INTO invoice_records \\n                (record_id, session_id, invoice_id, vendor_name, amount, currency, \\n                 processing_time, risk_level, apis_used, success)\\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\\n            \\\"\\\"\\\", [\\n                record_id, session_id,\\n                invoice_data.get('invoice_id', ''),\\n                invoice_data.get('vendor', ''),\\n                invoice_data.get('amount', 0),\\n                invoice_data.get('currency', 'USD'),\\n                processing_time,\\n                risk_assessment.get('risk_level', 'UNKNOWN'),\\n                metadata.get('services_used', []),\\n                len(metadata.get('errors', [])) == 0\\n            ])\\n            \\n            # Update vendor analytics\\n            self._update_vendor_analytics(invoice_data, processing_result)\\n            \\n            print(f\\\"üíæ Recorded processing: {record_id}\\\")\\n            return record_id\\n            \\n        except Exception as e:\\n            print(f\\\"‚ùå Failed to record processing: {e}\\\")\\n            return \\\"\\\"\\n    \\n    def _update_vendor_analytics(self, invoice_data: Dict[str, Any], processing_result: Dict[str, Any]):\\n        \\\"\\\"\\\"Update vendor analytics with new processing data\\\"\\\"\\\"\\n        # TODO: Update or insert vendor analytics\\n        vendor_name = invoice_data.get('vendor', '')\\n        if not vendor_name:\\n            return\\n        \\n        vendor_id = hashlib.md5(vendor_name.encode()).hexdigest()[:16]\\n        amount = invoice_data.get('amount', 0)\\n        currency = invoice_data.get('currency', 'USD')\\n        processing_time = processing_result.get('enhancement_metadata', {}).get('processing_time_seconds', 0)\\n        is_high_risk = processing_result.get('risk_assessment', {}).get('risk_level') == 'HIGH'\\n        \\n        # Check if vendor exists\\n        existing = self.conn.execute(\\\"\\\"\\\"\\n            SELECT vendor_id FROM vendor_analytics WHERE vendor_id = ?\\n        \\\"\\\"\\\", [vendor_id]).fetchone()\\n        \\n        if existing:\\n            # Update existing vendor\\n            self.conn.execute(\\\"\\\"\\\"\\n                UPDATE vendor_analytics \\n                SET avg_amount = (avg_amount + ?) / 2,\\n                    total_invoices = total_invoices + 1,\\n                    avg_processing_time = (avg_processing_time + ?) / 2,\\n                    risk_frequency = (risk_frequency * total_invoices + ?) / (total_invoices + 1),\\n                    last_seen = CURRENT_TIMESTAMP\\n                WHERE vendor_id = ?\\n            \\\"\\\"\\\", [amount, processing_time, 1.0 if is_high_risk else 0.0, vendor_id])\\n        else:\\n            # Create new vendor\\n            self.conn.execute(\\\"\\\"\\\"\\n                INSERT INTO vendor_analytics \\n                (vendor_id, vendor_name, avg_amount, total_invoices, avg_processing_time, \\n                 typical_currency, risk_frequency, last_seen)\\n                VALUES (?, ?, ?, 1, ?, ?, ?, CURRENT_TIMESTAMP)\\n            \\\"\\\"\\\", [vendor_id, vendor_name, amount, processing_time, currency, 1.0 if is_high_risk else 0.0])\\n    \\n    def get_vendor_insights(self, vendor_name: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get insights about vendor processing patterns\\\"\\\"\\\"\\n        # TODO: Query vendor analytics and processing history\\n        if not self.conn:\\n            return {\\\"error\\\": \\\"Database not available\\\"}\\n        \\n        try:\\n            vendor_id = hashlib.md5(vendor_name.encode()).hexdigest()[:16]\\n            \\n            # Get vendor analytics\\n            vendor_data = self.conn.execute(\\\"\\\"\\\"\\n                SELECT * FROM vendor_analytics WHERE vendor_id = ?\\n            \\\"\\\"\\\", [vendor_id]).fetchone()\\n            \\n            if not vendor_data:\\n                return {\\\"message\\\": \\\"No historical data for this vendor\\\"}\\n            \\n            # Convert to dict\\n            columns = [desc[0] for desc in self.conn.description]\\n            vendor_dict = dict(zip(columns, vendor_data))\\n            \\n            # Get recent processing history\\n            recent_history = self.conn.execute(\\\"\\\"\\\"\\n                SELECT COUNT(*) as recent_count, AVG(processing_time) as avg_time\\n                FROM invoice_records \\n                WHERE vendor_name = ? AND processed_at > datetime('now', '-30 days')\\n            \\\"\\\"\\\", [vendor_name]).fetchone()\\n            \\n            vendor_dict['recent_activity'] = {\\n                'invoices_last_30_days': recent_history[0] if recent_history else 0,\\n                'avg_processing_time_recent': recent_history[1] if recent_history else 0\\n            }\\n            \\n            return vendor_dict\\n            \\n        except Exception as e:\\n            return {\\\"error\\\": str(e)}\\n    \\n    def get_session_analytics(self, session_id: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get comprehensive session analytics\\\"\\\"\\\"\\n        # TODO: Generate session analytics report\\n        if not self.conn:\\n            return {\\\"error\\\": \\\"Database not available\\\"}\\n        \\n        try:\\n            # Session summary\\n            session_stats = self.conn.execute(\\\"\\\"\\\"\\n                SELECT \\n                    COUNT(*) as total_invoices,\\n                    AVG(amount) as avg_amount,\\n                    SUM(amount) as total_amount,\\n                    AVG(processing_time) as avg_processing_time,\\n                    COUNT(DISTINCT vendor_name) as unique_vendors,\\n                    COUNT(DISTINCT currency) as currencies_used,\\n                    SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful_processes\\n                FROM invoice_records \\n                WHERE session_id = ?\\n            \\\"\\\"\\\", [session_id]).fetchone()\\n            \\n            if not session_stats or session_stats[0] == 0:\\n                return {\\\"message\\\": \\\"No processing data for this session\\\"}\\n            \\n            # Risk breakdown\\n            risk_breakdown = self.conn.execute(\\\"\\\"\\\"\\n                SELECT risk_level, COUNT(*) as count\\n                FROM invoice_records \\n                WHERE session_id = ?\\n                GROUP BY risk_level\\n            \\\"\\\"\\\", [session_id]).fetchall()\\n            \\n            return {\\n                'total_invoices': session_stats[0],\\n                'avg_amount': session_stats[1],\\n                'total_amount': session_stats[2],\\n                'avg_processing_time': session_stats[3],\\n                'unique_vendors': session_stats[4],\\n                'currencies_used': session_stats[5],\\n                'success_rate': session_stats[6] / session_stats[0] if session_stats[0] > 0 else 0,\\n                'risk_breakdown': {level: count for level, count in risk_breakdown}\\n            }\\n            \\n        except Exception as e:\\n            return {\\\"error\\\": str(e)}\\n\\n# Test DuckDB Memory Manager\\nprint(\\\"üß™ Testing DuckDB Memory Manager...\\\")\\nduckdb_memory = DuckDBMemoryManager()\\n\\n# Test session creation\\nsession_id = f\\\"test_session_{int(time.time())}\\\"\\nduckdb_memory.start_session(session_id, \\\"test_user\\\")\\n\\nprint(\\\"‚úÖ DuckDB Memory Manager implementation complete!\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Install memory system dependencies\nprint(\"üì¶ Installing memory system dependencies...\")\n!pip install -q duckdb==0.9.2 chromadb==0.4.24 sentence-transformers==2.2.2\n\n# Import memory system libraries\nimport duckdb\nimport chromadb\nfrom sentence_transformers import SentenceTransformer\nimport sqlite3  # fallback for compatibility\n\nprint(\"‚úÖ Memory system libraries loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Task 6: Memory Systems Integration (12 minutes)\n\nImplement DuckDB and Chroma memory systems to enable intelligent context management and cross-session learning.\n\n**Your Task:** Complete the memory-integrated invoice processor that learns from past processing patterns.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Completion and Self-Assessment\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "Congratulations! You've built a production-ready invoice enhancement system with:\n",
    "\n",
    "1. **Production-Ready API Tools**\n",
    "   - Currency converter with live exchange rates\n",
    "   - VAT validator using web search\n",
    "   - Comprehensive error handling and fallback strategies\n",
    "\n",
    "2. **Resilience Patterns**\n",
    "   - Circuit breakers for failure protection\n",
    "   - Rate limiting for quota management\n",
    "   - Intelligent caching for cost optimization\n",
    "\n",
    "3. **Enterprise Features**\n",
    "   - Cost tracking and optimization\n",
    "   - Performance monitoring\n",
    "   - Batch processing capabilities\n",
    "   - Comprehensive testing suite\n",
    "\n",
    "### Self-Assessment Questions\n",
    "\n",
    "Rate your understanding (1-5 scale) and provide brief explanations:\n",
    "\n",
    "1. **API Integration** (1-5): ___\n",
    "   - How do you balance API costs with system reliability?\n",
    "   - What factors determine appropriate cache TTL values?\n",
    "\n",
    "2. **Circuit Breaker Pattern** (1-5): ___\n",
    "   - When should a circuit breaker open vs stay half-open?\n",
    "   - How do you tune failure thresholds for production?\n",
    "\n",
    "3. **Rate Limiting** (1-5): ___\n",
    "   - What's the difference between rate limiting and throttling?\n",
    "   - How do you handle rate limits across multiple services?\n",
    "\n",
    "4. **Caching Strategy** (1-5): ___\n",
    "   - What types of data should and shouldn't be cached?\n",
    "   - How do you invalidate stale cache entries?\n",
    "\n",
    "5. **Error Handling** (1-5): ___\n",
    "   - How do you distinguish between retryable and non-retryable errors?\n",
    "   - What information should be logged for debugging failures?\n",
    "\n",
    "### Key Production Patterns Learned\n",
    "\n",
    "**Circuit Breaker Benefits:**\n",
    "- Prevents cascade failures across services\n",
    "- Reduces unnecessary API calls during outages\n",
    "- Enables automatic recovery testing\n",
    "\n",
    "**Caching Strategy:**\n",
    "- 50-80% cost reduction with proper TTL\n",
    "- Significantly improved response times\n",
    "- Reduced load on external services\n",
    "\n",
    "**Rate Limiting:**\n",
    "- Protects against quota exhaustion\n",
    "- Enables fair resource allocation\n",
    "- Prevents service degradation\n",
    "\n",
    "**Cost Optimization:**\n",
    "- Real-time cost tracking enables budgeting\n",
    "- Cache hit rates directly impact costs\n",
    "- Batch processing reduces per-request overhead\n",
    "\n",
    "### Common Production Issues\n",
    "\n",
    "**Cache Stampede:**\n",
    "- Multiple requests for same expired data\n",
    "- Solution: Cache warming and distributed locking\n",
    "\n",
    "**Circuit Breaker Tuning:**\n",
    "- Too sensitive: Unnecessary service blocks\n",
    "- Too loose: Cascade failures not prevented\n",
    "- Solution: Monitor and adjust based on service characteristics\n",
    "\n",
    "**Rate Limit Coordination:**\n",
    "- Multiple service instances sharing quotas\n",
    "- Solution: Centralized rate limiting or distributed algorithms\n",
    "\n",
    "### Advanced Extensions\n",
    "\n",
    "If you completed the lab early, consider these enhancements:\n",
    "\n",
    "1. **Exponential Backoff with Jitter**\n",
    "   - Implement retry logic with randomized delays\n",
    "   - Reduce thundering herd problems\n",
    "\n",
    "2. **Request Queuing**\n",
    "   - Queue requests during rate limiting\n",
    "   - Process when tokens become available\n",
    "\n",
    "3. **Metrics Collection**\n",
    "   - Export metrics to Prometheus/CloudWatch\n",
    "   - Create alerting on SLA violations\n",
    "\n",
    "4. **Health Checks**\n",
    "   - Implement comprehensive health endpoints\n",
    "   - Include dependency health status\n",
    "\n",
    "### Integration with LangGraph\n",
    "\n",
    "Your tools can be easily integrated into LangGraph workflows:\n",
    "\n",
    "```python\n",
    "# Add to existing workflow\n",
    "workflow.add_node(\"enhance_invoice\", orchestrator.enhance_invoice_data)\n",
    "workflow.add_node(\"convert_currency\", currency_converter_node)\n",
    "workflow.add_node(\"validate_vat\", vat_validator_node)\n",
    "\n",
    "# Add conditional routing based on enhancement results\n",
    "workflow.add_conditional_edges(\n",
    "    \"enhance_invoice\",\n",
    "    lambda state: \"approve\" if state[\"risk_assessment\"][\"risk_level\"] == \"LOW\" else \"review\",\n",
    "    {\"approve\": \"auto_approve\", \"review\": \"manual_review\"}\n",
    ")\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To further your API integration expertise:\n",
    "\n",
    "1. **Learn Advanced Patterns**\n",
    "   - Bulkhead pattern for resource isolation\n",
    "   - Saga pattern for distributed transactions\n",
    "\n",
    "2. **Monitor in Production**\n",
    "   - Set up comprehensive monitoring\n",
    "   - Create runbooks for common failures\n",
    "\n",
    "3. **Scale Considerations**\n",
    "   - Implement distributed caching (Redis)\n",
    "   - Use message queues for async processing\n",
    "\n",
    "**Congratulations!** You've built enterprise-grade API integration tools that can handle real production workloads reliably and cost-effectively!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}