{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2, Session 5 Lab: Deploy Invoice Agent as Production API\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this 45-minute hands-on lab, you will:\n",
    "\n",
    "1. **Transform LangGraph agents into production APIs** using FastAPI\n",
    "2. **Implement real-time streaming** with Server-Sent Events (SSE) \n",
    "3. **Add enterprise security** with authentication and rate limiting\n",
    "4. **Create monitoring endpoints** for health checks and metrics\n",
    "5. **Containerize with Docker** for consistent deployment\n",
    "6. **Deploy to cloud platforms** using Hugging Face Spaces\n",
    "\n",
    "## üèóÔ∏è What We're Building\n",
    "\n",
    "A **production-ready Invoice Processing API** that:\n",
    "- ‚úÖ Accepts file uploads and processing requests\n",
    "- ‚úÖ Streams results as they're generated (no waiting!)\n",
    "- ‚úÖ Authenticates users and prevents abuse\n",
    "- ‚úÖ Runs anywhere with Docker containers\n",
    "- ‚úÖ Deploys to free cloud hosting\n",
    "\n",
    "## üöÄ Why This Matters\n",
    "\n",
    "**Real-world scenario**: Your company's procurement team needs to process hundreds of invoices daily. They need:\n",
    "- **Fast processing** - stream results as they come\n",
    "- **Secure access** - only authorized users can process invoices  \n",
    "- **Reliable deployment** - works consistently across environments\n",
    "- **Scalable architecture** - handles multiple users simultaneously\n",
    "\n",
    "This lab teaches you to **ship AI agents to production** - the most valuable skill for AI engineers!\n",
    "\n",
    "## ‚è∞ Time Allocation\n",
    "- **Setup & Core API** (8 minutes)\n",
    "- **Authentication & Security** (7 minutes) \n",
    "- **File Upload Handling** (8 minutes)\n",
    "- **Streaming Implementation** (10 minutes)\n",
    "- **Health & Monitoring** (5 minutes)\n",
    "- **Containerization** (5 minutes)\n",
    "- **Deployment** (7 minutes)\n",
    "\n",
    "## üìã Prerequisites Checklist\n",
    "- [x] Completed Day 2 Sessions 1-4 labs\n",
    "- [x] Understanding of FastAPI basics\n",
    "- [x] Familiarity with LangGraph agents\n",
    "- [x] Docker basics (for deployment)\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to ship your first AI agent to production?** Let's build something amazing! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Global configuration - Instructor will fill these\nOLLAMA_URL = \"http://XX.XX.XX.XX\"  # Course server IP (port 80)\nAPI_TOKEN = \"YOUR_TOKEN_HERE\"      # Instructor provides token\nMODEL = \"qwen3:8b\"                  # Default model on server\n\n# Load API keys from environment variables (NEVER hardcode in notebooks!)\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Voice API Keys (loaded securely from environment)\nCARTESIA_API_KEY = os.getenv(\"CARTESIA_API_KEY\")  # TTS\nDEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")  # STT\n\n# Verify keys are loaded\nif not CARTESIA_API_KEY:\n    print(\"‚ö†Ô∏è  Warning: CARTESIA_API_KEY not found in environment variables\")\nif not DEEPGRAM_API_KEY:\n    print(\"‚ö†Ô∏è  Warning: DEEPGRAM_API_KEY not found in environment variables\")\n\nprint(\"‚úÖ Configuration loaded from environment variables\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Setup Environment and Core API (8 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Create the foundational FastAPI application with proper configuration, error handling, and CORS setup for web clients.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- How to structure a production FastAPI application\n",
    "- Why CORS is essential for web-based clients\n",
    "- How to manage application state and lifecycle events\n",
    "- Best practices for API documentation\n",
    "\n",
    "### üìù Implementation Guide\n",
    "\n",
    "**FastAPI** is perfect for AI APIs because it provides:\n",
    "- **Automatic documentation** (Swagger UI)\n",
    "- **Type validation** with Pydantic models\n",
    "- **Async support** for concurrent requests\n",
    "- **Easy deployment** with Docker/cloud platforms\n",
    "\n",
    "**CORS (Cross-Origin Resource Sharing)** allows your API to be called from web browsers. Without it, browser security blocks requests from different domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install fastapi uvicorn python-multipart sse-starlette redis pydantic python-dotenv"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Depends\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from fastapi.responses import StreamingResponse, JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from sse_starlette.sse import EventSourceResponse\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "from typing import Optional, Dict, List\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize FastAPI app with metadata\n",
    "# HINT: Use title, description, version parameters for good documentation\n",
    "app = FastAPI(\n",
    "    title=\"Invoice Processing Agent API\",\n",
    "    description=\"Multimodal agent for invoice extraction and processing with voice support\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# TODO: Add CORS middleware for web access\n",
    "# HINT: Configure origins, credentials, methods, and headers\n",
    "# NOTE: In production, restrict origins to your domain!\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # TODO: Replace with your domain in production\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ FastAPI app initialized with CORS support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create global state management class\n",
    "# HINT: This will store our LangGraph agent, Redis connection, and active jobs\n",
    "class AgentState:\n",
    "    def __init__(self):\n",
    "        self.langgraph_app = None  # Will be initialized\n",
    "        self.redis_client = None   # For caching and sessions\n",
    "        self.processing_jobs = {}  # In-memory job tracking\n",
    "        self.startup_time = datetime.now()\n",
    "\n",
    "# Create global state instance\n",
    "agent_state = AgentState()\n",
    "\n",
    "# TODO: Add startup event handler\n",
    "# HINT: This runs when the API starts - perfect for loading models\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"Initialize agent and connections on startup\"\"\"\n",
    "    print(\"üöÄ Starting Invoice Agent API...\")\n",
    "    \n",
    "    # TODO: Initialize LangGraph agent here\n",
    "    # agent_state.langgraph_app = load_invoice_agent()\n",
    "    \n",
    "    # TODO: Connect to Redis for caching (optional)\n",
    "    # agent_state.redis_client = redis.Redis(host='localhost', port=6379)\n",
    "    \n",
    "    # TODO: Preload any required models\n",
    "    # Example: Load OCR models, embedding models, etc.\n",
    "    \n",
    "    print(\"‚úÖ Invoice Agent API started successfully\")\n",
    "\n",
    "# TODO: Add shutdown event handler\n",
    "@app.on_event(\"shutdown\")\n",
    "async def shutdown_event():\n",
    "    \"\"\"Cleanup on shutdown\"\"\"\n",
    "    print(\"üëã Shutting down Invoice Agent API...\")\n",
    "    \n",
    "    # TODO: Close connections gracefully\n",
    "    # TODO: Save any pending state if needed\n",
    "    \n",
    "    print(\"‚úÖ Shutdown complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement Authentication & Rate Limiting (7 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Secure your API with token-based authentication and prevent abuse with rate limiting.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- How to implement Bearer token authentication in FastAPI\n",
    "- Token bucket algorithm for rate limiting\n",
    "- User tier management (free vs premium)\n",
    "- Security best practices for production APIs\n",
    "\n",
    "### üìù Why Authentication Matters\n",
    "\n",
    "**Without authentication**, anyone can:\n",
    "- ‚ùå Overload your API with requests\n",
    "- ‚ùå Process sensitive documents\n",
    "- ‚ùå Run up your hosting costs\n",
    "- ‚ùå Access your AI models for free\n",
    "\n",
    "**With authentication**, you can:\n",
    "- ‚úÖ Track usage per user\n",
    "- ‚úÖ Implement pricing tiers\n",
    "- ‚úÖ Prevent abuse and spam\n",
    "- ‚úÖ Meet compliance requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up HTTP Bearer token security\n",
    "# HINT: This extracts the token from 'Authorization: Bearer <token>' header\n",
    "security = HTTPBearer()\n",
    "\n",
    "# TODO: Create mock user database\n",
    "# NOTE: In production, use a real database with hashed tokens!\n",
    "API_KEYS = {\n",
    "    \"demo-key-123\": {\n",
    "        \"user\": \"demo_user\",\n",
    "        \"tier\": \"free\",\n",
    "        \"requests_remaining\": 100,\n",
    "        \"requests_per_hour\": 10\n",
    "    },\n",
    "    \"premium-key-456\": {\n",
    "        \"user\": \"premium_user\",\n",
    "        \"tier\": \"premium\",\n",
    "        \"requests_remaining\": 1000,\n",
    "        \"requests_per_hour\": 100\n",
    "    },\n",
    "    # TODO: Add your own test keys here\n",
    "}\n",
    "\n",
    "print(f\"üîë Configured {len(API_KEYS)} API keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement token verification function\n",
    "# HINT: This will be used as a FastAPI dependency\n",
    "async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    \"\"\"\n",
    "    Verify API key and check rate limits\n",
    "    Returns user info if valid, raises HTTPException if invalid\n",
    "    \"\"\"\n",
    "    token = credentials.credentials\n",
    "    \n",
    "    # TODO: Check if token exists\n",
    "    if token not in API_KEYS:\n",
    "        raise HTTPException(\n",
    "            status_code=403, \n",
    "            detail=\"Invalid API key. Please check your authorization header.\"\n",
    "        )\n",
    "    \n",
    "    user_info = API_KEYS[token]\n",
    "    \n",
    "    # TODO: Check rate limits\n",
    "    if user_info[\"requests_remaining\"] <= 0:\n",
    "        raise HTTPException(\n",
    "            status_code=429, \n",
    "            detail=f\"Rate limit exceeded. Upgrade to premium for higher limits.\"\n",
    "        )\n",
    "    \n",
    "    # TODO: Decrement request counter\n",
    "    # NOTE: In production, this should be atomic and persistent\n",
    "    user_info[\"requests_remaining\"] -= 1\n",
    "    \n",
    "    return user_info\n",
    "\n",
    "print(\"üîí Token verification configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement rate limiter using token bucket algorithm\n",
    "# HINT: Token bucket allows burst traffic while maintaining average rate\n",
    "class RateLimiter:\n",
    "    \"\"\"Token bucket rate limiter for controlling request frequency\"\"\"\n",
    "    \n",
    "    def __init__(self, rate: int = 10, per: int = 60):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rate: Number of requests allowed\n",
    "            per: Time period in seconds\n",
    "        \"\"\"\n",
    "        self.rate = rate  # requests\n",
    "        self.per = per    # seconds\n",
    "        self.buckets = {}  # user_id -> bucket state\n",
    "    \n",
    "    def is_allowed(self, key: str) -> bool:\n",
    "        \"\"\"Check if request is allowed for given key\"\"\"\n",
    "        now = time.time()\n",
    "        \n",
    "        # TODO: Initialize bucket if not exists\n",
    "        if key not in self.buckets:\n",
    "            self.buckets[key] = {\"tokens\": self.rate, \"last\": now}\n",
    "            return True\n",
    "        \n",
    "        bucket = self.buckets[key]\n",
    "        \n",
    "        # TODO: Refill tokens based on time passed\n",
    "        time_passed = now - bucket[\"last\"]\n",
    "        tokens_to_add = time_passed * (self.rate / self.per)\n",
    "        bucket[\"tokens\"] = min(self.rate, bucket[\"tokens\"] + tokens_to_add)\n",
    "        bucket[\"last\"] = now\n",
    "        \n",
    "        # TODO: Check if tokens available\n",
    "        if bucket[\"tokens\"] >= 1:\n",
    "            bucket[\"tokens\"] -= 1\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Create global rate limiter: 10 requests per minute\n",
    "rate_limiter = RateLimiter(rate=10, per=60)\n",
    "\n",
    "print(\"‚è±Ô∏è Rate limiter initialized (10 req/min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: File Upload & Processing Endpoints (8 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Create endpoints to receive invoice images and initiate asynchronous processing jobs.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- How to handle file uploads in FastAPI\n",
    "- Pydantic models for request/response validation\n",
    "- Asynchronous job processing patterns\n",
    "- File validation and security considerations\n",
    "\n",
    "### üìù Why Async Processing?\n",
    "\n",
    "**Synchronous processing** (bad):\n",
    "- ‚ùå User waits 10-30 seconds for response\n",
    "- ‚ùå Request timeouts if processing takes too long\n",
    "- ‚ùå Server can't handle other requests meanwhile\n",
    "- ‚ùå Poor user experience\n",
    "\n",
    "**Asynchronous processing** (good):\n",
    "- ‚úÖ Immediate response with job ID\n",
    "- ‚úÖ User can check status or stream updates\n",
    "- ‚úÖ Server handles multiple requests concurrently\n",
    "- ‚úÖ Better scalability and user experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define Pydantic models for request/response validation\n",
    "# HINT: These ensure type safety and automatic API documentation\n",
    "\n",
    "class ProcessingRequest(BaseModel):\n",
    "    \"\"\"Request model for invoice processing configuration\"\"\"\n",
    "    instructions: Optional[str] = \"Extract all invoice data including vendor, amounts, dates, and line items\"\n",
    "    output_format: str = \"json\"  # json, text, or both\n",
    "    include_confidence: bool = True\n",
    "    voice_response: bool = False  # Enable voice synthesis\n",
    "    webhook_url: Optional[str] = None  # For notifications\n",
    "\n",
    "class ProcessingResponse(BaseModel):\n",
    "    \"\"\"Response with job information\"\"\"\n",
    "    job_id: str\n",
    "    status: str  # queued, processing, completed, failed\n",
    "    message: str\n",
    "    estimated_time_seconds: int\n",
    "    result_url: Optional[str] = None\n",
    "    stream_url: Optional[str] = None\n",
    "\n",
    "print(\"üìù Request/response models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create main file upload endpoint\n",
    "@app.post(\"/process/invoice\", response_model=ProcessingResponse)\n",
    "async def process_invoice(\n",
    "    file: UploadFile = File(..., description=\"Invoice image file (PNG, JPG, PDF)\"),\n",
    "    request: ProcessingRequest = ProcessingRequest(),\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload invoice image for processing\n",
    "    \n",
    "    This endpoint:\n",
    "    1. Validates the uploaded file\n",
    "    2. Creates an async processing job\n",
    "    3. Returns job ID for status tracking\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Validate file type\n",
    "    # HINT: Check content_type to ensure it's an image or PDF\n",
    "    allowed_types = [\"image/png\", \"image/jpeg\", \"image/jpg\", \"application/pdf\"]\n",
    "    if file.content_type not in allowed_types:\n",
    "        raise HTTPException(\n",
    "            status_code=400, \n",
    "            detail=f\"File type {file.content_type} not supported. Use PNG, JPG, or PDF.\"\n",
    "        )\n",
    "    \n",
    "    # TODO: Check file size limit (10MB max)\n",
    "    # HINT: Large files slow down processing and use more memory\n",
    "    max_size = 10 * 1024 * 1024  # 10MB\n",
    "    if file.size and file.size > max_size:\n",
    "        raise HTTPException(\n",
    "            status_code=400, \n",
    "            detail=f\"File too large ({file.size/1024/1024:.1f}MB). Maximum size is 10MB.\"\n",
    "        )\n",
    "    \n",
    "    # TODO: Check rate limit\n",
    "    if not rate_limiter.is_allowed(user_info[\"user\"]):\n",
    "        raise HTTPException(\n",
    "            status_code=429,\n",
    "            detail=\"Rate limit exceeded. Please wait before uploading another file.\"\n",
    "        )\n",
    "    \n",
    "    # TODO: Generate unique job ID\n",
    "    job_id = str(uuid.uuid4())\n",
    "    \n",
    "    # TODO: Read and store file content\n",
    "    # HINT: In production, save to S3/GCS instead of memory\n",
    "    file_content = await file.read()\n",
    "    \n",
    "    # TODO: Create processing job record\n",
    "    job = {\n",
    "        \"id\": job_id,\n",
    "        \"user\": user_info[\"user\"],\n",
    "        \"status\": \"queued\",\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"file_name\": file.filename,\n",
    "        \"file_size\": len(file_content),\n",
    "        \"file_type\": file.content_type,\n",
    "        \"instructions\": request.instructions,\n",
    "        \"output_format\": request.output_format,\n",
    "        \"voice_response\": request.voice_response,\n",
    "        \"progress\": 0\n",
    "    }\n",
    "    \n",
    "    # TODO: Store job in global state\n",
    "    # NOTE: In production, use Redis or database\n",
    "    agent_state.processing_jobs[job_id] = job\n",
    "    \n",
    "    # TODO: Start async processing task\n",
    "    # HINT: Use asyncio.create_task for background processing\n",
    "    asyncio.create_task(process_job_async(job_id, file_content, request))\n",
    "    \n",
    "    # TODO: Estimate processing time based on file size and user tier\n",
    "    base_time = 15  # seconds\n",
    "    size_factor = len(file_content) / (1024 * 1024)  # MB\n",
    "    tier_factor = 0.5 if user_info[\"tier\"] == \"premium\" else 1.0\n",
    "    estimated_time = int(base_time + (size_factor * 5) * tier_factor)\n",
    "    \n",
    "    return ProcessingResponse(\n",
    "        job_id=job_id,\n",
    "        status=\"queued\",\n",
    "        message=\"Invoice processing started. Use the stream URL for real-time updates.\",\n",
    "        estimated_time_seconds=estimated_time,\n",
    "        result_url=f\"/results/{job_id}\",\n",
    "        stream_url=f\"/stream/{job_id}\"\n",
    "    )\n",
    "\n",
    "print(\"üì§ File upload endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement async job processing function\n",
    "async def process_job_async(job_id: str, image_data: bytes, request: ProcessingRequest):\n",
    "    \"\"\"\n",
    "    Process invoice asynchronously in background\n",
    "    \n",
    "    This simulates the full LangGraph processing pipeline:\n",
    "    1. Image preprocessing \n",
    "    2. OCR extraction\n",
    "    3. LLM analysis\n",
    "    4. Result formatting\n",
    "    5. Optional voice synthesis\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = agent_state.processing_jobs[job_id]\n",
    "        \n",
    "        # TODO: Update status to processing\n",
    "        job[\"status\"] = \"processing\"\n",
    "        job[\"started_at\"] = datetime.now().isoformat()\n",
    "        \n",
    "        # TODO: Simulate processing steps with progress updates\n",
    "        # HINT: In real implementation, call your LangGraph agent here\n",
    "        \n",
    "        # Step 1: Image preprocessing (10%)\n",
    "        job[\"progress\"] = 10\n",
    "        job[\"current_step\"] = \"Preprocessing image...\"\n",
    "        await asyncio.sleep(1)  # Simulate processing time\n",
    "        \n",
    "        # Step 2: OCR extraction (30%)\n",
    "        job[\"progress\"] = 30\n",
    "        job[\"current_step\"] = \"Extracting text with OCR...\"\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        # Step 3: LLM analysis (70%)\n",
    "        job[\"progress\"] = 70\n",
    "        job[\"current_step\"] = \"Analyzing with LLM...\"\n",
    "        await asyncio.sleep(3)\n",
    "        \n",
    "        # Step 4: Result formatting (90%)\n",
    "        job[\"progress\"] = 90\n",
    "        job[\"current_step\"] = \"Formatting results...\"\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "        # TODO: Generate mock results\n",
    "        # HINT: Replace with actual LangGraph agent call:\n",
    "        # result = await agent_state.langgraph_app.ainvoke({\n",
    "        #     \"image_data\": image_data,\n",
    "        #     \"instructions\": request.instructions\n",
    "        # })\n",
    "        \n",
    "        mock_result = {\n",
    "            \"vendor\": \"ABC Supplies Inc.\",\n",
    "            \"invoice_number\": \"INV-2024-001\",\n",
    "            \"date\": \"2024-01-15\",\n",
    "            \"total_amount\": 1250.00,\n",
    "            \"currency\": \"USD\",\n",
    "            \"line_items\": [\n",
    "                {\"description\": \"Office Supplies\", \"quantity\": 10, \"unit_price\": 25.00, \"total\": 250.00},\n",
    "                {\"description\": \"Printing Paper\", \"quantity\": 20, \"unit_price\": 50.00, \"total\": 1000.00}\n",
    "            ],\n",
    "            \"confidence_scores\": {\n",
    "                \"vendor\": 0.95,\n",
    "                \"total_amount\": 0.98,\n",
    "                \"date\": 0.92\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # TODO: Add voice synthesis if requested\n",
    "        voice_url = None\n",
    "        if request.voice_response:\n",
    "            job[\"current_step\"] = \"Generating voice response...\"\n",
    "            # TODO: Call Cartesia TTS API here\n",
    "            # voice_url = await synthesize_voice_response(mock_result)\n",
    "            await asyncio.sleep(2)  # Simulate TTS processing\n",
    "            voice_url = f\"/audio/{job_id}.mp3\"  # Mock URL\n",
    "        \n",
    "        # TODO: Mark job as completed\n",
    "        job[\"status\"] = \"completed\"\n",
    "        job[\"progress\"] = 100\n",
    "        job[\"current_step\"] = \"Complete!\"\n",
    "        job[\"completed_at\"] = datetime.now().isoformat()\n",
    "        job[\"result\"] = mock_result\n",
    "        job[\"voice_url\"] = voice_url\n",
    "        \n",
    "        print(f\"‚úÖ Job {job_id} completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # TODO: Handle errors gracefully\n",
    "        job[\"status\"] = \"failed\"\n",
    "        job[\"error\"] = str(e)\n",
    "        job[\"failed_at\"] = datetime.now().isoformat()\n",
    "        print(f\"‚ùå Job {job_id} failed: {e}\")\n",
    "\n",
    "print(\"‚öôÔ∏è Async processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Streaming Results with Server-Sent Events (10 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Implement real-time streaming of processing updates using Server-Sent Events (SSE) for better user experience.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- How Server-Sent Events provide real-time updates\n",
    "- EventSourceResponse for streaming in FastAPI\n",
    "- Progress tracking and status updates\n",
    "- Browser compatibility considerations\n",
    "\n",
    "### üìù Why Streaming Matters\n",
    "\n",
    "**Without streaming** (polling approach):\n",
    "- ‚ùå User repeatedly calls `/status/{job_id}` every few seconds\n",
    "- ‚ùå Wastes bandwidth and server resources\n",
    "- ‚ùå Delayed updates (only on poll intervals)\n",
    "- ‚ùå Poor mobile battery life\n",
    "\n",
    "**With streaming** (SSE approach):\n",
    "- ‚úÖ Server pushes updates as they happen\n",
    "- ‚úÖ Minimal bandwidth usage\n",
    "- ‚úÖ Instant notifications\n",
    "- ‚úÖ Better user experience\n",
    "\n",
    "**SSE vs WebSockets:**\n",
    "- SSE: Simple, unidirectional (server ‚Üí client), works through proxies\n",
    "- WebSockets: Complex, bidirectional, may have firewall issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create streaming endpoint with Server-Sent Events\n",
    "@app.get(\"/stream/{job_id}\")\n",
    "async def stream_results(\n",
    "    job_id: str,\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"\n",
    "    Stream processing updates via Server-Sent Events\n",
    "    \n",
    "    Client usage:\n",
    "    ```javascript\n",
    "    const eventSource = new EventSource('/stream/job_123');\n",
    "    eventSource.onmessage = (event) => {\n",
    "        const data = JSON.parse(event.data);\n",
    "        console.log('Progress:', data.progress);\n",
    "    };\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Validate job exists\n",
    "    if job_id not in agent_state.processing_jobs:\n",
    "        raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "    \n",
    "    job = agent_state.processing_jobs[job_id]\n",
    "    \n",
    "    # TODO: Verify job ownership for security\n",
    "    if job[\"user\"] != user_info[\"user\"]:\n",
    "        raise HTTPException(status_code=403, detail=\"Access denied to this job\")\n",
    "    \n",
    "    async def event_generator():\n",
    "        \"\"\"\n",
    "        Generate Server-Sent Events for job progress\n",
    "        \n",
    "        SSE format:\n",
    "        event: progress\n",
    "        data: {\"progress\": 50, \"message\": \"Processing...\"}\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Send initial status\n",
    "        yield {\n",
    "            \"event\": \"status\",\n",
    "            \"data\": json.dumps({\n",
    "                \"job_id\": job_id,\n",
    "                \"status\": job[\"status\"],\n",
    "                \"created_at\": job[\"created_at\"]\n",
    "            })\n",
    "        }\n",
    "        \n",
    "        last_progress = -1\n",
    "        \n",
    "        # TODO: Stream updates while job is active\n",
    "        # HINT: Poll job state and send updates when changed\n",
    "        while job[\"status\"] in [\"queued\", \"processing\"]:\n",
    "            await asyncio.sleep(0.5)  # Check every 500ms\n",
    "            \n",
    "            # Only send update if progress changed\n",
    "            current_progress = job.get(\"progress\", 0)\n",
    "            if current_progress != last_progress:\n",
    "                yield {\n",
    "                    \"event\": \"progress\",\n",
    "                    \"data\": json.dumps({\n",
    "                        \"progress\": current_progress,\n",
    "                        \"message\": job.get(\"current_step\", \"Processing...\"),\n",
    "                        \"estimated_remaining\": max(0, 15 - (current_progress * 0.15))\n",
    "                    })\n",
    "                }\n",
    "                last_progress = current_progress\n",
    "        \n",
    "        # TODO: Send final result or error\n",
    "        if job[\"status\"] == \"completed\":\n",
    "            yield {\n",
    "                \"event\": \"completed\",\n",
    "                \"data\": json.dumps({\n",
    "                    \"result\": job[\"result\"],\n",
    "                    \"voice_url\": job.get(\"voice_url\"),\n",
    "                    \"processing_time\": calculate_processing_time(job)\n",
    "                })\n",
    "            }\n",
    "        elif job[\"status\"] == \"failed\":\n",
    "            yield {\n",
    "                \"event\": \"error\",\n",
    "                \"data\": json.dumps({\n",
    "                    \"error\": job.get(\"error\", \"Unknown error occurred\"),\n",
    "                    \"failed_at\": job.get(\"failed_at\")\n",
    "                })\n",
    "            }\n",
    "        \n",
    "        # TODO: Send close event\n",
    "        yield {\n",
    "            \"event\": \"close\",\n",
    "            \"data\": json.dumps({\"message\": \"Stream ended\"})\n",
    "        }\n",
    "    \n",
    "    return EventSourceResponse(event_generator())\n",
    "\n",
    "print(\"üì° Streaming endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add helper function for processing time calculation\n",
    "def calculate_processing_time(job: dict) -> float:\n",
    "    \"\"\"Calculate total processing time in seconds\"\"\"\n",
    "    if \"started_at\" not in job or \"completed_at\" not in job:\n",
    "        return 0.0\n",
    "    \n",
    "    start = datetime.fromisoformat(job[\"started_at\"])\n",
    "    end = datetime.fromisoformat(job[\"completed_at\"])\n",
    "    return (end - start).total_seconds()\n",
    "\n",
    "print(\"‚è±Ô∏è Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Status and Results Endpoints (5 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Add traditional polling endpoints for clients that can't use Server-Sent Events.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- REST API design patterns for async operations\n",
    "- Status codes and their meanings\n",
    "- Backward compatibility considerations\n",
    "- Mobile app integration patterns\n",
    "\n",
    "### üìù When to Use Polling vs Streaming\n",
    "\n",
    "**Use Streaming (SSE) when:**\n",
    "- ‚úÖ Web browsers with modern JavaScript\n",
    "- ‚úÖ Real-time dashboard applications\n",
    "- ‚úÖ Long-running operations (>10 seconds)\n",
    "- ‚úÖ Network supports persistent connections\n",
    "\n",
    "**Use Polling when:**\n",
    "- ‚úÖ Mobile apps (better battery life)\n",
    "- ‚úÖ Legacy systems or limited JavaScript\n",
    "- ‚úÖ Corporate firewalls block SSE\n",
    "- ‚úÖ Short operations (<5 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create job status endpoint for polling\n",
    "@app.get(\"/status/{job_id}\")\n",
    "async def get_job_status(\n",
    "    job_id: str,\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"\n",
    "    Get current job status (polling endpoint)\n",
    "    \n",
    "    Status codes:\n",
    "    - 200: Job found and accessible\n",
    "    - 404: Job not found\n",
    "    - 403: Access denied (not your job)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Check job exists\n",
    "    if job_id not in agent_state.processing_jobs:\n",
    "        raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "    \n",
    "    job = agent_state.processing_jobs[job_id]\n",
    "    \n",
    "    # TODO: Verify ownership\n",
    "    if job[\"user\"] != user_info[\"user\"]:\n",
    "        raise HTTPException(status_code=403, detail=\"Access denied\")\n",
    "    \n",
    "    # TODO: Return status information\n",
    "    # HINT: Don't include full results here, just status\n",
    "    return {\n",
    "        \"job_id\": job_id,\n",
    "        \"status\": job[\"status\"],\n",
    "        \"progress\": job.get(\"progress\", 0),\n",
    "        \"current_step\": job.get(\"current_step\", \"Initializing...\"),\n",
    "        \"created_at\": job[\"created_at\"],\n",
    "        \"estimated_completion\": calculate_estimated_completion(job),\n",
    "        \"file_name\": job[\"file_name\"]\n",
    "    }\n",
    "\n",
    "print(\"üìä Status endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create results retrieval endpoint  \n",
    "@app.get(\"/results/{job_id}\")\n",
    "async def get_results(\n",
    "    job_id: str,\n",
    "    format: str = \"json\",  # json, text, or voice\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"\n",
    "    Get processing results once job is complete\n",
    "    \n",
    "    Status codes:\n",
    "    - 200: Results available\n",
    "    - 202: Still processing (check back later)\n",
    "    - 404: Job not found\n",
    "    - 410: Job failed\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Validate job exists and check ownership\n",
    "    if job_id not in agent_state.processing_jobs:\n",
    "        raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "    \n",
    "    job = agent_state.processing_jobs[job_id]\n",
    "    \n",
    "    if job[\"user\"] != user_info[\"user\"]:\n",
    "        raise HTTPException(status_code=403, detail=\"Access denied\")\n",
    "    \n",
    "    # TODO: Check job completion status\n",
    "    if job[\"status\"] in [\"queued\", \"processing\"]:\n",
    "        raise HTTPException(\n",
    "            status_code=202, \n",
    "            detail=f\"Job still {job['status']}. Progress: {job.get('progress', 0)}%\"\n",
    "        )\n",
    "    \n",
    "    if job[\"status\"] == \"failed\":\n",
    "        raise HTTPException(\n",
    "            status_code=410, \n",
    "            detail=f\"Job failed: {job.get('error', 'Unknown error')}\"\n",
    "        )\n",
    "    \n",
    "    # TODO: Return results in requested format\n",
    "    result = job[\"result\"]\n",
    "    \n",
    "    if format == \"text\":\n",
    "        # Convert JSON to human-readable text\n",
    "        text_result = format_as_text(result)\n",
    "        return {\"result\": text_result, \"format\": \"text\"}\n",
    "    elif format == \"voice\" and job.get(\"voice_url\"):\n",
    "        return {\n",
    "            \"voice_url\": job[\"voice_url\"],\n",
    "            \"text\": format_as_text(result),\n",
    "            \"format\": \"voice\"\n",
    "        }\n",
    "    else:\n",
    "        # Default JSON format\n",
    "        return {\n",
    "            \"result\": result,\n",
    "            \"format\": \"json\",\n",
    "            \"processing_time\": calculate_processing_time(job),\n",
    "            \"voice_available\": bool(job.get(\"voice_url\"))\n",
    "        }\n",
    "\n",
    "print(\"üì• Results endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add job management endpoints\n",
    "@app.delete(\"/jobs/{job_id}\")\n",
    "async def cancel_job(\n",
    "    job_id: str,\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"Cancel a processing job\"\"\"\n",
    "    \n",
    "    if job_id not in agent_state.processing_jobs:\n",
    "        raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "    \n",
    "    job = agent_state.processing_jobs[job_id]\n",
    "    \n",
    "    if job[\"user\"] != user_info[\"user\"]:\n",
    "        raise HTTPException(status_code=403, detail=\"Access denied\")\n",
    "    \n",
    "    if job[\"status\"] in [\"completed\", \"failed\"]:\n",
    "        return {\"message\": \"Job already finished\", \"status\": job[\"status\"]}\n",
    "    \n",
    "    # TODO: Implement actual cancellation logic\n",
    "    job[\"status\"] = \"cancelled\"\n",
    "    job[\"cancelled_at\"] = datetime.now().isoformat()\n",
    "    \n",
    "    return {\"message\": \"Job cancelled successfully\", \"job_id\": job_id}\n",
    "\n",
    "@app.get(\"/jobs\")\n",
    "async def list_user_jobs(\n",
    "    limit: int = 10,\n",
    "    user_info: Dict = Depends(verify_token)\n",
    "):\n",
    "    \"\"\"List user's recent jobs\"\"\"\n",
    "    \n",
    "    user_jobs = [\n",
    "        {\n",
    "            \"job_id\": job_id,\n",
    "            \"status\": job[\"status\"],\n",
    "            \"file_name\": job[\"file_name\"],\n",
    "            \"created_at\": job[\"created_at\"]\n",
    "        }\n",
    "        for job_id, job in agent_state.processing_jobs.items()\n",
    "        if job[\"user\"] == user_info[\"user\"]\n",
    "    ]\n",
    "    \n",
    "    # Sort by creation time (newest first) and limit\n",
    "    user_jobs.sort(key=lambda x: x[\"created_at\"], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        \"jobs\": user_jobs[:limit],\n",
    "        \"total\": len(user_jobs)\n",
    "    }\n",
    "\n",
    "# TODO: Helper functions\n",
    "def format_as_text(result: dict) -> str:\n",
    "    \"\"\"Convert JSON result to human-readable text\"\"\"\n",
    "    return f\"\"\"\n",
    "Invoice Analysis Results:\n",
    "========================\n",
    "Vendor: {result.get('vendor', 'Unknown')}\n",
    "Invoice #: {result.get('invoice_number', 'Unknown')}\n",
    "Date: {result.get('date', 'Unknown')}\n",
    "Total: {result.get('currency', '')} {result.get('total_amount', 0)}\n",
    "\n",
    "Line Items:\n",
    "{chr(10).join([f\"- {item['description']}: {item['total']}\" for item in result.get('line_items', [])])}\n",
    "\"\"\".strip()\n",
    "\n",
    "def calculate_estimated_completion(job: dict) -> str:\n",
    "    \"\"\"Calculate estimated completion time\"\"\"\n",
    "    if job[\"status\"] in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    progress = job.get(\"progress\", 0)\n",
    "    if progress == 0:\n",
    "        return \"Calculating...\"\n",
    "    \n",
    "    # Simple estimation based on current progress\n",
    "    remaining_seconds = int(15 * (100 - progress) / 100)\n",
    "    return f\"{remaining_seconds} seconds\"\n",
    "\n",
    "print(\"üîß Job management endpoints created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Health Checks and Monitoring (5 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Add operational endpoints for monitoring the API in production environments.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- Health check patterns for microservices\n",
    "- Prometheus-style metrics collection\n",
    "- Dependency health monitoring\n",
    "- Production readiness indicators\n",
    "\n",
    "### üìù Why Health Checks Matter\n",
    "\n",
    "**Load balancers** use health checks to:\n",
    "- ‚úÖ Route traffic only to healthy instances\n",
    "- ‚úÖ Automatically remove failed instances\n",
    "- ‚úÖ Trigger auto-scaling based on health\n",
    "\n",
    "**Monitoring systems** use health checks to:\n",
    "- ‚úÖ Alert on service degradation\n",
    "- ‚úÖ Track uptime and availability\n",
    "- ‚úÖ Diagnose performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create basic health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Basic health check for load balancers\n",
    "    \n",
    "    Returns 200 if service is running\n",
    "    Load balancers should use this endpoint\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"uptime_seconds\": (datetime.now() - agent_state.startup_time).total_seconds()\n",
    "    }\n",
    "\n",
    "print(\"‚ù§Ô∏è Basic health check created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create detailed health check with dependencies\n",
    "@app.get(\"/health/detailed\")\n",
    "async def detailed_health():\n",
    "    \"\"\"\n",
    "    Detailed health check with component status\n",
    "    \n",
    "    Checks all dependencies and returns detailed status\n",
    "    Useful for debugging and monitoring dashboards\n",
    "    \"\"\"\n",
    "    \n",
    "    health_status = {\n",
    "        \"api\": \"healthy\",\n",
    "        \"langgraph\": \"unknown\",\n",
    "        \"redis\": \"unknown\",\n",
    "        \"llm_backend\": \"unknown\",\n",
    "        \"cartesia_tts\": \"unknown\",\n",
    "        \"deepgram_stt\": \"unknown\"\n",
    "    }\n",
    "    \n",
    "    # TODO: Check LangGraph agent\n",
    "    try:\n",
    "        if agent_state.langgraph_app:\n",
    "            health_status[\"langgraph\"] = \"healthy\"\n",
    "        else:\n",
    "            health_status[\"langgraph\"] = \"not_initialized\"\n",
    "    except Exception as e:\n",
    "        health_status[\"langgraph\"] = f\"unhealthy: {str(e)}\"\n",
    "    \n",
    "    # TODO: Check Redis connection\n",
    "    try:\n",
    "        if agent_state.redis_client:\n",
    "            agent_state.redis_client.ping()\n",
    "            health_status[\"redis\"] = \"healthy\"\n",
    "        else:\n",
    "            health_status[\"redis\"] = \"not_configured\"\n",
    "    except Exception as e:\n",
    "        health_status[\"redis\"] = f\"unhealthy: {str(e)}\"\n",
    "    \n",
    "    # TODO: Check Ollama LLM backend\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/health\", timeout=2)\n",
    "        if response.status_code == 200:\n",
    "            health_status[\"llm_backend\"] = \"healthy\"\n",
    "        else:\n",
    "            health_status[\"llm_backend\"] = f\"unhealthy: HTTP {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        health_status[\"llm_backend\"] = f\"unhealthy: {str(e)}\"\n",
    "    \n",
    "    # TODO: Check Cartesia TTS API\n",
    "    try:\n",
    "        if CARTESIA_API_KEY:\n",
    "            # Mock check - in production, make actual API call\n",
    "            health_status[\"cartesia_tts\"] = \"configured\"\n",
    "        else:\n",
    "            health_status[\"cartesia_tts\"] = \"not_configured\"\n",
    "    except Exception as e:\n",
    "        health_status[\"cartesia_tts\"] = f\"error: {str(e)}\"\n",
    "    \n",
    "    # TODO: Check Deepgram STT API\n",
    "    try:\n",
    "        if DEEPGRAM_API_KEY:\n",
    "            health_status[\"deepgram_stt\"] = \"configured\"\n",
    "        else:\n",
    "            health_status[\"deepgram_stt\"] = \"not_configured\"\n",
    "    except Exception as e:\n",
    "        health_status[\"deepgram_stt\"] = f\"error: {str(e)}\"\n",
    "    \n",
    "    # TODO: Determine overall status\n",
    "    critical_components = [\"api\", \"llm_backend\"]\n",
    "    critical_healthy = all(\n",
    "        health_status[comp] == \"healthy\" \n",
    "        for comp in critical_components\n",
    "    )\n",
    "    \n",
    "    overall_status = \"healthy\" if critical_healthy else \"degraded\"\n",
    "    \n",
    "    return {\n",
    "        \"status\": overall_status,\n",
    "        \"components\": health_status,\n",
    "        \"active_jobs\": len(agent_state.processing_jobs),\n",
    "        \"jobs_by_status\": get_job_stats(),\n",
    "        \"uptime_seconds\": (datetime.now() - agent_state.startup_time).total_seconds(),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "print(\"üîç Detailed health check created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create metrics endpoint for Prometheus\n",
    "@app.get(\"/metrics\")\n",
    "async def get_metrics():\n",
    "    \"\"\"\n",
    "    Prometheus-style metrics for monitoring\n",
    "    \n",
    "    These metrics can be scraped by Prometheus/Grafana\n",
    "    for dashboards and alerting\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Calculate various metrics\n",
    "    job_stats = get_job_stats()\n",
    "    uptime = (datetime.now() - agent_state.startup_time).total_seconds()\n",
    "    \n",
    "    # TODO: Format as Prometheus metrics\n",
    "    metrics = []\n",
    "    \n",
    "    # System metrics\n",
    "    metrics.append(f\"invoice_api_uptime_seconds {uptime}\")\n",
    "    metrics.append(f\"invoice_api_active_jobs {len(agent_state.processing_jobs)}\")\n",
    "    \n",
    "    # Job status metrics\n",
    "    for status, count in job_stats.items():\n",
    "        metrics.append(f'invoice_api_jobs_total{{status=\"{status}\"}} {count}')\n",
    "    \n",
    "    # User tier metrics\n",
    "    user_stats = get_user_stats()\n",
    "    for tier, count in user_stats.items():\n",
    "        metrics.append(f'invoice_api_users_total{{tier=\"{tier}\"}} {count}')\n",
    "    \n",
    "    # Success rate (last 100 jobs)\n",
    "    success_rate = calculate_success_rate()\n",
    "    metrics.append(f\"invoice_api_success_rate {success_rate}\")\n",
    "    \n",
    "    # Average processing time\n",
    "    avg_time = calculate_average_processing_time()\n",
    "    metrics.append(f\"invoice_api_avg_processing_seconds {avg_time}\")\n",
    "    \n",
    "    return \"\\n\".join(metrics), {\"Content-Type\": \"text/plain\"}\n",
    "\n",
    "print(\"üìä Metrics endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Helper functions for metrics\n",
    "def get_job_stats() -> Dict[str, int]:\n",
    "    \"\"\"Count jobs by status\"\"\"\n",
    "    stats = {\"queued\": 0, \"processing\": 0, \"completed\": 0, \"failed\": 0, \"cancelled\": 0}\n",
    "    \n",
    "    for job in agent_state.processing_jobs.values():\n",
    "        status = job[\"status\"]\n",
    "        if status in stats:\n",
    "            stats[status] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def get_user_stats() -> Dict[str, int]:\n",
    "    \"\"\"Count users by tier\"\"\"\n",
    "    stats = {\"free\": 0, \"premium\": 0}\n",
    "    \n",
    "    for user_info in API_KEYS.values():\n",
    "        tier = user_info[\"tier\"]\n",
    "        if tier in stats:\n",
    "            stats[tier] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def calculate_success_rate() -> float:\n",
    "    \"\"\"Calculate success rate for recent jobs\"\"\"\n",
    "    completed_jobs = [\n",
    "        job for job in agent_state.processing_jobs.values()\n",
    "        if job[\"status\"] in [\"completed\", \"failed\"]\n",
    "    ]\n",
    "    \n",
    "    if not completed_jobs:\n",
    "        return 1.0\n",
    "    \n",
    "    successful = sum(1 for job in completed_jobs if job[\"status\"] == \"completed\")\n",
    "    return successful / len(completed_jobs)\n",
    "\n",
    "def calculate_average_processing_time() -> float:\n",
    "    \"\"\"Calculate average processing time for completed jobs\"\"\"\n",
    "    completed_jobs = [\n",
    "        job for job in agent_state.processing_jobs.values()\n",
    "        if job[\"status\"] == \"completed\" and \"processing_time\" in job\n",
    "    ]\n",
    "    \n",
    "    if not completed_jobs:\n",
    "        return 0.0\n",
    "    \n",
    "    total_time = sum(calculate_processing_time(job) for job in completed_jobs)\n",
    "    return total_time / len(completed_jobs)\n",
    "\n",
    "print(\"üìà Metrics helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Docker Containerization (5 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Create Docker configuration for consistent deployment across environments.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- Multi-stage Docker builds for smaller images\n",
    "- Security best practices (non-root user)\n",
    "- Health checks in containers\n",
    "- Environment variable management\n",
    "\n",
    "### üìù Why Docker?\n",
    "\n",
    "**Without Docker:**\n",
    "- ‚ùå \"Works on my machine\" problems\n",
    "- ‚ùå Complex deployment procedures\n",
    "- ‚ùå Dependency conflicts\n",
    "- ‚ùå Different environments behave differently\n",
    "\n",
    "**With Docker:**\n",
    "- ‚úÖ Identical behavior everywhere\n",
    "- ‚úÖ Simple deployment (`docker run`)\n",
    "- ‚úÖ Isolated dependencies\n",
    "- ‚úÖ Easy scaling with orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create requirements.txt file\n",
    "requirements_content = \"\"\"\n",
    "# FastAPI and server\n",
    "fastapi==0.104.1\n",
    "uvicorn[standard]==0.24.0\n",
    "python-multipart==0.0.6\n",
    "\n",
    "# Streaming and SSE\n",
    "sse-starlette==1.6.5\n",
    "\n",
    "# Data models and validation\n",
    "pydantic==2.5.0\n",
    "\n",
    "# LangGraph and AI\n",
    "langgraph==0.1.0\n",
    "langchain==0.1.0\n",
    "\n",
    "# Storage and caching\n",
    "redis==5.0.1\n",
    "\n",
    "# HTTP requests\n",
    "requests==2.31.0\n",
    "\n",
    "# Image processing\n",
    "Pillow==10.1.0\n",
    "\n",
    "# Voice APIs\n",
    "# cartesia-tts==1.0.0  # Add when available\n",
    "# deepgram-sdk==3.0.0  # Add when available\n",
    "\"\"\".strip()\n",
    "\n",
    "# Write requirements.txt\n",
    "with open('/tmp/requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"üì¶ requirements.txt created\")\n",
    "print(requirements_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create Dockerfile with multi-stage build\n",
    "dockerfile_content = \"\"\"\n",
    "# Multi-stage build for smaller production image\n",
    "FROM python:3.10-slim as builder\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    gcc \\\n",
    "    g++ \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy and install Python dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir --user -r requirements.txt\n",
    "\n",
    "# Production stage\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy installed packages from builder stage\n",
    "COPY --from=builder /root/.local /root/.local\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Create non-root user for security\n",
    "RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app\n",
    "USER appuser\n",
    "\n",
    "# Make sure scripts in .local are usable\n",
    "ENV PATH=/root/.local/bin:$PATH\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import requests; requests.get('http://localhost:8000/health', timeout=2)\"\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run application\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--workers\", \"1\"]\n",
    "\"\"\".strip()\n",
    "\n",
    "# Write Dockerfile\n",
    "with open('/tmp/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "print(\"üê≥ Dockerfile created\")\n",
    "print(dockerfile_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create docker-compose.yml for local development\n",
    "docker_compose_content = \"\"\"\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  invoice-api:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - OLLAMA_URL=http://host.docker.internal:80\n",
    "      - API_TOKEN=your_token_here\n",
    "      - MODEL=qwen3:8b\n",
    "      - CARTESIA_API_KEY=sk_car_opGv9cytcCL97oHBNCns6r\n",
    "      - DEEPGRAM_API_KEY=3038f0650ad0fd4955efd0191b10948a6fe95b74\n",
    "    volumes:\n",
    "      - ./:/app\n",
    "    depends_on:\n",
    "      - redis\n",
    "    restart: unless-stopped\n",
    "\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    restart: unless-stopped\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "\"\"\".strip()\n",
    "\n",
    "# Write docker-compose.yml\n",
    "with open('/tmp/docker-compose.yml', 'w') as f:\n",
    "    f.write(docker_compose_content)\n",
    "\n",
    "print(\"üîß docker-compose.yml created\")\n",
    "print(docker_compose_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Deploy to Hugging Face Spaces (7 minutes)\n",
    "\n",
    "### üéØ Goal\n",
    "Deploy your API to free cloud hosting using Hugging Face Spaces.\n",
    "\n",
    "### üí° What You'll Learn\n",
    "- Hugging Face Spaces deployment process\n",
    "- Gradio wrapper for FastAPI applications\n",
    "- Environment variable management in cloud\n",
    "- Production deployment considerations\n",
    "\n",
    "### üìù Deployment Options\n",
    "\n",
    "**Hugging Face Spaces:**\n",
    "- ‚úÖ Free hosting for public projects\n",
    "- ‚úÖ Automatic HTTPS and domain\n",
    "- ‚úÖ Docker support\n",
    "- ‚úÖ Great for demos and prototypes\n",
    "- ‚ùå Limited resources (2 CPU, 16GB RAM)\n",
    "\n",
    "**Other options:**\n",
    "- **Railway**: Fast deployment, good for startups\n",
    "- **Render**: Free tier, easy to use\n",
    "- **Google Cloud Run**: Pay-per-use, auto-scaling\n",
    "- **AWS Lambda**: Serverless, very cost-effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create app.py for Hugging Face Spaces\n",
    "spaces_app_content = \"\"\"\n",
    "# Hugging Face Spaces entry point\n",
    "import gradio as gr\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "\n",
    "# Import your FastAPI app\n",
    "# from main import app\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"  # Update for production\n",
    "API_KEY = \"demo-key-123\"  # Use environment variable in production\n",
    "\n",
    "def process_invoice_gradio(image, instructions, voice_enabled):\n",
    "    \\\"\\\"\\\"\n",
    "    Gradio interface function for invoice processing\n",
    "    \\\"\\\"\\\"\n",
    "    \n",
    "    if image is None:\n",
    "        return \"Please upload an image\", None, None\n",
    "    \n",
    "    try:\n",
    "        # Convert PIL image to bytes\n",
    "        img_bytes = io.BytesIO()\n",
    "        image.save(img_bytes, format='PNG')\n",
    "        img_bytes.seek(0)\n",
    "        \n",
    "        # Upload to API\n",
    "        files = {'file': ('invoice.png', img_bytes, 'image/png')}\n",
    "        data = {\n",
    "            'instructions': instructions,\n",
    "            'voice_response': voice_enabled\n",
    "        }\n",
    "        headers = {'Authorization': f'Bearer {API_KEY}'}\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/process/invoice\",\n",
    "            files=files,\n",
    "            data=data,\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            job_info = response.json()\n",
    "            job_id = job_info['job_id']\n",
    "            \n",
    "            # Poll for results\n",
    "            max_wait = 60  # seconds\n",
    "            waited = 0\n",
    "            \n",
    "            while waited < max_wait:\n",
    "                time.sleep(2)\n",
    "                waited += 2\n",
    "                \n",
    "                status_response = requests.get(\n",
    "                    f\"{API_BASE_URL}/status/{job_id}\",\n",
    "                    headers=headers\n",
    "                )\n",
    "                \n",
    "                if status_response.status_code == 200:\n",
    "                    status = status_response.json()\n",
    "                    \n",
    "                    if status['status'] == 'completed':\n",
    "                        # Get results\n",
    "                        results_response = requests.get(\n",
    "                            f\"{API_BASE_URL}/results/{job_id}\",\n",
    "                            headers=headers\n",
    "                        )\n",
    "                        \n",
    "                        if results_response.status_code == 200:\n",
    "                            results = results_response.json()\n",
    "                            \n",
    "                            # Format results\n",
    "                            result_text = format_results(results['result'])\n",
    "                            result_json = json.dumps(results['result'], indent=2)\n",
    "                            \n",
    "                            # Audio URL if available\n",
    "                            audio_url = results.get('voice_url')\n",
    "                            \n",
    "                            return result_text, result_json, audio_url\n",
    "                    \n",
    "                    elif status['status'] == 'failed':\n",
    "                        return f\"Processing failed: {status.get('error', 'Unknown error')}\", None, None\n",
    "            \n",
    "            return \"Processing timed out. Please try again.\", None, None\n",
    "        \n",
    "        else:\n",
    "            return f\"Upload failed: {response.text}\", None, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", None, None\n",
    "\n",
    "def format_results(result):\n",
    "    \\\"\\\"\\\"Format JSON results as readable text\\\"\\\"\\\"\n",
    "    return f\\\"\\\"\\\"Invoice Analysis Results:\n",
    "========================\n",
    "Vendor: {result.get('vendor', 'Unknown')}\n",
    "Invoice #: {result.get('invoice_number', 'Unknown')}\n",
    "Date: {result.get('date', 'Unknown')}\n",
    "Total: {result.get('currency', '')} {result.get('total_amount', 0)}\n",
    "\n",
    "Line Items:\n",
    "{chr(10).join([f\"- {item['description']}: {item['total']}\" for item in result.get('line_items', [])])}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Invoice Processing Agent\") as demo:\n",
    "    gr.Markdown(\\\"\\\"\\\"# üìÑ Invoice Processing Agent\n",
    "    \n",
    "    Upload an invoice image to extract structured data using our multimodal AI agent.\n",
    "    \n",
    "    **Features:**\n",
    "    - üîç Automatic text extraction with OCR\n",
    "    - üß† Smart data structuring with LLM\n",
    "    - üéµ Optional voice response\n",
    "    - ‚ö° Real-time processing updates\n",
    "    \\\"\\\"\\\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_input = gr.Image(\n",
    "                type=\"pil\", \n",
    "                label=\"üì§ Upload Invoice Image\",\n",
    "                height=300\n",
    "            )\n",
    "            \n",
    "            instructions_input = gr.Textbox(\n",
    "                label=\"üìù Processing Instructions\",\n",
    "                value=\"Extract all invoice data including vendor, amounts, dates, and line items\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            voice_checkbox = gr.Checkbox(\n",
    "                label=\"üéµ Generate Voice Response\",\n",
    "                value=False\n",
    "            )\n",
    "            \n",
    "            process_btn = gr.Button(\n",
    "                \"üöÄ Process Invoice\", \n",
    "                variant=\"primary\",\n",
    "                size=\"lg\"\n",
    "            )\n",
    "        \n",
    "        with gr.Column():\n",
    "            result_text = gr.Textbox(\n",
    "                label=\"üìã Extracted Data (Formatted)\",\n",
    "                lines=10,\n",
    "                max_lines=20\n",
    "            )\n",
    "            \n",
    "            result_json = gr.JSON(\n",
    "                label=\"üîß Raw JSON Output\"\n",
    "            )\n",
    "            \n",
    "            audio_output = gr.Audio(\n",
    "                label=\"üéµ Voice Response\",\n",
    "                visible=False\n",
    "            )\n",
    "    \n",
    "    # Event handlers\n",
    "    process_btn.click(\n",
    "        fn=process_invoice_gradio,\n",
    "        inputs=[image_input, instructions_input, voice_checkbox],\n",
    "        outputs=[result_text, result_json, audio_output]\n",
    "    )\n",
    "    \n",
    "    # Show audio player when voice is enabled\n",
    "    voice_checkbox.change(\n",
    "        fn=lambda x: gr.update(visible=x),\n",
    "        inputs=[voice_checkbox],\n",
    "        outputs=[audio_output]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\\\"\\\"\\\"### üìö How to Use\n",
    "    \n",
    "    1. **Upload** an invoice image (PNG, JPG, or PDF)\n",
    "    2. **Customize** processing instructions if needed\n",
    "    3. **Enable** voice response for audio output\n",
    "    4. **Click** \"Process Invoice\" and wait for results\n",
    "    \n",
    "    ### üõ†Ô∏è Technical Details\n",
    "    \n",
    "    - **Backend**: FastAPI with LangGraph agents\n",
    "    - **Vision**: Multiple OCR engines + LLM analysis\n",
    "    - **Voice**: Cartesia TTS for natural speech\n",
    "    - **Deployment**: Docker container on Hugging Face Spaces\n",
    "    \\\"\\\"\\\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=7860)\n",
    "\"\"\".strip()\n",
    "\n",
    "# Write app.py\n",
    "with open('/tmp/app.py', 'w') as f:\n",
    "    f.write(spaces_app_content)\n",
    "\n",
    "print(\"üé® Gradio app.py created for Hugging Face Spaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create README.md for Hugging Face Spaces\n",
    "readme_content = \"\"\"\n",
    "---\n",
    "title: Invoice Processing Agent API\n",
    "emoji: üìÑ\n",
    "colorFrom: blue\n",
    "colorTo: green\n",
    "sdk: docker\n",
    "app_port: 8000\n",
    "---\n",
    "\n",
    "# üìÑ Invoice Processing Agent API\n",
    "\n",
    "A production-ready multimodal AI agent for invoice processing with voice support.\n",
    "\n",
    "## üöÄ Features\n",
    "\n",
    "- **üì§ File Upload**: Support for PNG, JPG, and PDF invoices\n",
    "- **üîç Smart Extraction**: Advanced OCR + LLM analysis\n",
    "- **‚ö° Real-time Streaming**: Server-Sent Events for live updates\n",
    "- **üîê Authentication**: Secure API key-based access\n",
    "- **üéµ Voice Support**: Optional TTS responses\n",
    "- **üìä Monitoring**: Health checks and metrics\n",
    "- **üê≥ Containerized**: Docker-ready for any deployment\n",
    "\n",
    "## üõ†Ô∏è Technology Stack\n",
    "\n",
    "- **Framework**: FastAPI with async processing\n",
    "- **AI Pipeline**: LangGraph for document workflows\n",
    "- **Vision**: Multiple OCR engines (Tesseract, EasyOCR)\n",
    "- **Language Model**: Qwen3 8B via Ollama\n",
    "- **Voice**: Cartesia TTS + Deepgram STT\n",
    "- **Deployment**: Docker on Hugging Face Spaces\n",
    "\n",
    "## üìö API Documentation\n",
    "\n",
    "Once deployed, visit `/docs` for interactive Swagger documentation.\n",
    "\n",
    "### Key Endpoints\n",
    "\n",
    "- `POST /process/invoice` - Upload and process invoice\n",
    "- `GET /stream/{job_id}` - Real-time processing updates\n",
    "- `GET /results/{job_id}` - Get final results\n",
    "- `GET /health` - Service health check\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```bash\n",
    "# Upload invoice for processing\n",
    "curl -X POST \"https://your-space.hf.space/process/invoice\" \\\n",
    "  -H \"Authorization: Bearer your-api-key\" \\\n",
    "  -F \"file=@invoice.jpg\" \\\n",
    "  -F 'request={\"instructions\":\"Extract vendor and total\"}'\n",
    "\n",
    "# Stream real-time updates\n",
    "curl -N \"https://your-space.hf.space/stream/job-id\" \\\n",
    "  -H \"Authorization: Bearer your-api-key\" \\\n",
    "  -H \"Accept: text/event-stream\"\n",
    "```\n",
    "\n",
    "## üîß Local Development\n",
    "\n",
    "```bash\n",
    "# Clone and setup\n",
    "git clone <your-repo>\n",
    "cd invoice-agent-api\n",
    "\n",
    "# Run with Docker Compose\n",
    "docker-compose up --build\n",
    "\n",
    "# Or run directly\n",
    "pip install -r requirements.txt\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "## üîê Security\n",
    "\n",
    "- API key authentication required\n",
    "- Rate limiting per user tier\n",
    "- File type and size validation\n",
    "- Non-root container execution\n",
    "\n",
    "## üìä Monitoring\n",
    "\n",
    "- Health checks at `/health` and `/health/detailed`\n",
    "- Prometheus metrics at `/metrics`\n",
    "- Job tracking and user statistics\n",
    "\n",
    "## ü§ù Contributing\n",
    "\n",
    "1. Fork the repository\n",
    "2. Create a feature branch\n",
    "3. Make your changes\n",
    "4. Add tests\n",
    "5. Submit a pull request\n",
    "\n",
    "## üìÑ License\n",
    "\n",
    "MIT License - see LICENSE file for details.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Write README.md\n",
    "with open('/tmp/README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"üìñ README.md created for Hugging Face Spaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show deployment instructions\n",
    "deployment_instructions = \"\"\"\n",
    "üöÄ DEPLOYMENT INSTRUCTIONS\n",
    "==========================\n",
    "\n",
    "### Option 1: Hugging Face Spaces (Recommended)\n",
    "\n",
    "1. **Create new Space**:\n",
    "   - Go to https://huggingface.co/new-space\n",
    "   - Choose \"Docker\" as SDK\n",
    "   - Set app_port to 8000\n",
    "\n",
    "2. **Upload files**:\n",
    "   - Dockerfile\n",
    "   - requirements.txt\n",
    "   - app.py (Gradio wrapper)\n",
    "   - main.py (your FastAPI code)\n",
    "   - README.md\n",
    "\n",
    "3. **Set environment variables**:\n",
    "   - OLLAMA_URL=your_ollama_server\n",
    "   - API_TOKEN=your_token\n",
    "   - CARTESIA_API_KEY=sk_car_opGv9cytcCL97oHBNCns6r\n",
    "   - DEEPGRAM_API_KEY=3038f0650ad0fd4955efd0191b10948a6fe95b74\n",
    "\n",
    "### Option 2: Railway (Fast deployment)\n",
    "\n",
    "1. Connect GitHub repo to Railway\n",
    "2. Railway auto-detects Dockerfile\n",
    "3. Set environment variables\n",
    "4. Deploy automatically\n",
    "\n",
    "### Option 3: Google Cloud Run\n",
    "\n",
    "```bash\n",
    "# Build and deploy\n",
    "gcloud builds submit --tag gcr.io/PROJECT_ID/invoice-api\n",
    "gcloud run deploy --image gcr.io/PROJECT_ID/invoice-api --platform managed\n",
    "```\n",
    "\n",
    "### Option 4: Local Docker\n",
    "\n",
    "```bash\n",
    "# Build image\n",
    "docker build -t invoice-api .\n",
    "\n",
    "# Run container\n",
    "docker run -p 8000:8000 \\\n",
    "  -e OLLAMA_URL=http://your-server \\\n",
    "  -e API_TOKEN=your-token \\\n",
    "  invoice-api\n",
    "```\n",
    "\n",
    "### Testing Your Deployment\n",
    "\n",
    "1. **Health check**: GET /health\n",
    "2. **API docs**: Visit /docs\n",
    "3. **Upload test**: POST /process/invoice\n",
    "4. **Monitor**: GET /metrics\n",
    "\n",
    "üéâ Your API is now live and ready for production!\n",
    "\"\"\"\n",
    "\n",
    "print(deployment_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Lab Completion & Testing\n",
    "\n",
    "### ‚úÖ Assessment Checklist\n",
    "\n",
    "**Core Functionality:**\n",
    "- [ ] FastAPI application starts without errors\n",
    "- [ ] File upload endpoint accepts images and PDFs\n",
    "- [ ] Authentication blocks invalid API keys\n",
    "- [ ] Rate limiting prevents abuse\n",
    "- [ ] Async processing returns job IDs\n",
    "- [ ] Streaming endpoint provides real-time updates\n",
    "- [ ] Results endpoint returns structured data\n",
    "\n",
    "**Production Readiness:**\n",
    "- [ ] Health checks return 200 status\n",
    "- [ ] Metrics endpoint provides monitoring data\n",
    "- [ ] Docker container builds successfully\n",
    "- [ ] Application handles errors gracefully\n",
    "- [ ] API documentation is accessible at `/docs`\n",
    "\n",
    "**Advanced Features:**\n",
    "- [ ] Voice synthesis integration works\n",
    "- [ ] Job cancellation functions\n",
    "- [ ] User job listing works\n",
    "- [ ] Detailed health checks all components\n",
    "\n",
    "### üß™ Testing Your API\n",
    "\n",
    "Run these commands to test your deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the API endpoints (if running locally)\n",
    "# HINT: Uncomment and run these tests if your API is running\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"http://localhost:8000\"  # Change to your deployed URL\n",
    "TEST_API_KEY = \"demo-key-123\"\n",
    "headers = {\"Authorization\": f\"Bearer {TEST_API_KEY}\"}\n",
    "\n",
    "def test_health_check():\n",
    "    \"\"\"Test basic health endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/health\")\n",
    "        print(f\"‚úÖ Health check: {response.status_code} - {response.json()['status']}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Health check failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_authentication():\n",
    "    \"\"\"Test authentication with invalid key\"\"\"\n",
    "    try:\n",
    "        bad_headers = {\"Authorization\": \"Bearer invalid-key\"}\n",
    "        response = requests.get(f\"{BASE_URL}/status/test\", headers=bad_headers)\n",
    "        if response.status_code == 403:\n",
    "            print(\"‚úÖ Authentication: Correctly rejects invalid keys\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Authentication: Expected 403, got {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Authentication test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_file_upload():\n",
    "    \"\"\"Test file upload with mock image\"\"\"\n",
    "    try:\n",
    "        # Create a small test image\n",
    "        from PIL import Image\n",
    "        import io\n",
    "        \n",
    "        # Create test image\n",
    "        img = Image.new('RGB', (100, 100), color='white')\n",
    "        img_bytes = io.BytesIO()\n",
    "        img.save(img_bytes, format='PNG')\n",
    "        img_bytes.seek(0)\n",
    "        \n",
    "        # Upload test\n",
    "        files = {'file': ('test.png', img_bytes, 'image/png')}\n",
    "        data = {'instructions': 'Test processing'}\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/process/invoice\",\n",
    "            files=files,\n",
    "            data=data,\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ File upload: Job {result['job_id']} created\")\n",
    "            return result['job_id']\n",
    "        else:\n",
    "            print(f\"‚ùå File upload failed: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå File upload test failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_job_status(job_id):\n",
    "    \"\"\"Test job status endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/status/{job_id}\", headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            status = response.json()\n",
    "            print(f\"‚úÖ Job status: {status['status']} ({status['progress']}%)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Job status failed: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Job status test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run tests if API is available\n",
    "print(\"üß™ Starting API Tests...\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: These tests require the API to be running locally\")\n",
    "print(\"   Start your API first: uvicorn main:app --reload\\n\")\n",
    "\n",
    "# Uncomment these lines to run tests:\n",
    "# if test_health_check():\n",
    "#     test_authentication()\n",
    "#     job_id = test_file_upload()\n",
    "#     if job_id:\n",
    "#         time.sleep(2)\n",
    "#         test_job_status(job_id)\n",
    "\n",
    "print(\"\\nüéâ Lab completed! Your production API is ready to deploy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Congratulations!\n",
    "\n",
    "You've successfully built a **production-ready Invoice Processing API** with:\n",
    "\n",
    "### üéØ What You Accomplished\n",
    "- ‚úÖ **FastAPI Backend** with async processing\n",
    "- ‚úÖ **Authentication & Security** with API keys and rate limiting\n",
    "- ‚úÖ **File Upload & Processing** with validation and job management\n",
    "- ‚úÖ **Real-time Streaming** with Server-Sent Events\n",
    "- ‚úÖ **Voice Integration** with Cartesia TTS and Deepgram STT\n",
    "- ‚úÖ **Health Monitoring** with metrics and diagnostics\n",
    "- ‚úÖ **Docker Containerization** for consistent deployment\n",
    "- ‚úÖ **Cloud Deployment** ready for Hugging Face Spaces\n",
    "\n",
    "### üöÄ Key Skills Learned\n",
    "1. **Production API Design** - REST patterns, async processing, error handling\n",
    "2. **Security Implementation** - Authentication, rate limiting, input validation\n",
    "3. **Real-time Communication** - Server-Sent Events for live updates\n",
    "4. **Containerization** - Docker best practices for AI applications\n",
    "5. **Cloud Deployment** - Platform-agnostic deployment strategies\n",
    "6. **Monitoring & Observability** - Health checks, metrics, logging\n",
    "\n",
    "### üîÑ Next Steps\n",
    "- **Deploy** your API to Hugging Face Spaces or your preferred platform\n",
    "- **Integrate** with a frontend application (React, Vue, or mobile app)\n",
    "- **Scale** with Redis for session management and job queuing\n",
    "- **Monitor** with Prometheus/Grafana for production insights\n",
    "- **Enhance** with additional AI capabilities (document classification, fraud detection)\n",
    "\n",
    "### üí° Real-World Applications\n",
    "This pattern applies to any AI service:\n",
    "- **Document Processing** (contracts, receipts, forms)\n",
    "- **Image Analysis** (medical scans, quality inspection)\n",
    "- **Voice Assistants** (customer service, accessibility)\n",
    "- **Content Generation** (reports, summaries, translations)\n",
    "\n",
    "**You now have the skills to ship AI agents to production!** üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **FastAPI Documentation**: https://fastapi.tiangolo.com/\n",
    "- **Docker Best Practices**: https://docs.docker.com/develop/dev-best-practices/\n",
    "- **Hugging Face Spaces**: https://huggingface.co/docs/hub/spaces\n",
    "- **Server-Sent Events**: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events\n",
    "- **API Security**: https://owasp.org/www-project-api-security/\n",
    "\n",
    "## üèÉ‚Äç‚ôÇÔ∏è Bonus Challenges (For Fast Finishers)\n",
    "\n",
    "### Challenge 1: Add WebSocket Support\n",
    "Implement bidirectional communication for real-time voice chat with the invoice agent.\n",
    "\n",
    "### Challenge 2: Implement Caching\n",
    "Add Redis caching for processed invoices to avoid reprocessing identical documents.\n",
    "\n",
    "### Challenge 3: Add Batch Processing\n",
    "Create an endpoint that accepts multiple invoices and processes them in parallel.\n",
    "\n",
    "### Challenge 4: Build a Frontend\n",
    "Create a React/Vue.js frontend that consumes your API with drag-and-drop file upload.\n",
    "\n",
    "### Challenge 5: Add Database Integration\n",
    "Replace in-memory job storage with PostgreSQL or MongoDB for persistence.\n",
    "\n",
    "### Challenge 6: Implement A/B Testing\n",
    "Add multiple processing pipelines and test which performs better for different invoice types.\n",
    "\n",
    "**Time remaining? Pick a challenge and level up your production skills!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}